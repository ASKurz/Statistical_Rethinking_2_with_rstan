[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Statistical rethinking 2 with rstan and the tidyverse",
    "section": "",
    "text": "Preface"
  },
  {
    "objectID": "index.html#what-and-why",
    "href": "index.html#what-and-why",
    "title": "Statistical rethinking 2 with rstan and the tidyverse",
    "section": "What and why",
    "text": "What and why\nThis book is based on the second edition of Richard McElreath’s (2020) text, Statistical rethinking: A Bayesian course with examples in R and Stan. My contributions show how to fit the models he covered with rstan (Stan Development Team, 2024a), which allows one to fit Bayesian models in R (R Core Team, 2022) using Hamiltonian Monte Carlo. I also prefer plotting and data wrangling with the packages from the tidyverse (Wickham et al., 2019; Wickham, 2022), so we’ll be using those methods, too.\nThis is a sibling book of my translation of McElreath’s second edition into brms code (Kurz, 2023), which you can find by clicking here."
  },
  {
    "objectID": "index.html#how-this-compares-with-the-brms-translation-and-what-this-means-for-readers",
    "href": "index.html#how-this-compares-with-the-brms-translation-and-what-this-means-for-readers",
    "title": "Statistical rethinking 2 with rstan and the tidyverse",
    "section": "How this compares with the brms translation, and what this means for readers",
    "text": "How this compares with the brms translation, and what this means for readers\nI think rstan is harder to use than brms. Its syntax is more technical, and it doesn’t follow many of the conventions used by other popular statistics packages, such as stats and lme4. rstan is also more general than brms, allowing for a variety of unconventional and bespoke models. Therefore I’m presuming the readership for this book will be intermediate to advanced in both statistical skills, and general R programming skills. I will still take a pedagogical tone in this book, but my pace will be a little faster than in my other books.\nAlso, because this is sibling book to my brms translation, I will not replicate all my previous work. Rather, the code in this book will be more tightly focused on reproducing the models and primary analyses with an rstan + tidyverse framework. The supporting prose will be sparser, and I will have fewer quotes from the text. If you want a richer engagement with McElreath’s text, you probably want my brms translation instead."
  },
  {
    "objectID": "index.html#r-setup",
    "href": "index.html#r-setup",
    "title": "Statistical rethinking 2 with rstan and the tidyverse",
    "section": "R setup",
    "text": "R setup\nTo get the full benefit from this ebook, you’ll need some software. Happily, everything will be free (provided you have access to a decent personal computer and an good internet connection).\nFirst, you’ll need to install R, which you can learn about at https://cran.r-project.org/.\nThough not necessary, your R experience might be more enjoyable if done through the free RStudio interface, which you can learn about at https://posit.co/products/open-source/rstudio/.\nOnce you have installed R, execute the following to install the bulk of the add-on packages. This may take a few minutes to finish. Go make yourself a coffee.\n\npackages &lt;- c(\"bayesplot\", \"dagitty\", \"devtools\", \"GGally\", \"ggdag\", \"patchwork\", \"posterior\", \"remotes\", \"rstan\", \"tidybayes\", \"tidyverse\", \"tigris\")\n\ninstall.packages(packages, dependencies = TRUE)\n\nA couple of the other packages are not officially available via the Comprehensive R Archive Network (CRAN; https://cran.r-project.org/). You can download them directly from GitHub by executing the following.\n\ndevtools::install_github(\"stan-dev/cmdstanr\")\ndevtools::install_github(\"rmcelreath/rethinking\")\n\nIt’s possible you’ll have problems installing some of these packages. Here are some likely suspects and where you can find help:\n\nfor difficulties installing cmdstanr, go to https://mc-stan.org/cmdstanr/articles/cmdstanr.html;\nfor difficulties installing rethinking, go to https://github.com/rmcelreath/rethinking#installation; and\nfor difficulties installing rstan, go to https://github.com/stan-dev/rstan/wiki/RStan-Getting-Started."
  },
  {
    "objectID": "index.html#conventions",
    "href": "index.html#conventions",
    "title": "Statistical rethinking 2 with rstan and the tidyverse",
    "section": "Conventions",
    "text": "Conventions\nAs in my other books, I use a handful of formatting conventions gleaned from R4DS, The tidyverse style guide (Wickham, 2020), and R markdown: The definitive guide (Xie et al., 2020).\n\nR code blocks and their output appear in a gray background. E.g.,\n\n\n2 + 2 == 5\n\n[1] FALSE\n\n\n\nR and the names of specific package (e.g., rstan) are in boldface font.\nFunctions are in a typewriter font and followed by parentheses, all atop a gray background (e.g., stan()).\nWhen I want to make explicit the package a given function comes from, I insert the double-colon operator :: between the package name and the function (e.g., posterior::as_draws_df()).\nR objects, such as data or function arguments, are in typewriter font atop gray backgrounds (e.g., chimpanzees, .width = 0.89).\nYou can detect hyperlinks by their typical blue-colored font.\n\nFor the rstan code, I’m also taking cues from the Stan Program Style Guide section of the Stan User’s Guide (Stan Development Team, 2024b). However, as I’m relatively new to rstan, don’t be surprised if you find quirks an inconsistencies."
  },
  {
    "objectID": "index.html#warning",
    "href": "index.html#warning",
    "title": "Statistical rethinking 2 with rstan and the tidyverse",
    "section": "Warning",
    "text": "Warning\nThis book is a side-product of another project for which I needed to learn more about rstan. It was also a good opportunity to learn more about making a Quarto-based ebook (Allaire et al., 2024). For this second 0.0.2 release, I’m only up through Chapter 12. I will continue to chip away on this as my schedule permits, but I am setting no goals and no deadlines. On the one hand, it would be nice to have another finished book in my portfolio; on the other hand, I really don’t like using rstan and I still much prefer a brms-based workflow. The remaining chapters in this book may find themselves fleshed out in quick succession, or this whole project may lay fallow. We’ll see…"
  },
  {
    "objectID": "index.html#comments",
    "href": "index.html#comments",
    "title": "Statistical rethinking 2 with rstan and the tidyverse",
    "section": "Comments!",
    "text": "Comments!\nThis is my first ebook with comments sections! Please play nice. I don’t plan on heavily monitoring the comments, but if needed I reserve the right to delete, block, and so on."
  },
  {
    "objectID": "index.html#thank-yous-are-in-order",
    "href": "index.html#thank-yous-are-in-order",
    "title": "Statistical rethinking 2 with rstan and the tidyverse",
    "section": "Thank-you’s are in order",
    "text": "Thank-you’s are in order\nI’d like to thank the following for their helpful contributions:\n\nVincent Arel-Bundock (@vincentarelbundock),\nAndrew Heiss (@andrewheiss),\nAndrew Johnson (@andrjohns),\nJohn K. Kruschke (@kruschke), and\nJeff Pollock (@jeffpollock9).\n\nEach of these folks have shared rstan code that a directly helped make this book possible. I especially appreciate and recommend Arel-Bundock’s website Statistical Rethinking 2 with Stan and R, wherein you can find rendered Rmarkdown files with loads of rstan code on many of the same problems I’m tackling in this book. If you compare our works, you’ll see I have been heavily influenced by Arel-Bundock’s rstan style."
  },
  {
    "objectID": "index.html#license-and-citation",
    "href": "index.html#license-and-citation",
    "title": "Statistical rethinking 2 with rstan and the tidyverse",
    "section": "License and citation",
    "text": "License and citation\nThis book is licensed under the Creative Commons Zero v1.0 Universal license, the details for which you can about here. In short, you can use my work. Just make sure you give me the appropriate credit the same way you would for any other scholarly resource. Here’s the basic citation information:\n\n@book{kurzStatisticalRethinking2rstan2024,\n  title = {Statistical rethinking 2 with rstan and the tidyverse},\n  author = {Kurz, A. Solomon},\n  year = {2024},\n  month = {aug},\n  edition = {version 0.0.2},\n  url = {https://solomon.quarto.pub/sr2rstan/},\n  doi = {https://doi.org/10.5281/zenodo.13343828}\n}\n\n\n\n\n\nAllaire, J. J., Teague, C., Scheidegger, C., Xie, Y., & Dervieux, C. (2024). Quarto (version 1.2.0). https://doi.org/10.5281/zenodo.5960048\n\n\nKurz, A. S. (2023). Statistical Rethinking with brms, ggplot2, and the tidyverse: Second Edition (version 0.4.0). https://bookdown.org/content/4857/\n\n\nMcElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (Second Edition). CRC Press. https://xcelab.net/rm/statistical-rethinking/\n\n\nR Core Team. (2022). R: A language and environment for statistical computing. R Foundation for Statistical Computing. https://www.R-project.org/\n\n\nStan Development Team. (2024a). RStan: The R interface to Stan. https://mc-stan.org/\n\n\nStan Development Team. (2024b). Stan user’s guide, Version 2.35. https://mc-stan.org/docs/stan-users-guide/\n\n\nWickham, H. (2020). The tidyverse style guide. https://style.tidyverse.org/\n\n\nWickham, H. (2022). tidyverse: Easily install and load the ’tidyverse’. https://CRAN.R-project.org/package=tidyverse\n\n\nWickham, H., Averick, M., Bryan, J., Chang, W., McGowan, L. D., François, R., Grolemund, G., Hayes, A., Henry, L., Hester, J., Kuhn, M., Pedersen, T. L., Miller, E., Bache, S. M., Müller, K., Ooms, J., Robinson, D., Seidel, D. P., Spinu, V., … Yutani, H. (2019). Welcome to the tidyverse. Journal of Open Source Software, 4(43), 1686. https://doi.org/10.21105/joss.01686\n\n\nXie, Y., Allaire, J. J., & Grolemund, G. (2020). R markdown: The definitive guide. Chapman and Hall/CRC. https://bookdown.org/yihui/rmarkdown/"
  },
  {
    "objectID": "01.html#session-info",
    "href": "01.html#session-info",
    "title": "1  The Golem of Prague",
    "section": "Session info",
    "text": "Session info\nAt the end of every chapter, I use the sessionInfo() function to help make my results more reproducible.\n\nsessionInfo()\n\nR version 4.4.0 (2024-04-24)\nPlatform: aarch64-apple-darwin20\nRunning under: macOS Ventura 13.4\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: America/Chicago\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] assertthat_0.2.1  digest_0.6.35     R6_2.5.1          fastmap_1.1.1    \n [5] xfun_0.43         magrittr_2.0.3    glue_1.7.0        stringr_1.5.1    \n [9] knitr_1.46        htmltools_0.5.8.1 rmarkdown_2.26    lifecycle_1.0.4  \n[13] cli_3.6.3         vctrs_0.6.5       compiler_4.4.0    httr_1.4.7       \n[17] vembedr_0.1.5     rstudioapi_0.16.0 tools_4.4.0       curl_5.2.1       \n[21] evaluate_0.23     yaml_2.3.8        rlang_1.1.4       jsonlite_1.8.8   \n[25] htmlwidgets_1.6.4 stringi_1.8.4"
  },
  {
    "objectID": "01.html#comments",
    "href": "01.html#comments",
    "title": "1  The Golem of Prague",
    "section": "Comments",
    "text": "Comments"
  },
  {
    "objectID": "02.html#the-garden-of-forking-data",
    "href": "02.html#the-garden-of-forking-data",
    "title": "2  Small Worlds and Large Worlds",
    "section": "2.1 The garden of forking data",
    "text": "2.1 The garden of forking data\n\n2.1.1 Counting possibilities.\n\n2.1.1.1 Rethinking: Justification.\n\n\n\n2.1.2 Combining other information.\n\n2.1.2.1 Rethinking: Original ignorance.\n\n\n\n2.1.3 From counts to probability.\n\n2.1.3.1 Rethinking: Randomization."
  },
  {
    "objectID": "02.html#building-a-model",
    "href": "02.html#building-a-model",
    "title": "2  Small Worlds and Large Worlds",
    "section": "2.2 Building a model",
    "text": "2.2 Building a model\nWe might save our globe-tossing data in a tibble.\n\ntoss_vector &lt;- c(\"w\", \"l\", \"w\", \"w\", \"w\", \"l\", \"w\", \"l\", \"w\")\n\n(d &lt;- tibble(toss = toss_vector))\n\n# A tibble: 9 × 1\n  toss \n  &lt;chr&gt;\n1 w    \n2 l    \n3 w    \n4 w    \n5 w    \n6 l    \n7 w    \n8 l    \n9 w    \n\n\n\n2.2.1 A data story.\n\n2.2.1.1 Rethinking: The value of storytelling.\n\n\n\n2.2.2 Bayesian updating.\nHere we’ll add the cumulative number of trials, n_trials, and the cumulative number of successes, n_successes (i.e., toss == \"w\"), to the data.\n\nd &lt;- d |&gt;  \n  mutate(n_trials  = 1:9,\n         n_success = cumsum(toss == \"w\"))\n\n# What?\nprint(d)\n\n# A tibble: 9 × 3\n  toss  n_trials n_success\n  &lt;chr&gt;    &lt;int&gt;     &lt;int&gt;\n1 w            1         1\n2 l            2         1\n3 w            3         2\n4 w            4         3\n5 w            5         4\n6 l            6         4\n7 w            7         5\n8 l            8         5\n9 w            9         6\n\n\nMake Figure 2.5.\n\nsequence_length &lt;- 50\n\nd &lt;- d |&gt; \n  expand_grid(p_water = seq(from = 0, to = 1, length.out = sequence_length)) |&gt;\n  group_by(p_water) |&gt; \n  mutate(lagged_n_trials  = lag(n_trials, n = 1, default = 0),\n         lagged_n_success = lag(n_success, n = 1, default = 0)) |&gt; \n  ungroup() |&gt; \n  mutate(prior = ifelse(n_trials == 1, 0.5,\n                        dbinom(x = lagged_n_success, \n                               size = lagged_n_trials, \n                               prob = p_water)),\n         likelihood = dbinom(x = n_success, \n                             size = n_trials, \n                             prob = p_water)) |&gt; \n  # The next three lines normalize the prior and the likelihood, \n  # putting them both in a probability metric \n  group_by(n_trials) |&gt; \n  mutate(prior = prior / sum(prior),\n         likelihood = likelihood / sum(likelihood)) |&gt; \n  # For annotation\n  mutate(n = str_c(\"italic(n)==\", n_trials),\n         strip = map_chr(.x = n_trials, .f =~ paste(toss_vector[1:.x], collapse = \"\")))\n\n# Plot!\nd |&gt; \n  ggplot(aes(x = p_water)) +\n  geom_line(aes(y = prior), \n            linetype = 2) +\n  geom_text(data = d |&gt;\n              slice(1),\n            aes(y = Inf, label = n),\n            hjust = 0, parse = TRUE, vjust = 1.5) +\n  geom_line(aes(y = likelihood)) +\n  scale_x_continuous(\"proportion water\", breaks = 0:2 / 2) +\n  scale_y_continuous(\"plausibility\", breaks = NULL) +\n  facet_wrap(~ strip, scales = \"free_y\")\n\n\n\n\nIf it wasn’t clear in the code, the dashed curves are normalized prior densities. The solid ones are normalized likelihoods. If you don’t normalize (i.e., divide the density by the sum of the density), their respective heights don’t match up with those in the text. Furthermore, it’s the normalization that makes them directly comparable.\n\n2.2.2.1 Rethinking: Sample size and reliable inference.\n\n\n\n2.2.3 Evaluate.\n\n2.2.3.1 Rethinking: Deflationary statistics."
  },
  {
    "objectID": "02.html#components-of-the-model",
    "href": "02.html#components-of-the-model",
    "title": "2  Small Worlds and Large Worlds",
    "section": "2.3 Components of the model",
    "text": "2.3 Components of the model\n\n2.3.1 Variables.\n\n\n2.3.2 Definitions.\n\n2.3.2.1 Observed variables.\n\n2.3.2.1.1 Overthinking: Names and probability distributions.\n\n\n2.3.2.1.2 Rethinking: A central role for likelihood.\n\n\n\n2.3.2.2 Unobserved variables.\n\n2.3.2.2.1 Overthinking: Prior as a probability distribution\n\n\n2.3.2.2.2 Rethinking: Datum or parameter?\n\n\n2.3.2.2.3 Rethinking: Prior, prior pants on fire.\n\n\n\n\n2.3.3 A model is born.\nWe can now describe our observed variables, \\(w\\) and \\(l\\), with parameters within the binomial likelihood, our shorthand notation for which is\n\\[w \\sim \\operatorname{Binomial}(n, p),\\]\nwhere \\(n = w + l\\). Our binomial likelihood contains a parameter for an unobserved variable, \\(p\\). Parameters in Bayesian models are assigned priors, and we can report our prior for \\(p\\) as\n\\[p \\sim \\operatorname{Uniform}(0, 1),\\]\nwhich expresses the model assumption that the entire range of possible values for \\(p\\), \\([0, 1]\\), are equally plausible."
  },
  {
    "objectID": "02.html#making-the-model-go",
    "href": "02.html#making-the-model-go",
    "title": "2  Small Worlds and Large Worlds",
    "section": "2.4 Making the model go",
    "text": "2.4 Making the model go\n\n2.4.1 Bayes’ theorem.\nWe already know about our values for \\(w\\), \\(l\\), and, by logical necessity, \\(n\\). Bayes’ theorem will allow us to determine the plausibility of various values of \\(p\\), given \\(w\\) and \\(l\\), which we can express formally as \\(\\Pr(p | w, l)\\). Building on some of the earlier equations on page 37, Bayes’ theorem tells us that\n\\[\\Pr(p \\mid w, l) = \\frac{\\Pr(w, l \\mid p) \\Pr(p)}{\\Pr(w, l)}.\\]\n\nAnd this is Bayes’ theorem. It says that the probability of any particular value of \\(p\\), considering the data, is equal to the product of the relative plausibility of the data, conditional on \\(p\\), and the prior plausibility of \\(p\\), divided by this thing \\(\\Pr(W, L)\\), which I’ll call the average probability of the data. (p. 37, emphasis in the original)\n\nWe can express this in words as\n\\[\\text{Posterior} = \\frac{\\text{Probability of the data} \\times \\text{Prior}}{\\text{Average probability of the data}}.\\]\nThe average probability of the data is often called the “evidence” or the “average likelihood” and we’ll get a sense of what that means as we go along. “The key lesson is that the posterior is proportional to the product of the prior and the probability of the data” (p. 37). Figure 2.6 will help us see what this means. Here are the preparatory steps for the data.\n\nsequence_length &lt;- 1000\n\nprior_vec &lt;- c(\"flat\", \"stepped\", \"Laplace\")\n\nd &lt;- tibble(probability = seq(from = 0, to = 1, length.out = sequence_length)) |&gt; \n  expand_grid(row = factor(prior_vec, levels = prior_vec)) |&gt; \n  mutate(prior = case_when(\n    row == \"flat\" ~ 0.5,\n    row == \"stepped\" ~ ifelse(probability &lt; 0.5, 0, 1),\n    row == \"Laplace\" ~ exp(-abs(probability - 0.5) / 0.25) / (2 * 0.25)),\n    likelihood = dbinom(x = 6, size = 9, prob = probability)) |&gt; \n  group_by(row) |&gt; \n  mutate(posterior = prior * likelihood / sum(prior * likelihood)) |&gt; \n  pivot_longer(prior:posterior) |&gt;\n  mutate(name = factor(name, levels = c(\"prior\", \"likelihood\", \"posterior\")))\n\nNow make Figure 2.6.\n\n# Left\np1 &lt;- d |&gt; \n  filter(name == \"prior\") |&gt; \n  ggplot(aes(x = probability, y = value)) +\n  geom_line() +\n  theme(strip.text.y = element_blank()) +\n  facet_grid(row ~ name, scales = \"free\")\n\n# Middle\np2 &lt;- d |&gt; \n  filter(name == \"likelihood\") |&gt; \n  ggplot(aes(x = probability, y = value)) +\n  geom_line() +\n  theme(strip.text.y = element_blank()) +\n  facet_grid(row ~ name, scales = \"free\")\n\n# Right\np3 &lt;- d |&gt; \n  filter(name == \"posterior\") |&gt; \n  ggplot(aes(x = probability, y = value)) +\n  geom_line() +\n  facet_grid(row ~ name, scales = \"free\")\n\n# Combine, adjust, and display\n(p1 | p2 | p3) &\n  scale_x_continuous(NULL, breaks = c(0, .5, 1)) &\n  scale_y_continuous(NULL, breaks = NULL)\n\n\n\n\nI’m not sure if it’s the same McElreath used in the text, but the formula I used for the triangle-shaped prior is the Laplace distribution with a location of 0.5 and a dispersion of 0.25.\n\n2.4.1.1 Rethinking: Bayesian data analysis isn’t about Bayes’ theorem.\n\n\n\n2.4.2 Motors.\n\n\n2.4.3 Grid approximation.\nContinuing on with our globe-tossing example,\n\nat any particular value of a parameter, \\(p'\\) , it’s a simple matter to compute the posterior probability: just multiply the prior probability of \\(p'\\) by the likelihood at \\(p'\\). Repeating this procedure for each value in the grid generates an approximate picture of the exact posterior distribution. This procedure is called grid approximation. (pp. 39–40, emphasis in the original)\n\nWe just employed grid approximation over the last figure. To get nice smooth lines, we computed the posterior over 1,000 evenly-spaced points on the probability space. Here we’ll prepare for Figure 2.7 with 20.\n\nd &lt;- tibble(p_grid = seq(from = 0, to = 1, length.out = 20),      # Define a grid\n            prior  = 1) |&gt;                                        # Define the prior\n  mutate(likelihood = dbinom(x = 6, size = 9, prob = p_grid)) |&gt;  # Compute the likelihood at each grid point\n  mutate(unstd_posterior = likelihood * prior) |&gt;                 # Compute the product of likelihood and prior\n  mutate(posterior = unstd_posterior / sum(unstd_posterior))      # Normalize the posterior so it sums to 1\n\n# What?\nhead(d)\n\n# A tibble: 6 × 5\n  p_grid prior likelihood unstd_posterior   posterior\n   &lt;dbl&gt; &lt;dbl&gt;      &lt;dbl&gt;           &lt;dbl&gt;       &lt;dbl&gt;\n1 0          1 0               0          0          \n2 0.0526     1 0.00000152      0.00000152 0.000000799\n3 0.105      1 0.0000819       0.0000819  0.0000431  \n4 0.158      1 0.000777        0.000777   0.000409   \n5 0.211      1 0.00360         0.00360    0.00189    \n6 0.263      1 0.0112          0.0112     0.00587    \n\n\nHere’s the code for the right panel of Figure 2.7.\n\np1 &lt;- d |&gt; \n  ggplot(aes(x = p_grid, y = posterior)) +\n  geom_point() +\n  geom_line() +\n  labs(x = \"probability of water\",\n       y = NULL) +\n  facet_wrap(~ \"20 points\")\n\nNow here’s the code for the left hand panel of Figure 2.7.\n\np2 &lt;- tibble(p_grid = seq(from = 0, to = 1, length.out = 5),\n             prior  = 1) |&gt;\n  mutate(likelihood = dbinom(x = 6, size = 9, prob = p_grid)) |&gt;\n  mutate(unstd_posterior = likelihood * prior) |&gt;\n  mutate(posterior = unstd_posterior / sum(unstd_posterior)) |&gt;\n  \n  ggplot(aes(x = p_grid, y = posterior)) +\n  geom_point() +\n  geom_line() +\n  labs(x = \"probability of water\",\n       y = \"posterior probability\") +\n  facet_wrap(~ \"5 points\")\n\nHere we combine them, entitle, and plot!\n\np2 + p1 + \n  plot_annotation(title = \"More grid points make for smoother approximations\")\n\n\n\n\n\n2.4.3.1 Overthinking: Vectorization.\n\n\n\n2.4.4 Quadratic approximation.\nThough McElreath used the quadratic approximation for the first half of the text, we won’t use it much past this chapter. Here, though, we’ll apply the quadratic approximation to the globe tossing data with the rethinking::quap() function.\n\nglobe.qa &lt;- quap(\n  data = list(w = 6, \n              l = 3),\n  alist(w ~ dbinom(w + l, p),  # Binomial likelihood \n        p ~ dunif(0, 1))       # Uniform prior \n)\n\n# Display summary of quadratic approximation \nprecis(globe.qa, digits = 3)\n\n       mean        sd      5.5%     94.5%\np 0.6666664 0.1571339 0.4155361 0.9177966\n\n\nIn preparation for Figure 2.8, here’s the model with \\(n = 18\\) and \\(n = 36\\).\n\nglobe.qa.18 &lt;- quap(\n  data = list(w = 6 * 2,       # More data with same proportion\n              l = 3 * 2),\n  alist(w ~ dbinom(w + l, p),  # Same likelihood\n        p ~ dunif(0, 1))       # Same prior\n)\n\nglobe.qa.36 &lt;- quap(\n  data = list(w = 6 * 4, \n              l = 3 * 4),\n  alist(w ~ dbinom(w + l, p),\n        p ~ dunif(0, 1))\n)\n\n# Summarize\nprecis(globe.qa.18, digits = 3)\n\n       mean        sd      5.5%     94.5%\np 0.6666662 0.1111104 0.4890903 0.8442422\n\nprecis(globe.qa.36, digits = 3)\n\n       mean         sd      5.5%     94.5%\np 0.6666664 0.07856692 0.5411013 0.7922316\n\n\nNow make Figure 2.8.\n\nn_grid &lt;- 100\n\n# Wrangle\ntibble(w = c(6, 12, 24),\n       n = c(9, 18, 36),\n       s = c(0.157, 0.111, 0.079)) |&gt; \n  expand_grid(p_grid = seq(from = 0, to = 1, length.out = n_grid)) |&gt; \n  mutate(prior = 1,\n         m     = 0.67)  |&gt;\n  mutate(likelihood = dbinom(w, size = n, prob = p_grid)) |&gt;\n  mutate(unstd_grid_posterior = likelihood * prior,\n         unstd_quad_posterior = dnorm(x = p_grid, mean = m, sd = s)) |&gt;\n  group_by(w) |&gt; \n  mutate(grid_posterior = unstd_grid_posterior / sum(unstd_grid_posterior),\n         quad_posterior = unstd_quad_posterior / sum(unstd_quad_posterior),\n         n              = str_c(\"italic(n)==\", n)) |&gt; \n  mutate(n = factor(n, levels = str_c(\"italic(n)==\", 9 * c(1, 2, 4)))) |&gt; \n  \n  # Plot\n  ggplot(aes(x = p_grid)) +\n  geom_line(aes(y = grid_posterior)) +\n  geom_line(aes(y = quad_posterior),\n            color = \"blue\") +\n  labs(x = \"proportion water\",\n       y = \"density\") +\n  facet_wrap(~ n, scales = \"free\", labeller = label_parsed)\n\n\n\n\nThe grid solutions are in black, and the quadratic approximations are in blue.\n\n2.4.4.1 Rethinking: Maximum likelihood estimation.\n\n\n2.4.4.2 Overthinking: The Hessians are coming.\n\n\n\n2.4.5 Markov chain Monte Carlo.\n\nThe most popular [alternative to grid approximation and the quadratic approximation] is Markov chain Monte Carlo (MCMC), which is a family of conditioning engines capable of handling highly complex models. It is fair to say that MCMC is largely responsible for the insurgence of Bayesian data analysis that began in the 1990s. While MCMC is older than the 1990s, affordable computer power is not, so we must also thank the engineers. Much later in the book (Chapter 9), you’ll meet simple and precise examples of MCMC model fitting, aimed at helping you understand the technique. (p. 45, emphasis in the original)\n\nThe rstan package uses a version of MCMC to fit Bayesian models. Since one of the main goals of this project is to highlight rstan, we may as well fit a model right here. This seems like an appropriately named subsection to do so. If you haven’t already installed rstan, you can find instructions here.\nTo avoid issues, we’ll detach() the rethinking package and then load rstan.\n\ndetach(package:rethinking)\nlibrary(rstan)\n\nHere we re-fit the last model from above, the one for which \\(w = 24\\) and \\(n = 36\\).\n\nmodel_code &lt;- '\ndata {\n  int&lt;lower=1&gt; n;                       \n  int&lt;lower=0&gt; w;\n}\nparameters {\n  real&lt;lower=0, upper=1&gt; p;\n}\nmodel {\n  w ~ binomial(n, p);  // Likelihood\n  p ~ beta(1, 1);      // Prior\n}\n'\n\nm2.1 &lt;- stan(\n  data = list(w = 24, n = 36),\n  model_code = model_code)\n\nWe’ll cover the details of this workflow and syntax later. For now, we can display a summary of the results with print().\n\nprint(m2.1)\n\nInference for Stan model: anon_model.\n4 chains, each with iter=2000; warmup=1000; thin=1; \npost-warmup draws per chain=1000, total post-warmup draws=4000.\n\n       mean se_mean   sd   2.5%    25%    50%    75%  97.5% n_eff Rhat\np      0.66    0.00 0.08   0.50   0.61   0.66   0.71   0.80  1474    1\nlp__ -24.94    0.02 0.73 -26.99 -25.12 -24.65 -24.47 -24.41  2039    1\n\nSamples were drawn using NUTS(diag_e) at Wed Jul 31 17:42:32 2024.\nFor each parameter, n_eff is a crude measure of effective sample size,\nand Rhat is the potential scale reduction factor on split chains (at \nconvergence, Rhat=1).\n\n\nThere’s a lot going on in that output, which we’ll start to clarify in Chapter 4. For now, focus on the ‘p’ line, which is the summary for our focal parameter p.\nTo finish up, why not plot the results of our model and compare them with those from quap(), above?\n\nas_draws_df(m2.1) |&gt; \n  ggplot(aes(x = p)) +\n  geom_density(fill = \"black\") +\n  scale_x_continuous(\"proportion water\", limits = 0:1) +\n  facet_wrap(~ \"italic(n)==36\", labeller = label_parsed)\n\n\n\n\nIf you’re still confused, cool. This is just a preview. We’ll start walking through fitting models with brms in Chapter 4 and we’ll learn a lot about regression with the binomial likelihood in Chapter 11.\n\n2.4.5.1 Overthinking: Monte Carlo globe tossing.\nHere’s McElreath’s hand-made Metropolis algorithm for the globe-tossing example.\n\nn_samples &lt;- 1000\np &lt;- rep(NA, times = n_samples)\np[1] &lt;- 0.5\n\nw &lt;- 6\nl &lt;- 3\n\n# To help make the results reproducible\nset.seed(2)\n\nfor (i in 2:n_samples) {\n    p_new &lt;- rnorm(n = 1, mean = p[i - 1], sd = 0.1)\n    if (p_new &lt; 0) p_new &lt;- abs(p_new)\n    if (p_new &gt; 1) p_new &lt;- 2 - p_new\n    q0 &lt;- dbinom(x = w, size = w + l, prob = p[i - 1])\n    q1 &lt;- dbinom(x = w, size = w + l, prob = p_new )\n    p[i] &lt;- ifelse(runif(1) &lt; q1 / q0, p_new, p[i - 1])\n}\n\nThe results are saved in the numeric vector p.\n\nstr(p)\n\n num [1:1000] 0.5 0.5 0.5 0.5 0.513 ...\n\n\nHere we put p into a data frame, and plot like before.\n\ndata.frame(p = p) |&gt; \n  ggplot(aes(x = p)) +\n  geom_density(fill = \"black\") +\n  scale_x_continuous(\"proportion water\", limits = 0:1) +\n  facet_wrap(~ \"italic(n)==9\", labeller = label_parsed)\n\n\n\n\nHand-made samplers are cool and all, but we’ll rely in stan() from here on out."
  },
  {
    "objectID": "02.html#summary",
    "href": "02.html#summary",
    "title": "2  Small Worlds and Large Worlds",
    "section": "2.5 Summary",
    "text": "2.5 Summary"
  },
  {
    "objectID": "02.html#session-info",
    "href": "02.html#session-info",
    "title": "2  Small Worlds and Large Worlds",
    "section": "Session info",
    "text": "Session info\n\nsessionInfo()\n\nR version 4.4.0 (2024-04-24)\nPlatform: aarch64-apple-darwin20\nRunning under: macOS Ventura 13.4\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: America/Chicago\ntzcode source: internal\n\nattached base packages:\n[1] parallel  stats     graphics  grDevices utils     datasets  methods  \n[8] base     \n\nother attached packages:\n [1] rstan_2.32.6       StanHeaders_2.32.7 posterior_1.6.0    cmdstanr_0.8.1    \n [5] patchwork_1.2.0    lubridate_1.9.3    forcats_1.0.0      stringr_1.5.1     \n [9] dplyr_1.1.4        purrr_1.0.2        readr_2.1.5        tidyr_1.3.1       \n[13] tibble_3.2.1       ggplot2_3.5.1      tidyverse_2.0.0   \n\nloaded via a namespace (and not attached):\n [1] gtable_0.3.5         shape_1.4.6.1        tensorA_0.36.2.1    \n [4] QuickJSR_1.1.3       xfun_0.43            htmlwidgets_1.6.4   \n [7] processx_3.8.4       inline_0.3.19        lattice_0.22-6      \n[10] tzdb_0.4.0           vctrs_0.6.5          tools_4.4.0         \n[13] ps_1.7.6             generics_0.1.3       curl_5.2.1          \n[16] stats4_4.4.0         fansi_1.0.6          pkgconfig_2.0.3     \n[19] Matrix_1.7-0         checkmate_2.3.1      distributional_0.4.0\n[22] RcppParallel_5.1.7   lifecycle_1.0.4      compiler_4.4.0      \n[25] farver_2.1.1         munsell_0.5.1        codetools_0.2-20    \n[28] htmltools_0.5.8.1    yaml_2.3.8           pillar_1.9.0        \n[31] MASS_7.3-60.2        rethinking_2.40      abind_1.4-5         \n[34] tidyselect_1.2.1     digest_0.6.35        mvtnorm_1.2-5       \n[37] stringi_1.8.4        labeling_0.4.3       fastmap_1.1.1       \n[40] grid_4.4.0           colorspace_2.1-0     cli_3.6.3           \n[43] magrittr_2.0.3       loo_2.8.0            pkgbuild_1.4.4      \n[46] utf8_1.2.4           withr_3.0.0          scales_1.3.0        \n[49] backports_1.5.0      timechange_0.3.0     rmarkdown_2.26      \n[52] matrixStats_1.3.0    gridExtra_2.3        hms_1.1.3           \n[55] coda_0.19-4.1        evaluate_0.23        knitr_1.46          \n[58] V8_4.4.2             rlang_1.1.4          Rcpp_1.0.12         \n[61] glue_1.7.0           rstudioapi_0.16.0    jsonlite_1.8.8      \n[64] R6_2.5.1"
  },
  {
    "objectID": "02.html#comments",
    "href": "02.html#comments",
    "title": "2  Small Worlds and Large Worlds",
    "section": "Comments",
    "text": "Comments"
  },
  {
    "objectID": "03.html#sampling-from-a-grid-approximate-posterior",
    "href": "03.html#sampling-from-a-grid-approximate-posterior",
    "title": "3  Sampling the Imaginary",
    "section": "3.1 Sampling from a grid-approximate posterior",
    "text": "3.1 Sampling from a grid-approximate posterior"
  },
  {
    "objectID": "03.html#sampling-to-summarize",
    "href": "03.html#sampling-to-summarize",
    "title": "3  Sampling the Imaginary",
    "section": "3.2 Sampling to summarize",
    "text": "3.2 Sampling to summarize\nI’m not going to cover the grid approach McElreath highlighted in this section. But we might take the time to explore some of these analyses with a stan()-based posterior.\nHere we fit a model like m2.1 from the last chapter, but this time based on the simple globe-tossing data of \\(w = 6\\) and \\(n = 9\\). Note how we are now adjusting some of the default settings in the stan() arguments. Notably, our changes to the warmup and iter arguments will give us 100,000 posterior draws, which will help our MCMC results more closely mimic the analytic results in the text.\n\ndata_list &lt;- list(w = as.integer(6), \n                  n = as.integer(9))\n\nmodel_code &lt;- '\ndata {\n  int&lt;lower=1&gt; n;                       \n  int&lt;lower=0&gt; w;\n}\nparameters {\n  real&lt;lower=0, upper=1&gt; p;\n}\nmodel {\n  w ~ binomial(n, p);  // Likelihood\n  p ~ beta(1, 1);      // Prior\n}\n'\n\nm3.1 &lt;- stan(\n  data = data_list,\n  model_code = model_code, \n  warmup = 500, iter = 25500, seed = 3)\n\nCheck the model summary. Note how we can use the probs argument to compute 89% intervals.\n\nprint(m3.1, probs = c(0.055, 0.945))\n\nInference for Stan model: anon_model.\n4 chains, each with iter=25500; warmup=500; thin=1; \npost-warmup draws per chain=25000, total post-warmup draws=1e+05.\n\n      mean se_mean   sd  5.5% 94.5% n_eff Rhat\np     0.64       0 0.14  0.40  0.84 37525    1\nlp__ -7.74       0 0.76 -9.18 -7.21 36724    1\n\nSamples were drawn using NUTS(diag_e) at Wed Jul 31 17:43:32 2024.\nFor each parameter, n_eff is a crude measure of effective sample size,\nand Rhat is the potential scale reduction factor on split chains (at \nconvergence, Rhat=1).\n\n\n\n3.2.1 Intervals of defined boundaries.\nOne of the ways to extract the posterior draws from a stan() model is with the as_draws_df() function from the posterior package. Here we save the results as a data frame called draws.\n\ndraws &lt;- as_draws_df(m3.1)\n\n# What?\nhead(draws)\n\n# A draws_df: 6 iterations, 1 chains, and 2 variables\n     p lp__\n1 0.48 -7.8\n2 0.68 -7.3\n3 0.67 -7.2\n4 0.83 -8.3\n5 0.71 -7.4\n6 0.60 -7.2\n# ... hidden reserved variables {'.chain', '.iteration', '.draw'}\n\n\nWe can compute the proportion of the posterior distribution of p below 0.5 like so.\n\ndraws |&gt; \n  summarise(p_below_0.5 = mean(p &lt; 0.5))\n\n# A tibble: 1 × 1\n  p_below_0.5\n        &lt;dbl&gt;\n1       0.174\n\n\nMuch like in the text (p. 53), the value is about 17%. Here’s how much of posterior probability lies between 0.5 and 0.75.\n\ndraws |&gt; \n  summarise(p_between_0.5_and_0.75 = mean(p &gt; 0.5 & p &lt; 0.75))\n\n# A tibble: 1 × 1\n  p_between_0.5_and_0.75\n                   &lt;dbl&gt;\n1                  0.603\n\n\nAbout 60%.\n\n3.2.1.1 Overthinking: Counting with sum.\n\n\n\n3.2.2 Intervals of defined mass.\nWe can make the full version of Figure 3.2 with our draws object by including the proportion summaries from above, along with similar ones for the lower and middle 80 percentiles as new columns within draws. Then we just wrangle and make a faceted histogram with a conditional fill.\n\npartion_vector &lt;- c(\"italic(p)&lt;0.5\", \"{0.5&lt;italic(p)}&lt;0.75\", \"lower~80*'%'\", \"middle~80*'%'\")\n\ndraws |&gt; \n  mutate(`italic(p)&lt;0.5` = p &lt; 0.5,\n         `{0.5&lt;italic(p)}&lt;0.75` = p &gt; 0.5 & p &lt; 0.75,\n         `lower~80*'%'` = p &lt; quantile(p, probs = 0.8),\n         `middle~80*'%'` = p &gt; quantile(p, probs = 0.1) & p &lt; quantile(p, probs = 0.9)) |&gt; \n  pivot_longer(cols = `italic(p)&lt;0.5`:`middle~80*'%'`) |&gt; \n  mutate(name = factor(name, levels = partion_vector)) |&gt; \n  \n  ggplot(aes(x = p, fill = value)) +\n  geom_histogram(boundary = 0, binwidth = 0.01) +\n  scale_x_continuous(expression(proportion~water~(italic(p))), limits = 0:1) +\n  scale_y_continuous(NULL, breaks = NULL) +\n  scale_fill_viridis_d(end = 0.6, breaks = NULL) +\n  facet_wrap(~ name, labeller = label_parsed)\n\n\n\n\nWe can also compute basic percentile, or quantile, based intervals with the quantile() function. Here are the exact values for our quantile()-based inner 80% interval bounds.\n\ndraws |&gt; \n  summarise(lower = quantile(p, probs = 0.1),\n            upper = quantile(p, probs = 0.9))\n\n# A tibble: 1 × 2\n  lower upper\n  &lt;dbl&gt; &lt;dbl&gt;\n1 0.446 0.812\n\n\nNow fit a model for the smaller data \\(w = 3\\), \\(n = 3\\).\n\nmodel_code &lt;- '\ndata {\n  int&lt;lower=1&gt; n;                       \n  int&lt;lower=0&gt; w;\n}\nparameters {\n  real&lt;lower=0, upper=1&gt; p;\n}\nmodel {\n  w ~ binomial(n, p);  // Likelihood\n  p ~ beta(1, 1);      // Prior\n}\n'\n\nm3.2 &lt;- stan(\n  data = list(w = 3, n = 3),\n  model_code = model_code,\n  warmup = 500, iter = 25500, seed = 3)\n\nCheck the model summary.\n\nprint(m3.2, probs = c(0.055, 0.945))\n\nInference for Stan model: anon_model.\n4 chains, each with iter=25500; warmup=500; thin=1; \npost-warmup draws per chain=25000, total post-warmup draws=1e+05.\n\n      mean se_mean   sd  5.5% 94.5% n_eff Rhat\np     0.80    0.00 0.16  0.48  0.99 34839    1\nlp__ -3.09    0.01 0.82 -4.65 -2.50 26387    1\n\nSamples were drawn using NUTS(diag_e) at Wed Jul 31 17:44:14 2024.\nFor each parameter, n_eff is a crude measure of effective sample size,\nand Rhat is the potential scale reduction factor on split chains (at \nconvergence, Rhat=1).\n\n\nExtract the posterior draws, and save them as draws.\n\ndraws &lt;- as_draws_df(m3.2)\n\n# What?\nglimpse(draws)\n\nRows: 100,000\nColumns: 5\n$ p          &lt;dbl&gt; 0.9615547, 0.9441528, 0.8024310, 0.5713889, 0.8707930, 0.89…\n$ lp__       &lt;dbl&gt; -3.415334, -3.115005, -2.502105, -3.085946, -2.599744, -2.6…\n$ .chain     &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n$ .iteration &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, …\n$ .draw      &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, …\n\n\nThough it’s easy to compute percentile-based intervals with base-R quantile(), it not so easy to compute HDIs that way. But we can with the various convenience functions from the tidybayes package. If all we want are the 50% HDI’s for p, we can use the hdi() function. Unless the HDI is multimodal, hdi() will return a 1X2 numeric matrix. Here we’ll save that matrix as p_hdi.\n\np_hdi &lt;- hdi(draws$p, .width = 0.5)\n\n# What?\nprint(p_hdi)\n\n          [,1]      [,2]\n[1,] 0.8400446 0.9999816\n\n\nHere’s how we can use that hdi() information to make Figure 3.3.\n\ndraws |&gt; \n  mutate(pi = p &gt; quantile(p, probs = 0.25) & p &lt; quantile(p, probs = 0.75),\n         hdi = p &gt; p_hdi[1] & p &lt; p_hdi[2]) |&gt; \n  pivot_longer(cols = pi:hdi) |&gt; \n  mutate(interval = factor(name, \n                           levels = c(\"pi\", \"hdi\"),\n                           labels = c(\"50% Percentile Interval\", \"50% HPDI\"))) |&gt; \n  \n  ggplot(aes(x = p, fill = value)) +\n  geom_histogram(boundary = 0, binwidth = 0.01) +\n  scale_x_continuous(expression(proportion~water~(italic(p))), limits = 0:1) +\n  scale_y_continuous(NULL, breaks = NULL) +\n  scale_fill_viridis_d(end = 0.6, breaks = NULL) +\n  facet_wrap(~ interval)\n\n\n\n\n\n3.2.2.1 Rethinking: What do compatibility intervals mean?\n\n\n\n3.2.3 Point estimates.\nWe can compute the mean or medians for a stan()-based posterior with the typical mean() and median() functions. Though there is a base-R function called mode(), it returns the ‘storage mode’ of an object, which is not the kind of mode we often think of in statistics. We do, however, have the tidybayes::Mode() function for that purpose. Here are those three values for p from m3.2.\n\npoint_estimates &lt;- draws |&gt; \n  summarise(mean = mean(p),\n            median = median(p),\n            mode = Mode(p)) |&gt; \n  pivot_longer(everything(),\n               names_to = \"point\",\n               values_to = \"estimate\")\n\npoint_estimates\n\n# A tibble: 3 × 2\n  point  estimate\n  &lt;chr&gt;     &lt;dbl&gt;\n1 mean      0.799\n2 median    0.840\n3 mode      0.995\n\n\nHere they are in a plot like the left panel of Figure 3.4.\n\ndraws |&gt; \n  ggplot(aes(x = p)) +\n  geom_histogram(boundary = 0, binwidth = 0.01) +\n  geom_vline(data = point_estimates,\n             aes(xintercept = estimate, color = point)) +\n  scale_x_continuous(expression(proportion~water~(italic(p))), limits = 0:1) +\n  scale_y_continuous(NULL, breaks = NULL) +\n  scale_color_viridis_d(NULL)"
  },
  {
    "objectID": "03.html#sampling-to-simulate-prediction",
    "href": "03.html#sampling-to-simulate-prediction",
    "title": "3  Sampling the Imaginary",
    "section": "3.3 Sampling to simulate prediction",
    "text": "3.3 Sampling to simulate prediction\n\n3.3.1 Dummy data.\n\n3.3.1.1 Rethinking: Sampling distributions.\n\n\n\n3.3.2 Model checking.\n\n3.3.2.1 Did the software work?\n\n\n3.3.2.2 Is the model adequate?\nWe can make a version of Figure 3.6 using the stan() model m3.1. But it’s going to take a few steps, some of which will include nerdy little side quests.\nTo start of with how we might plot an HMC-derived posterior density like McElreath showed at the top of the figure, compare these two histograms for the posterior of p from m3.1.\n\n# Left\np1 &lt;- as_draws_df(m3.1) |&gt; \n  ggplot(aes(x = p)) +\n  geom_histogram(boundary = 0, binwidth = 0.01)\n\n# Save the breaks as a vector\np_breaks &lt;- seq(from = 0, to = 1, by = 0.01)\n\n# Right\np2 &lt;- as_draws_df(m3.1) |&gt; \n  mutate(bin = cut(p, breaks = p_breaks)) |&gt; \n  \n  ggplot(aes(x = bin)) +\n  geom_bar() +\n  theme(axis.text.x = element_text(angle = 90, size = 5))\n\n# Combine\np1 | p2\n\n\n\n\nThe left histogram is made with the usual geom_histogram() code, with adjustments to the boundary and binwidth arguments. The histogram on the right was made with geom_bar(), which we might usually use to make bar charts. In our data-wrangling code, we used the base-R cut() function to discretize the HMC draws for p into bins. We defined those bins using the breaks argument, into which we inserted our p_breaks sequence. Note how that sequence of breaks via cut() produced the exact same bins as geom_histogram() with our custom boundary and binwidth settings.\nThe reason we’d go through all this extra labor with cut() is because we can use those bins to compute the counts for the bins containing the nine example parameter values McElreath showcased with his vertical lines. Here are those counts.\n\n# To simplify the next line\nline_seq &lt;- 1:9 / 10\n\n# Define the labels for the bins containing our `p` values of interest\nline_label &lt;- str_c(\"(\", line_seq, \",\", line_seq + 0.01, \"]\")\n\nd_bin_count &lt;- as_draws_df(m3.1) |&gt; \n  mutate(bin = cut(p, breaks = p_breaks)) |&gt; \n  count(bin, .drop = FALSE) |&gt; \n  filter(bin %in% line_label) |&gt; \n  # Extract the values defining the left-limit of the `bin`s\n  mutate(p = str_sub(bin, start = 2, end = 4) |&gt; \n           as.double())\n\n# What?\nprint(d_bin_count)\n\n# A tibble: 9 × 3\n  bin            n     p\n  &lt;fct&gt;      &lt;int&gt; &lt;dbl&gt;\n1 (0.1,0.11]     0   0.1\n2 (0.2,0.21]    43   0.2\n3 (0.3,0.31]   235   0.3\n4 (0.4,0.41]   790   0.4\n5 (0.5,0.51]  1598   0.5\n6 (0.6,0.61]  2463   0.6\n7 (0.7,0.71]  2616   0.7\n8 (0.8,0.81]  1762   0.8\n9 (0.9,0.91]   417   0.9\n\n\nWe will come back and use this d_bin_count data frame in a bit. For now, here we use the line_label vector to help mark off the bins of interest in the histogram for our version of the top panel of Figure 3.6.\n\np1 &lt;- as_draws_df(m3.1) |&gt; \n  mutate(bin = cut(p, breaks = p_breaks)) |&gt; \n  mutate(line = bin %in% line_label) |&gt; \n  \n  ggplot(aes(x = p)) +\n  geom_histogram(aes(fill = line),\n                 boundary = 0, binwidth = 0.01) +\n  scale_x_continuous(\"probability of water\", breaks = 0:2 / 2, limits = 0:1) +\n  scale_y_continuous(NULL, breaks = NULL) +\n  scale_fill_manual(values = c(\"gray65\", \"gray35\"), breaks = NULL) +\n  labs(subtitle = \"Posterior probability\")\n\np1\n\n\n\n\nWe can make the middle panels of Figure 3.6 with a faceted bar chart via geom_col().\n\np2 &lt;- crossing(x = 0:9,\n               p = 1:9 / 10) |&gt; \n  mutate(density = dbinom(x = x, size = 9, prob = p)) |&gt; \n  mutate(p = str_c(\"italic(p)==\", p)) |&gt; \n  \n  ggplot(aes(x = x, y = density)) +\n  geom_col(width = 0.2) +\n  scale_x_continuous(NULL, breaks = NULL) +\n  scale_y_continuous(NULL, breaks = NULL) +\n  labs(subtitle = \"Sampling distributions\") +\n  facet_wrap(~ p, labeller = label_parsed, nrow = 1) +\n  theme(strip.text.x = element_text(margin = margin(0, 0, 0, 0, \"in\")))\n\np2\n\n\n\n\nTo make the basic posterior predictive distribution plot with our m3.1 model, we just pump the p draws into the prob argument of the rbinom() function to compute a column of water counts, which we’ll save as w.\n\nas_draws_df(m3.1) |&gt; \n  mutate(w = rbinom(n = n(), size = 9, prob = p)) |&gt; \n  \n  ggplot(aes(x = w)) +\n  geom_bar(width = 0.2) +\n  labs(subtitle = \"Posterior predictive distribution\")\n\n\n\n\nThe trick, though, is how one might put the subtitle way to the left of the plot. To my mind, the easiest thing is to make two plots. The first will be blank, with just the subtitle. The second will be a cleaned-up version of the bar chart above, but without a subtitle.\n\np3a &lt;- as_draws_df(m3.1) |&gt; \n  ggplot(aes(x = p)) +\n  labs(subtitle = \"Posterior predictive distribution\") +\n  theme(axis.text = element_text(color = \"transparent\"),\n        axis.ticks = element_line(color = \"transparent\"),\n        axis.title = element_text(color = \"transparent\"),\n        panel.background = element_blank())\n\np3b &lt;- as_draws_df(m3.1) |&gt; \n  mutate(w = rbinom(n = n(), size = 9, prob = p)) |&gt; \n  \n  ggplot(aes(x = w)) +\n  geom_bar(width = 0.2) +\n  scale_x_continuous(\"number of water samples\", breaks = 0:3 * 3) +\n  scale_y_continuous(NULL, breaks = NULL, expand = expansion(mult = c(0.05, 0.8)))\n\np3a | p3b\n\n\n\n\nNow we get to another one of the fun parts. Remember those d_bin_count data from above? Here we can use those values to make the angled lines that connect the top and middle panels. One of the tricks, here, is we need to set theme_void() to make the all the elements of the plot, other than the lines, transparent. The lines themselves will be weighted by the n counts from the cut()-made bins. We’ll add arrowheads for a little style.\n\np4 &lt;- d_bin_count|&gt; \n  mutate(x = p,\n         xend = (1:9 / 10) + (-4:4 / 50),\n         y = 0.84, \n         yend = 0.28) |&gt; \n  \n  ggplot(aes(x = x, xend = xend, y = y, yend = yend,\n             linewidth = n)) +\n  geom_segment(arrow = arrow(length = unit(0.05, \"in\")),\n               color = \"gray35\") +\n  scale_linewidth(range = c(1/10, 0.75), breaks = NULL) +\n  coord_cartesian(xlim = 0:1,\n                  ylim = 0:1) +\n  theme_void()\n\np4\n\n\n\n\nNow we follow a similar strategy for the lines connecting the middle and bottom panels.\n\np5 &lt;- d_bin_count |&gt; \n  mutate(x = p + (-4:4 / 50),\n         xend = 0.5 + (-4:4 / 150),\n         y = 0.8, \n         yend = 0.22) |&gt; \n  \n  ggplot(aes(x = x, xend = xend, y = y, yend = yend,\n             linewidth = n)) +\n  geom_segment(arrow = arrow(length = unit(0.05, \"in\")),\n               color = \"gray35\") +\n  scale_linewidth(range = c(1/10, 0.75), breaks = NULL) +\n  coord_cartesian(xlim = 0:1,\n                  ylim = 0:1) +\n  theme_void()\n\np5\n\n\n\n\nHere’s the full version of Figure 3.6.\n\n# Define the `layout` for the panels\nlayout &lt;- c(\n  area(t = 1, b = 4, l = 1, r = 9),   # Posterior probability\n  area(t = 5, b = 6, l = 1, r = 9),   # Sampling distributions\n  area(t = 8, b = 10, l = 1, r = 3),  # `subtitle`\n  area(t = 8, b = 10, l = 4, r = 6),  # Posterior predictive distribution\n  area(t = 4, b = 5, l = 1, r = 9),   # Upper lines\n  area(t = 6, b = 8, l = 1, r = 9)    # Lower lines\n)\n\n# Combine and display\n(p1 + p2 + p3a + p3b + p4 + p5) + \n  plot_layout(design = layout)\n\n\n\n\nIn Figure 3.7, McElreath considered the longest sequence of the sample values. We’ve been using rbinom() with the size argument set to 9 for our simulations. E.g.,\n\nset.seed(3)\n\nrbinom(10, size = 9, prob = 0.6)\n\n [1] 7 4 6 6 5 5 7 6 5 5\n\n\nNotice this collapsed (i.e., aggregated) over the sequences within the individual sets of 9. What we need is to simulate nine individual trials many times over. For example, this\n\nset.seed(3)\n\nrbinom(9, size = 1, prob = .6)\n\n[1] 1 0 1 1 0 0 1 1 1\n\n\nwould be the disaggregated version of just one of the numerals returned by rbinom() when size = 9. So let’s try simulating again with un-aggregated samples.\nWe can use our m3.1 posterior draws of p to simulate disaggregated counts. For each of the draws, we’ll do the n = 9 simulations from rbinom() from within the purrr::map() function, saving the results in a nested column called w_draws. Then we’ll un-nest that column with the unnest() function. Since this is a substantial change to the original as_draws_df() output, we’ll save the results as d_w_draws.\n\nset.seed(3)\n\nd_w_draws &lt;- as_draws_df(m3.1) |&gt; \n  select(.draw, p) |&gt; \n  mutate(w_draws = purrr::map(.x = p, .f = rbinom, n = 9, size = 1)) |&gt; \n  unnest(w_draws)\n\n# What?\nhead(d_w_draws, n = 10)\n\n# A tibble: 10 × 3\n   .draw     p w_draws\n   &lt;int&gt; &lt;dbl&gt;   &lt;int&gt;\n 1     1 0.479       0\n 2     1 0.479       1\n 3     1 0.479       0\n 4     1 0.479       0\n 5     1 0.479       1\n 6     1 0.479       1\n 7     1 0.479       0\n 8     1 0.479       0\n 9     1 0.479       1\n10     2 0.677       1\n\n\nNow each of the original levels of .draw has nine rows, on for each of the nine w_draws values.\nNext we count the longest sequences. The base-R rle() function will help with that. Consider McElreath’s sequence of tosses.\n\ntosses &lt;- c(\"w\", \"l\", \"w\", \"w\", \"w\", \"l\", \"w\", \"l\", \"w\")\n\nYou can plug that into rle().\n\nrle(tosses)\n\nRun Length Encoding\n  lengths: int [1:7] 1 1 3 1 1 1 1\n  values : chr [1:7] \"w\" \"l\" \"w\" \"l\" \"w\" \"l\" \"w\"\n\n\nFor our purposes, we’re interested in the lengths portion of the output. That tells us the length of each sequences of the same value. The 3 corresponds to our run of three w values. The max() function will help us confirm it’s the largest value.\n\nrle(tosses)$lengths %&gt;% max()\n\n[1] 3\n\n\nNow let’s apply our method to the data and plot.\n\np1 &lt;- d_w_draws |&gt; \n  group_by(.draw) |&gt; \n  summarise(longest_run_length = rle(w_draws)$lengths %&gt;% max()) |&gt; \n  \n  ggplot(aes(x = longest_run_length)) +\n  geom_bar(aes(fill = longest_run_length == 3)) +\n  scale_fill_viridis_d(option = \"D\", end = .9, breaks = NULL) +\n  scale_x_continuous(\"longest run length\", breaks = 1:4 * 2) +\n  scale_y_continuous(\"frequency\", breaks = 0:2 * 1e4, limits = c(0, 3e4))\n\np1\n\n\n\n\nLet’s look at rle() again.\n\nrle(tosses)\n\nRun Length Encoding\n  lengths: int [1:7] 1 1 3 1 1 1 1\n  values : chr [1:7] \"w\" \"l\" \"w\" \"l\" \"w\" \"l\" \"w\"\n\n\nWe can use the length of the lengths vector (i.e., 7 in this example) as the numbers of switches from, in this case, “w” and “l”.\n\nrle(tosses)$lengths %&gt;% length()\n\n[1] 7\n\n\nWith that new trick, we’re ready to make the right panel of Figure 3.7.\n\np2 &lt;- d_w_draws |&gt; \n  group_by(.draw) |&gt; \n  summarise(longest_run_length = rle(w_draws)$lengths %&gt;% length()) |&gt; \n  \n  ggplot(aes(x = longest_run_length)) +\n  geom_bar(aes(fill = longest_run_length == 3)) +\n  scale_x_continuous(\"number of switches\", breaks = 0:4 * 2) +\n  scale_fill_viridis_d(option = \"D\", end = 0.9, breaks = NULL) +\n  scale_y_continuous(NULL, breaks = NULL, limits = c(0, 3e4))\n\n# Combine both panels to make the full figure\np1 | p2\n\n\n\n\n\n\n3.3.2.3 Rethinking: What does more extreme mean?"
  },
  {
    "objectID": "03.html#summary",
    "href": "03.html#summary",
    "title": "3  Sampling the Imaginary",
    "section": "3.4 Summary",
    "text": "3.4 Summary"
  },
  {
    "objectID": "03.html#session-info",
    "href": "03.html#session-info",
    "title": "3  Sampling the Imaginary",
    "section": "Session info",
    "text": "Session info\n\nsessionInfo()\n\nR version 4.4.0 (2024-04-24)\nPlatform: aarch64-apple-darwin20\nRunning under: macOS Ventura 13.4\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: America/Chicago\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n [1] posterior_1.6.0    rstan_2.32.6       StanHeaders_2.32.7 tidybayes_3.0.6   \n [5] patchwork_1.2.0    lubridate_1.9.3    forcats_1.0.0      stringr_1.5.1     \n [9] dplyr_1.1.4        purrr_1.0.2        readr_2.1.5        tidyr_1.3.1       \n[13] tibble_3.2.1       ggplot2_3.5.1      tidyverse_2.0.0   \n\nloaded via a namespace (and not attached):\n [1] gtable_0.3.5         tensorA_0.36.2.1     xfun_0.43           \n [4] QuickJSR_1.1.3       htmlwidgets_1.6.4    inline_0.3.19       \n [7] lattice_0.22-6       tzdb_0.4.0           vctrs_0.6.5         \n[10] tools_4.4.0          generics_0.1.3       curl_5.2.1          \n[13] stats4_4.4.0         parallel_4.4.0       fansi_1.0.6         \n[16] pkgconfig_2.0.3      Matrix_1.7-0         checkmate_2.3.1     \n[19] distributional_0.4.0 RcppParallel_5.1.7   lifecycle_1.0.4     \n[22] farver_2.1.1         compiler_4.4.0       munsell_0.5.1       \n[25] codetools_0.2-20     htmltools_0.5.8.1    yaml_2.3.8          \n[28] pillar_1.9.0         arrayhelpers_1.1-0   abind_1.4-5         \n[31] tidyselect_1.2.1     digest_0.6.35        svUnit_1.0.6        \n[34] stringi_1.8.4        labeling_0.4.3       fastmap_1.1.1       \n[37] grid_4.4.0           colorspace_2.1-0     cli_3.6.3           \n[40] magrittr_2.0.3       loo_2.8.0            pkgbuild_1.4.4      \n[43] utf8_1.2.4           withr_3.0.0          scales_1.3.0        \n[46] backports_1.5.0      timechange_0.3.0     rmarkdown_2.26      \n[49] matrixStats_1.3.0    gridExtra_2.3        hms_1.1.3           \n[52] coda_0.19-4.1        evaluate_0.23        knitr_1.46          \n[55] V8_4.4.2             ggdist_3.3.2         viridisLite_0.4.2   \n[58] rlang_1.1.4          Rcpp_1.0.12          glue_1.7.0          \n[61] rstudioapi_0.16.0    jsonlite_1.8.8       R6_2.5.1"
  },
  {
    "objectID": "03.html#comments",
    "href": "03.html#comments",
    "title": "3  Sampling the Imaginary",
    "section": "Comments",
    "text": "Comments"
  },
  {
    "objectID": "04.html#why-normal-distributions-are-normal",
    "href": "04.html#why-normal-distributions-are-normal",
    "title": "4  Geocentric Models",
    "section": "4.1 Why normal distributions are normal",
    "text": "4.1 Why normal distributions are normal\n\n4.1.1 Normal by addition.\n\n\n4.1.2 Normal by multiplication.\n\n\n4.1.3 Normal by log-multiplication.\n\n\n4.1.4 Using Gaussian distributions.\n\n4.1.4.1 Rethinking: Heavy tails.\n\n\n4.1.4.2 Overthinking: Gaussian distribution."
  },
  {
    "objectID": "04.html#a-language-for-describing-models",
    "href": "04.html#a-language-for-describing-models",
    "title": "4  Geocentric Models",
    "section": "4.2 A language for describing models",
    "text": "4.2 A language for describing models\n\n4.2.1 Re-describing the globe tossing model.\n\n4.2.1.1 Overthinking: From model definition to Bayes’ theorem.\nWe can use grid approximation to work through our globe-tossing model.\n\n# How many `p_grid` points would you like?\nn_points &lt;- 100\n\nd &lt;- tibble(\n  p_grid = seq(from = 0, to = 1, length.out = n_points),\n  w = 6, \n  n = 9) |&gt; \n  mutate(prior = dunif(x = p_grid, min = 0, max = 1),\n         likelihood = dbinom(x = w, size = n, prob = p_grid)) |&gt; \n  mutate(posterior = likelihood * prior / sum(likelihood * prior))\n\n# What?\nhead(d)\n\n# A tibble: 6 × 6\n  p_grid     w     n prior likelihood posterior\n   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;      &lt;dbl&gt;     &lt;dbl&gt;\n1 0          6     9     1   0         0       \n2 0.0101     6     9     1   8.65e-11  8.74e-12\n3 0.0202     6     9     1   5.37e- 9  5.43e-10\n4 0.0303     6     9     1   5.93e- 8  5.99e- 9\n5 0.0404     6     9     1   3.23e- 7  3.26e- 8\n6 0.0505     6     9     1   1.19e- 6  1.21e- 7\n\n\nIn case you were curious, here’s what they look like.\n\nd |&gt; \n  pivot_longer(prior:posterior) |&gt; \n  mutate(name = factor(name, levels = c(\"prior\", \"likelihood\", \"posterior\"))) |&gt; \n  \n  ggplot(aes(x = p_grid, y = value, fill = name)) +\n  geom_area() +\n  scale_y_continuous(NULL, breaks = NULL) +\n  scale_fill_manual(values = c(\"blue\", \"red\", \"purple\"), breaks = NULL) +\n  xlab(\"probability grid\") +\n  facet_wrap(~ name, scales = \"free\")"
  },
  {
    "objectID": "04.html#a-gaussian-model-of-height",
    "href": "04.html#a-gaussian-model-of-height",
    "title": "4  Geocentric Models",
    "section": "4.3 A Gaussian model of height",
    "text": "4.3 A Gaussian model of height\n\n4.3.1 The data.\nLoad the Howell1 data (Howell, 2001, 2010).\n\ndata(Howell1, package = \"rethinking\")\nd &lt;- Howell1\nrm(Howell1)\nstr(d)\n\n'data.frame':   544 obs. of  4 variables:\n $ height: num  152 140 137 157 145 ...\n $ weight: num  47.8 36.5 31.9 53 41.3 ...\n $ age   : num  63 63 65 41 51 35 32 27 19 54 ...\n $ male  : int  1 0 0 1 0 1 0 1 0 1 ...\n\n\nI’m not aware of a precis() function for numeric and graphical summaries of variables outside of McElreath’s rethinking package. We can, at least, get some of that information with summary().\n\nsummary(d)\n\n     height           weight            age             male       \n Min.   : 53.98   Min.   : 4.252   Min.   : 0.00   Min.   :0.0000  \n 1st Qu.:125.09   1st Qu.:22.008   1st Qu.:12.00   1st Qu.:0.0000  \n Median :148.59   Median :40.058   Median :27.00   Median :0.0000  \n Mean   :138.26   Mean   :35.611   Mean   :29.34   Mean   :0.4724  \n 3rd Qu.:157.48   3rd Qu.:47.209   3rd Qu.:43.00   3rd Qu.:1.0000  \n Max.   :179.07   Max.   :62.993   Max.   :88.00   Max.   :1.0000  \n\n\nWe might make the histograms like this.\n\nd |&gt; \n  pivot_longer(everything()) |&gt; \n  mutate(name = factor(name, levels = c(\"height\", \"weight\", \"age\", \"male\"))) |&gt; \n  \n  ggplot(aes(x = value)) +\n  geom_histogram(bins = 10) +\n  facet_wrap(~ name, scales = \"free\", ncol = 1)\n\n\n\n\nIf you’re curious, McElreath made those tiny histograms with help from Wickham’s histospark() function. Here’s the code.\n\nsparks &lt;- c(\"\\u2581\", \"\\u2582\", \"\\u2583\", \"\\u2585\", \"\\u2587\")\n\nhistospark &lt;- function(x, width = 10) {\n  bins &lt;- graphics::hist(x, breaks = width, plot = FALSE)\n\n  factor &lt;- cut(\n    bins$counts / max(bins$counts),\n    breaks = seq(0, 1, length = length(sparks) + 1),\n    labels = sparks,\n    include.lowest = TRUE\n  )\n\n  paste0(factor, collapse = \"\")\n}\n\nHere’s how it works.\n\nhistospark(d$weight)\n\n[1] \"▁▂▃▂▂▂▂▅▇▇▃▂▁\"\n\n\nWe can use the dplyr::filter() function to make an adults-only data frame.\n\nd2 &lt;- d |&gt; \n  filter(age &gt;= 18)\n\nOur reduced d2 does indeed have \\(n = 352\\) cases.\n\nd2 |&gt;  \n  count()\n\n    n\n1 352\n\n\n\n4.3.1.1 Overthinking: Data frames and indexes.\n\n\n\n4.3.2 The model.\nThe likelihood for our model is\n\\[\\text{heights}_i \\sim \\operatorname{Normal}(\\mu, \\sigma),\\]\nwhere the \\(i\\) subscript indexes the individual cases in the data. Our two parameters are \\(\\mu\\) and \\(\\sigma\\), which we will estimate using Bayes’ formula. Our prior for \\(\\mu\\) will be\n\\[\\mu \\sim \\operatorname{Normal}(178, 20),\\]\nand our prior for \\(\\sigma\\) will be\n\\[\\sigma \\sim \\operatorname{Uniform}(0, 50).\\]\nHere’s the shape of the prior for \\(\\mu\\), \\(\\mathcal N(178, 20)\\).\n\np1 &lt;- tibble(x = seq(from = 100, to = 250, by = 0.1)) |&gt; \n  mutate(density = dnorm(x = x, mean = 178, sd = 20)) |&gt; \n  \n  ggplot(aes(x = x, y = density)) +\n  geom_line() +\n  scale_x_continuous(breaks = seq(from = 100, to = 250, by = 75)) +\n  ggtitle(\"mu ~ dnorm(178, 20)\")\n\np1\n\n\n\n\nAnd here’s the ggplot2 code for \\(p(\\sigma)\\), a uniform distribution with a minimum value of 0 and a maximum value of 50. We don’t really need the \\(y\\)-axis when looking at the shapes of a density, so we’ll just remove it with scale_y_continuous().\n\np2 &lt;- tibble(x = seq(from = -10, to = 60, by = 0.1)) |&gt; \n  mutate(density = dunif(x = x, min = 0, max = 50)) |&gt; \n  \n  ggplot(aes(x = x, y = density)) +\n  geom_line() +\n  scale_x_continuous(breaks = c(0, 50)) +\n  scale_y_continuous(NULL, breaks = NULL) +\n  ggtitle(\"sigma ~ dunif(0, 50)\")\n\np2\n\n\n\n\nWe can simulate from both priors at once to get a prior probability distribution of heights.\n\nn &lt;- 1e4\n\nset.seed(4)\n\nsim &lt;- tibble(sample_mu    = rnorm(n = n, mean = 178, sd  = 20),\n              sample_sigma = runif(n = n, min = 0, max = 50)) |&gt; \n  mutate(height = rnorm(n = n, mean = sample_mu, sd = sample_sigma))\n  \np3 &lt;- sim|&gt; \n  ggplot(aes(x = height)) +\n  geom_density(fill = \"grey33\") +\n  scale_x_continuous(breaks = c(0, 73, 178, 283)) +\n  scale_y_continuous(NULL, breaks = NULL) +\n  ggtitle(\"height ~ dnorm(mu, sigma)\")\n\np3\n\n\n\n\nIf you look at the \\(x\\)-axis breaks on the plot in McElreath’s lower left panel in Figure 4.3, you’ll notice they’re intentional. To compute the mean and 3 standard deviations above and below, you might do this.\n\nsim |&gt; \n  summarise(lower = mean(height) - sd(height) * 3,\n            mean  = mean(height),\n            upper = mean(height) + sd(height) * 3) |&gt; \n  mutate_all(round, digits = 1)\n\n# A tibble: 1 × 3\n  lower  mean upper\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1  73.9  177.  281.\n\n\nOur values are very close to his, but are off by just a bit due to simulation variation.\nHere’s the work to make the lower right panel of Figure 4.3.\n\n# Simulate\nset.seed(4)\n\nsim &lt;- tibble(sample_mu    = rnorm(n = n, mean = 178, sd = 100),\n              sample_sigma = runif(n = n, min = 0, max = 50)) |&gt; \n  mutate(height = rnorm(n = n, mean = sample_mu, sd = sample_sigma))\n\n# Compute the values we'll use to break on our x axis\nbreaks &lt;- c(mean(sim$height) + c(-3, 0, 3) * sd(sim$height), 0) |&gt; round(digits = 0)\n\n# This is just for aesthetics\ntext &lt;- tibble(\n  height = 272 - 25,\n  y      = 0.0013,\n  label  = \"tallest man\",\n  angle  = 90)\n  \n# Plot\np4 &lt;- sim |&gt; \n  ggplot(aes(x = height)) +\n  geom_density(fill = \"black\", linewidth = 0) +\n  geom_vline(xintercept = 0, color = \"grey92\") +\n  geom_vline(xintercept = 272, color = \"grey92\", linetype = 3) +\n  geom_text(data = text,\n            aes(y = y, label = label, angle = angle),\n            color = \"grey92\") +\n  scale_x_continuous(breaks = breaks) +\n  scale_y_continuous(NULL, breaks = NULL) +\n  ggtitle(\"height ~ dnorm(mu, sigma)\\nmu ~ dnorm(178, 100)\")\n\np4\n\n\n\n\nYou may have noticed how we were saving each of the four last plots as p1 through p4. Let’s combine the four to make our version of McElreath’s Figure 4.3.\n\n(p1 + xlab(\"mu\") | p2 + xlab(\"sigma\")) / (p3 | p4)\n\n\n\n\nOn page 84, McElreath said his prior simulation indicated 4% of the heights would be below zero. Here’s how we might determine that percentage for our simulation.\n\nsim |&gt; \n  count(height &lt; 0) |&gt; \n  mutate(percent = 100 * n / sum(n))\n\n# A tibble: 2 × 3\n  `height &lt; 0`     n percent\n  &lt;lgl&gt;        &lt;int&gt;   &lt;dbl&gt;\n1 FALSE         9571   95.7 \n2 TRUE           429    4.29\n\n\nHere’s the break down compared to the tallest man on record, Robert Pershing Wadlow (1918–1940).\n\nsim |&gt; \n  count(height &lt; 272) |&gt; \n  mutate(percent = 100 * n / sum(n))\n\n# A tibble: 2 × 3\n  `height &lt; 272`     n percent\n  &lt;lgl&gt;          &lt;int&gt;   &lt;dbl&gt;\n1 FALSE           1761    17.6\n2 TRUE            8239    82.4\n\n\n\n4.3.2.1 Rethinking: A farewell to epsilon.\n\n\n4.3.2.2 Overthinking: Model definition to Bayes’ theorem again.\n\n\n\n4.3.3 Grid approximation of the posterior distribution.\nThis can be a handy preparatory step before we fit the model with stan().\n\nn &lt;- 200\n\nd_grid &lt;- crossing(\n  mu    = seq(from = 140, to = 160, length.out = n),\n  sigma = seq(from = 4, to = 9, length.out = n))\n\n# What?\nglimpse(d_grid)\n\nRows: 40,000\nColumns: 2\n$ mu    &lt;dbl&gt; 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140,…\n$ sigma &lt;dbl&gt; 4.000000, 4.025126, 4.050251, 4.075377, 4.100503, 4.125628, 4.15…\n\n\nd_grid contains every combination of mu and sigma across their specified values. Instead of base-R sapply(), we’ll do the computations by making a custom function which we’ll then plug into purrr::map2().\n\ngrid_function &lt;- function(mu, sigma) {\n  \n  dnorm(x = d2$height, mean = mu, sd = sigma, log = TRUE) |&gt; \n    sum()\n  \n}\n\nNow we’re ready to complete the tibble.\n\nd_grid &lt;- d_grid |&gt; \n  mutate(log_likelihood = map2(.x = mu, .y = sigma, .f = grid_function)) |&gt;\n  unnest(log_likelihood) |&gt; \n  mutate(prior_mu    = dnorm(x = mu, mean = 178, sd = 20, log = TRUE),\n         prior_sigma = dunif(x = sigma, min = 0, max = 50, log = TRUE)) |&gt; \n  mutate(product = log_likelihood + prior_mu + prior_sigma) |&gt; \n  mutate(probability = exp(product - max(product)))\n\n# What?\nhead(d_grid)\n\n# A tibble: 6 × 7\n     mu sigma log_likelihood prior_mu prior_sigma product probability\n  &lt;dbl&gt; &lt;dbl&gt;          &lt;dbl&gt;    &lt;dbl&gt;       &lt;dbl&gt;   &lt;dbl&gt;       &lt;dbl&gt;\n1   140  4            -3813.    -5.72       -3.91  -3822.           0\n2   140  4.03         -3778.    -5.72       -3.91  -3787.           0\n3   140  4.05         -3743.    -5.72       -3.91  -3753.           0\n4   140  4.08         -3709.    -5.72       -3.91  -3719.           0\n5   140  4.10         -3676.    -5.72       -3.91  -3686.           0\n6   140  4.13         -3644.    -5.72       -3.91  -3653.           0\n\n\nIn the final d_grid, the probability vector contains the posterior probabilities across values of mu and sigma. We can make a contour plot with geom_contour().\n\nd_grid |&gt; \n  ggplot(aes(x = mu, y = sigma, z = probability)) + \n  geom_contour() +\n  labs(x = expression(mu),\n       y = expression(sigma)) +\n  coord_cartesian(xlim = range(d_grid$mu),\n                  ylim = range(d_grid$sigma))\n\n\n\n\nWe’ll make our heat map with geom_raster().\n\nd_grid |&gt; \n  ggplot(aes(x = mu, y = sigma, fill = probability)) + \n  geom_raster(interpolate = TRUE) +\n  scale_fill_viridis_c(option = \"B\") +\n  labs(x = expression(mu),\n       y = expression(sigma))\n\n\n\n\n\n\n4.3.4 Sampling from the posterior.\nWe can use dplyr::sample_n() to sample rows, with replacement, from d_grid.\n\nset.seed(4)\n\nd_grid_samples &lt;- d_grid |&gt; \n  sample_n(size = 1e4, replace = TRUE, weight = probability)\n\nd_grid_samples |&gt; \n  ggplot(aes(x = mu, y = sigma)) + \n  geom_point(size = 0.9, alpha = 1/15) +\n  scale_fill_viridis_c() +\n  labs(x = expression(mu[samples]),\n       y = expression(sigma[samples]))\n\n\n\n\nWe can use pivot_longer() and then facet_wrap() to plot the densities for both mu and sigma at once.\n\nd_grid_samples |&gt; \n  pivot_longer(mu:sigma) |&gt; \n\n  ggplot(aes(x = value)) + \n  geom_density(fill = \"grey33\") +\n  scale_y_continuous(NULL, breaks = NULL) +\n  xlab(NULL) +\n  facet_wrap(~ name, labeller = label_parsed, scales = \"free\")\n\n\n\n\nWe’ll use the tidybayes package to compute their posterior modes and 95% HDIs.\n\nd_grid_samples |&gt; \n  pivot_longer(mu:sigma) |&gt; \n  group_by(name) |&gt; \n  mode_hdi(value)\n\n# A tibble: 2 × 7\n  name   value .lower .upper .width .point .interval\n  &lt;chr&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;    \n1 mu    155.   154.   155.     0.95 mode   hdi      \n2 sigma   7.82   7.19   8.35   0.95 mode   hdi      \n\n\n\n4.3.4.1 Overthinking: Sample size and the normality of \\(\\sigma\\)’s posterior.\nHere’s d3.\n\nset.seed(4)\n(d3 &lt;- sample(d2$height, size = 20))\n\n [1] 147.3200 154.9400 168.9100 156.8450 165.7350 151.7650 165.7350 156.2100\n [9] 144.7800 154.9400 151.1300 147.9550 149.8600 162.5600 161.9250 164.4650\n[17] 160.9852 151.7650 163.8300 149.8600\n\n\nFor our first step using d3, we’ll redefine d_grid.\n\nn &lt;- 200\n\n# Note we've redefined the ranges of `mu` and `sigma`\nd_grid &lt;- crossing(\n  mu    = seq(from = 150, to = 170, length.out = n),\n  sigma = seq(from = 4, to = 20, length.out = n))\n\nSecond, we’ll redefine our custom grid_function() function to operate over the height values of d3.\n\ngrid_function &lt;- function(mu, sigma) {\n  \n  dnorm(d3, mean = mu, sd = sigma, log = TRUE) |&gt; \n    sum()\n  \n}\n\nNow we’ll use the amended grid_function() to make the posterior.\n\nd_grid &lt;- d_grid |&gt; \n  mutate(log_likelihood = map2_dbl(.x = mu, .y = sigma, .f = grid_function)) |&gt; \n  mutate(prior_mu    = dnorm(x = mu, mean = 178, sd = 20, log = TRUE),\n         prior_sigma = dunif(x = sigma, min = 0, max = 50, log = TRUE)) |&gt; \n  mutate(product = log_likelihood + prior_mu + prior_sigma) |&gt; \n  mutate(probability = exp(product - max(product)))\n\nNext we’ll sample_n() and plot.\n\nset.seed(4)\n\nd_grid_samples &lt;- d_grid |&gt;  \n  sample_n(size = 1e4, replace = TRUE, weight = probability)\n\nd_grid_samples |&gt; \n  ggplot(aes(x = mu, y = sigma)) + \n  geom_point(size = 0.9, alpha = 1/15) +\n  labs(x = expression(mu[samples]),\n       y = expression(sigma[samples]))\n\n\n\n\nBehold the updated densities.\n\nd_grid_samples |&gt; \n  pivot_longer(mu:sigma) |&gt; \n\n  ggplot(aes(x = value)) + \n  geom_density(fill = \"grey33\", linewidth = 0) +\n  scale_y_continuous(NULL, breaks = NULL) +\n  xlab(NULL) +\n  facet_wrap(~ name, labeller = label_parsed, scales = \"free\")\n\n\n\n\n\n\n\n4.3.5 Finding the posterior distribution with quap() stan().\nHere we rewrite the statistical model, this time using font color to help differentiate the likelihood from the prior(s).\n\\[\n\\begin{align*}\n\\color{red}{\\text{heights}_i} & \\color{red}\\sim \\color{red}{\\operatorname{Normal}(\\mu, \\sigma)} && \\color{red}{\\text{likelihood}} \\\\\n\\color{blue}\\mu & \\color{blue}\\sim \\color{blue}{\\operatorname{Normal}(178, 20)} && \\color{blue}{\\text{prior}} \\\\\n\\color{blue}\\sigma & \\color{blue}\\sim \\color{blue}{\\operatorname{Uniform}(0, 50)}\n\\end{align*}\n\\]\nFor rstan, first we define the model code, which is a character string specifying the model with a series of blocks. Perhaps the most fundamental of these are the model, parameters, and model blocks. Note that whereas we typically use the # mark to make comments in R code, we use // for comments in rstan model code.\n\nmodel_code &lt;- '\ndata {\n  int&lt;lower=1&gt; n;\n  vector[n] height;\n}\nparameters {\n  real mu;\n  real&lt;lower=0,upper=50&gt; sigma;\n}\nmodel {\n  height ~ normal(mu, sigma);  // Likelihood\n  mu ~ normal(178, 20);        // Priors\n  sigma ~ uniform(0, 50);\n}\n'\n\nNext we use the tidybayes::compose_data() function to convert the data to a list, which is the format expected by rstan.\n\nstan_data &lt;- d2 |&gt;\n  compose_data()\n\n# What?\nstr(stan_data)\n\nList of 5\n $ height: num [1:352(1d)] 152 140 137 157 145 ...\n $ weight: num [1:352(1d)] 47.8 36.5 31.9 53 41.3 ...\n $ age   : num [1:352(1d)] 63 63 65 41 51 35 32 27 19 54 ...\n $ male  : int [1:352(1d)] 1 0 0 1 0 1 0 1 0 1 ...\n $ n     : int 352\n\n\nNote how the compose_data() function automatically added a variable called n, which tells the number of rows in the original data frame. If you look at the model_code above, you’ll see how I used that value when defining the vector of height values.\nNow we fit the model with the stan() function.\n\nm4.1 &lt;- stan(\n  data = stan_data,\n  model_code = model_code,\n  # Default settings\n  chains = 4, iter = 2000, warmup = 1000,\n  # To make it reproducible\n  seed = 4)\n\nHere’s the model summary.\n\nprint(m4.1, probs = c(0.055, 0.945))\n\nInference for Stan model: anon_model.\n4 chains, each with iter=2000; warmup=1000; thin=1; \npost-warmup draws per chain=1000, total post-warmup draws=4000.\n\n         mean se_mean   sd    5.5%   94.5% n_eff Rhat\nmu     154.59    0.01 0.41  153.94  155.25  2711    1\nsigma    7.78    0.01 0.30    7.32    8.26  3292    1\nlp__  -895.75    0.02 0.99 -897.62 -894.80  1726    1\n\nSamples were drawn using NUTS(diag_e) at Wed Jul 31 18:17:42 2024.\nFor each parameter, n_eff is a crude measure of effective sample size,\nand Rhat is the potential scale reduction factor on split chains (at \nconvergence, Rhat=1).\n\n\nHere’s the second model with the stronger prior for \\(\\mu\\).\n\nmodel_code &lt;- '\ndata {\n  int&lt;lower=1&gt; n;\n  vector[n] height;\n}\nparameters {\n  real mu;\n  real&lt;lower=0,upper=50&gt; sigma;\n}\nmodel {\n  height ~ normal(mu, sigma);\n  mu ~ normal(178, 0.1);       // This prior has been updated\n  sigma ~ uniform(0, 50);\n}\n'\n\nm4.2 &lt;- stan(\n  data = stan_data,\n  model_code = model_code,\n  chains = 4, iter = 2000, warmup = 1000,\n  seed = 4)\n\nHere’s the model summary.\n\nprint(m4.2, probs = c(0.055, 0.945))\n\nInference for Stan model: anon_model.\n4 chains, each with iter=2000; warmup=1000; thin=1; \npost-warmup draws per chain=1000, total post-warmup draws=4000.\n\n          mean se_mean   sd     5.5%    94.5% n_eff Rhat\nmu      177.86    0.00 0.10   177.69   178.03  3207    1\nsigma    24.60    0.02 0.94    23.13    26.14  3222    1\nlp__  -1301.64    0.03 1.04 -1303.65 -1300.66  1461    1\n\nSamples were drawn using NUTS(diag_e) at Wed Jul 31 18:18:11 2024.\nFor each parameter, n_eff is a crude measure of effective sample size,\nand Rhat is the potential scale reduction factor on split chains (at \nconvergence, Rhat=1).\n\n\n\n4.3.5.1 Overthinking: Start values for quap rstan().\nThe Stan folks generally use the language of initial values, rather than start values. But I believe these are basically the same thing. Within the stan() function, you can set these with the init argument, about which you can learn more by executing ?stan in your console, or perhaps looking through this thread on the Stan forums.\n\n\n\n4.3.6 Sampling from a quap() stan().\nThe vcov() function does not work for models fit with stan().\n\nvcov(m4.1)  # This returns an error message\n\nHowever, if you really wanted this information, you could get it after putting the HMC chains in a data frame. We do that with the as_draws_df() function from the posterior package.\n\ndraws &lt;- as_draws_df(m4.1)\n\nhead(draws)\n\n# A draws_df: 6 iterations, 1 chains, and 3 variables\n   mu sigma lp__\n1 155   7.5 -896\n2 155   7.0 -899\n3 154   7.6 -895\n4 154   8.0 -895\n5 155   7.6 -895\n6 155   7.4 -895\n# ... hidden reserved variables {'.chain', '.iteration', '.draw'}\n\n\nWhen McElreath extracts his posterior draws in the text, he generally calls the object post. Since several of the related functions from the posterior and tidybayes packages tend to use the language of draws, we’ll do the same and call our posterior draws objects draws.\nNow select() the columns containing the draws from the desired parameters and feed them into the cov() function, which will return a variance/covariance matrix.\n\ndraws |&gt; \n  select(mu:sigma) |&gt; \n  cov()\n\n               mu       sigma\nmu     0.16783765 -0.00255372\nsigma -0.00255372  0.08895420\n\n\nHere are just the variances, and then the correlation matrix.\n\n# Variances\ndraws |&gt; \n  select(mu:sigma) |&gt; \n  cov() |&gt; \n  diag()\n\n       mu     sigma \n0.1678377 0.0889542 \n\n# Correlation\ndraws |&gt; \n  select(mu:sigma) |&gt; \n  cor()\n\n               mu       sigma\nmu     1.00000000 -0.02089996\nsigma -0.02089996  1.00000000\n\n\nWith our draws &lt;- as_draws_df(m4.1) code from a few lines above, we’ve already produced the rstan version of what McElreath achieved with extract.samples() on page 90. However, what happened under the hood was different. Whereas rethinking used the mvnorm() function from the MASS package, with posterior::as_draws_df() we extracted the iterations of the HMC chains and put them in a data frame.\nThe summary() function doesn’t work for as_draws_df() objects quite the way precis() does for posterior data frames from the rethinking package. Behold the results.\n\ndraws |&gt; \n  select(mu:sigma) |&gt; \n  summary()\n\n       mu            sigma      \n Min.   :153.4   Min.   :6.841  \n 1st Qu.:154.3   1st Qu.:7.565  \n Median :154.6   Median :7.765  \n Mean   :154.6   Mean   :7.776  \n 3rd Qu.:154.9   3rd Qu.:7.967  \n Max.   :156.2   Max.   :8.891  \n\n\nHowever, the summarise_draws() function provides a nice summary for columns from as_draws_df().\n\ndraws |&gt; \n  select(mu:sigma) |&gt; \n  summarise_draws() |&gt; \n  mutate_if(is.double, round, digits = 2)\n\n# A tibble: 2 × 10\n  variable   mean median    sd   mad    q5    q95  rhat ess_bulk ess_tail\n  &lt;chr&gt;     &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1 mu       155.   155.    0.41  0.41 154.  155.       1    2750.    2433.\n2 sigma      7.78   7.77  0.3   0.3    7.3   8.27     1    3328.    2087.\n\n\nThe function comes with three handy default_*_meaures() helper function, which can help give a more focused output.\n\n# default_summary_measures()\ndraws |&gt; \n  select(mu:sigma) |&gt; \n  summarise_draws(default_summary_measures()) |&gt; \n  mutate_if(is.double, round, digits = 2)\n\n# A tibble: 2 × 7\n  variable   mean median    sd   mad    q5    q95\n  &lt;chr&gt;     &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;\n1 mu       155.   155.    0.41  0.41 154.  155.  \n2 sigma      7.78   7.77  0.3   0.3    7.3   8.27\n\n# default_convergence_measures()\ndraws |&gt; \n  select(mu:sigma) |&gt; \n  summarise_draws(default_convergence_measures()) |&gt; \n  mutate_if(is.double, round, digits = 2)\n\n# A tibble: 2 × 4\n  variable  rhat ess_bulk ess_tail\n  &lt;chr&gt;    &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1 mu           1    2750.    2433.\n2 sigma        1    3328.    2087.\n\n# default_mcse_measures()\ndraws |&gt; \n  select(mu:sigma) |&gt; \n  summarise_draws(default_mcse_measures()) |&gt; \n  mutate_if(is.double, round, digits = 2)\n\n# A tibble: 2 × 6\n  variable mcse_mean mcse_median mcse_sd mcse_q5 mcse_q95\n  &lt;chr&gt;        &lt;dbl&gt;       &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;\n1 mu            0.01        0.01    0.01    0.02     0.02\n2 sigma         0.01        0.01    0.01    0.01     0.01\n\n\nYou can also compute many of these statistics with explicit tidyverse code.\n\ndraws |&gt; \n  pivot_longer(mu:sigma) |&gt; \n  group_by(name) |&gt;\n  summarise(mean = mean(value),\n            sd   = sd(value),\n            `5.5%`  = quantile(value, probs = 0.055),\n            `94.5%` = quantile(value, probs = 0.945)) |&gt;\n  mutate_if(is.numeric, round, digits = 2)\n\n# A tibble: 2 × 5\n  name    mean    sd `5.5%` `94.5%`\n  &lt;chr&gt;  &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;\n1 mu    155.    0.41 154.    155.  \n2 sigma   7.78  0.3    7.32    8.26\n\n\nAnd if you’re willing to drop the posterior \\(\\textit{SD}\\)s, you can use tidybayes::mean_hdi(), too.\n\ndraws |&gt; \n  pivot_longer(mu:sigma) |&gt; \n  group_by(name) |&gt;\n  mean_qi(value)\n\n# A tibble: 2 × 7\n  name   value .lower .upper .width .point .interval\n  &lt;chr&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;    \n1 mu    155.   154.   155.     0.95 mean   qi       \n2 sigma   7.78   7.23   8.42   0.95 mean   qi       \n\n\n\n4.3.6.1 Overthinking: Under the hood with multivariate sampling."
  },
  {
    "objectID": "04.html#linear-prediction",
    "href": "04.html#linear-prediction",
    "title": "4  Geocentric Models",
    "section": "4.4 Linear prediction",
    "text": "4.4 Linear prediction\nHere’s our scatter plot of weight and height.\n\nd2 |&gt; \n  ggplot(aes(x = weight, y = height)) +\n  geom_point(alpha = 1/2, size = 1/2)\n\n\n\n\n\n4.4.0.1 Rethinking: What is “regression”?\n\n\n4.4.1 The linear model strategy.\nLike we did for our first model without a predictor, we’ll use font color to help differentiate between the likelihood and prior(s) of our new univariable model,\n\\[\n\\begin{align*}\n\\color{red}{\\text{height}_i} & \\color{red}\\sim \\color{red}{\\operatorname{Normal}(\\mu_i, \\sigma)} && \\color{red}{\\text{likelihood}} \\\\\n\\color{red}{\\mu_i} & \\color{red}= \\color{red}{\\alpha + \\beta (\\text{weight}_i - \\overline{\\text{weight}})}  && \\color{red}{\\text{\\{the linear model is just a special part of the likelihood\\}} } \\\\\n\\color{blue}\\alpha & \\color{blue}\\sim \\color{blue}{\\operatorname{Normal}(178, 20)} && \\color{blue}{\\text{prior(s)}} \\\\\n\\color{blue}\\beta  & \\color{blue}\\sim \\color{blue}{\\operatorname{Normal}(0, 10)} \\\\\n\\color{blue}\\sigma & \\color{blue}\\sim \\color{blue}{\\operatorname{Uniform}(0, 50)}.\n\\end{align*}\n\\]\n\n4.4.1.1 Probability of the data.\n\n\n4.4.1.2 Linear model.\n\n4.4.1.2.1 Rethinking: Nothing special or natural about linear models.\n\n\n4.4.1.2.2 Overthinking: Units and regression models.\n\n\n\n4.4.1.3 Priors.\nInstead of using a loop to make our data for Figure 4.5, we’ll stay within the tidyverse.\n\n# How many lines would you like?\nn_lines &lt;- 100\n\nset.seed(2971)\n\nlines &lt;- tibble(\n  n = 1:n_lines,\n  a = rnorm(n = n_lines, mean = 178, sd = 20),\n  b = rnorm(n = n_lines, mean = 0, sd = 10)) |&gt; \n  expand_grid(weight = range(d2$weight)) |&gt; \n  mutate(height = a + b * (weight - mean(d2$weight)))\n\n# What?\nhead(lines)\n\n# A tibble: 6 × 5\n      n     a      b weight height\n  &lt;int&gt; &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n1     1  191. -7.06    31.1  289. \n2     1  191. -7.06    63.0   63.5\n3     2  199.  0.839   31.1  187. \n4     2  199.  0.839   63.0  214. \n5     3  202.  3.93    31.1  147. \n6     3  202.  3.93    63.0  272. \n\n\nNow we’ll plot the left panel from Figure 4.5.\n\np1 &lt;- lines |&gt; \n  ggplot(aes(x = weight, y = height, group = n)) +\n  geom_hline(yintercept = c(0, 272), linetype = 2:1, linewidth = 1/3) +\n  geom_line(alpha = 1/10) +\n  coord_cartesian(ylim = c(-100, 400)) +\n  ggtitle(\"b ~ dnorm(0, 10)\")\n\np1\n\n\n\n\nHere’s what \\(\\operatorname{Log-Normal}(0, 1)\\) looks like.\n\nset.seed(4)\n\ntibble(b = rlnorm(n = 1e4, mean = 0, sd = 1)) |&gt; \n  ggplot(aes(x = b)) +\n  geom_density(fill = \"grey92\") +\n  coord_cartesian(xlim = c(0, 5))\n\n\n\n\nHere’s what happens when we compare \\(\\operatorname{Normal}(0, 1)\\) with \\(\\log \\big ( \\operatorname{Log-Normal}(0, 1) \\big)\\).\n\nset.seed(4)\n\ntibble(rnorm           = rnorm(n = 1e5, mean = 0, sd = 1),\n       `log(rlognorm)` = rlnorm(n = 1e5, mean = 0, sd = 1) |&gt; log()) |&gt; \n  pivot_longer(everything()) |&gt; \n\n  ggplot(aes(x = value)) +\n  geom_density(fill = \"grey92\") +\n  coord_cartesian(xlim = c(-3, 3)) +\n  facet_wrap(~ name, nrow = 2)\n\n\n\n\nThe formulas for the actual mean and standard deviation for the log-normal distribution itself are:\n\\[\n\\begin{align*}\n\\text{mean}               & = \\exp \\left (\\mu + \\frac{\\sigma^2}{2} \\right) & \\text{and} \\\\\n\\text{standard deviation} & = \\sqrt{[\\exp(\\sigma ^{2})-1] \\; \\exp(2\\mu +\\sigma ^{2})}.\n\\end{align*}\n\\]\nLet’s try our hand at those formulas and compute the mean and standard deviation for \\(\\operatorname{Log-Normal}(0, 1)\\).\n\nmu    &lt;- 0\nsigma &lt;- 1\n\n# Mean\nexp(mu + (sigma^2) / 2)\n\n[1] 1.648721\n\n# SD\nsqrt((exp(sigma^2) - 1) * exp(2 * mu + sigma^2))\n\n[1] 2.161197\n\n\nLet’s confirm with simulated draws from rlnorm().\n\nset.seed(4)\n\ntibble(x = rlnorm(n = 1e7, mean = 0, sd = 1)) |&gt; \n  summarise(mean = mean(x),\n            sd   = sd(x))\n\n# A tibble: 1 × 2\n   mean    sd\n  &lt;dbl&gt; &lt;dbl&gt;\n1  1.65  2.17\n\n\nBut okay, “so what [do all these complications] earn us? Do the prior predictive simulation again, now with the Log-Normal prior:” (p. 96).\n\n# Make a tibble to annotate the plot\ntext &lt;-\n  tibble(weight = c(34, 43),\n         height = c(0 - 25, 272 + 25),\n         label  = c(\"Embryo\", \"World's tallest person (272 cm)\"))\n\n# Simulate\nset.seed(2971)\n\np2 &lt;- tibble(\n  n = 1:n_lines,\n  a = rnorm(n = n_lines, mean = 178, sd = 20),\n  b = rlnorm(n = n_lines, mean = 0, sd = 1)) |&gt; \n  expand_grid(weight = range(d2$weight)) |&gt; \n  mutate(height = a + b * (weight - mean(d2$weight))) |&gt;\n  \n  # Plot\n  ggplot(aes(x = weight, y = height, group = n)) +\n  geom_hline(yintercept = c(0, 272), linetype = 2:1, linewidth = 1/3) +\n  geom_line(alpha = 1/10) +\n  geom_text(data = text,\n            aes(label = label),\n            size = 3) +\n  coord_cartesian(ylim = c(-100, 400)) +\n  ggtitle(\"log(b) ~ dnorm(0, 1)\")\n\n# Combine both panels\np1 | p2\n\n\n\n\nThus we now have the full Figure 4.5.\n\n4.4.1.3.1 Rethinking: What’s the correct prior?\n\n\n4.4.1.3.2 Rethinking: Prior predictive simulation and \\(p\\)-hacking.\n\n\n\n\n4.4.2 Finding the posterior distribution.\nNow we get ready to actually fit the model\n\\[\n\\begin{align*}\n\\text{height}_i & \\sim \\operatorname{Normal}(\\mu_i, \\sigma) \\\\\n\\mu_i & = \\alpha + \\beta (\\text{weight}_i - \\overline{\\text{weight}}) \\\\\n\\alpha & \\sim \\operatorname{Normal}(178, 20) \\\\\n\\beta  & \\sim \\operatorname{Log-Normal}(0, 1) \\\\\n\\sigma & \\sim \\operatorname{Uniform}(0, 50).\n\\end{align*}\n\\]\nFirst, here’s the updated model_code.\n\nmodel_code &lt;- '\ndata {\n  int&lt;lower=1&gt; n;\n  real xbar;         // New data point\n  vector[n] height;\n  vector[n] weight;\n}\nparameters {\n  real a;\n  real&lt;lower=0&gt; b;\n  real&lt;lower=0,upper=50&gt; sigma;\n}\nmodel {\n  vector[n] mu;\n  mu = a + b * (weight - xbar);  // New model syntax\n  height ~ normal(mu, sigma);\n  a ~ normal(178, 20);\n  b ~ lognormal(0, 1);\n  sigma ~ uniform(0, 50);\n}\n'\n\nNext we need to add the mean of the weight column as a new value in the stan_data data list. We’ll call it xbar. Note how this is just a single value, not a vector.\n\nstan_data$xbar &lt;- mean(stan_data$weight)\n\n# What?\nstr(stan_data)\n\nList of 6\n $ height: num [1:352(1d)] 152 140 137 157 145 ...\n $ weight: num [1:352(1d)] 47.8 36.5 31.9 53 41.3 ...\n $ age   : num [1:352(1d)] 63 63 65 41 51 35 32 27 19 54 ...\n $ male  : int [1:352(1d)] 1 0 0 1 0 1 0 1 0 1 ...\n $ n     : int 352\n $ xbar  : num 45\n\n\nNow we fit the model with stan(), as before.\n\nm4.3 &lt;- stan(\n  data = stan_data,\n  model_code = model_code,\n  seed = 4)\n\nLook at the print() summary.\n\nprint(m4.3, probs = c(0.055, 0.945))\n\nInference for Stan model: anon_model.\n4 chains, each with iter=2000; warmup=1000; thin=1; \npost-warmup draws per chain=1000, total post-warmup draws=4000.\n\n         mean se_mean   sd    5.5%   94.5% n_eff Rhat\na      154.60    0.00 0.27  154.17  155.02  4510    1\nb        0.90    0.00 0.04    0.84    0.97  4079    1\nsigma    5.11    0.00 0.19    4.83    5.43  3751    1\nlp__  -749.09    0.03 1.19 -751.34 -747.82  2180    1\n\nSamples were drawn using NUTS(diag_e) at Wed Jul 31 17:55:47 2024.\nFor each parameter, n_eff is a crude measure of effective sample size,\nand Rhat is the potential scale reduction factor on split chains (at \nconvergence, Rhat=1).\n\n\n\n4.4.2.1 Rethinking: Everything that depends upon parameters has a posterior distribution.\n\n\n4.4.2.2 Overthinking: Logs and exps, oh my.\nWith stan(), you can include exp() and other defined functions right in the model formula.\n\n# Update the model\nmodel_code &lt;- '\ndata {\n  int&lt;lower=1&gt; n;\n  real xbar;\n  vector[n] height;\n  vector[n] weight;\n}\nparameters {\n  real a;\n  real&lt;lower=0&gt; log_b;\n  real&lt;lower=0,upper=50&gt; sigma;\n}\nmodel {\n  vector[n] mu;\n  mu = a + exp(log_b) * (weight - xbar);  // Include `exp()` right in the formula\n  height ~ normal(mu, sigma);\n  a ~ normal(178, 20);\n  log_b ~ normal(0, 1);\n  sigma ~ uniform(0, 50);\n}\n'\n\n# Fit the non-linear model\nm4.3b &lt;- stan(\n  data = stan_data,\n  model_code = model_code,\n  seed = 4)\n\nCheck the summary.\n\nprint(m4.3b, probs = c(0.055, 0.945))\n\nInference for Stan model: anon_model.\n4 chains, each with iter=2000; warmup=1000; thin=1; \npost-warmup draws per chain=1000, total post-warmup draws=4000.\n\n         mean se_mean   sd    5.5%   94.5% n_eff Rhat\na      154.60    0.01 0.27  154.16  155.03  2790    1\nlog_b    0.01    0.00 0.01    0.00    0.04  3334    1\nsigma    5.15    0.00 0.20    4.85    5.49  2865    1\nlp__  -755.86    0.03 1.23 -758.14 -754.50  1692    1\n\nSamples were drawn using NUTS(diag_e) at Wed Jul 31 17:58:15 2024.\nFor each parameter, n_eff is a crude measure of effective sample size,\nand Rhat is the potential scale reduction factor on split chains (at \nconvergence, Rhat=1).\n\n\nWe can exponentiate the log_b parameter to convert it back to the \\(\\beta\\) scale.\n\nas_draws_df(m4.3b) |&gt; \n  transmute(b = exp(log_b)) |&gt; \n  mean_qi(b)\n\n# A tibble: 1 × 6\n      b .lower .upper .width .point .interval\n  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;    \n1  1.01   1.00   1.05   0.95 mean   qi       \n\n\n\n\n\n4.4.3 Interpreting the posterior distribution.\n\n4.4.3.0.1 Rethinking: What do parameters mean?\n\n\n4.4.3.1 Tables of marginal distributions.\nWe can get an exhaustive summary by simply inputting the stan() model fit object directly into summarise_draws().\n\nm4.3 |&gt; \n  summarise_draws()\n\n# A tibble: 4 × 10\n  variable     mean   median     sd    mad       q5      q95  rhat ess_bulk\n  &lt;chr&gt;       &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;\n1 a         155.     155.    0.269  0.266   154.     155.     1.00    4520.\n2 b           0.905    0.904 0.0414 0.0419    0.837    0.973  1.00    4063.\n3 sigma       5.11     5.10  0.190  0.189     4.82     5.44   1.00    3843.\n4 lp__     -749.    -749.    1.19   0.968  -751.    -748.     1.00    2101.\n# ℹ 1 more variable: ess_tail &lt;dbl&gt;\n\n\nThough not needed in this application, you can also use summarise_draws() after first calling as_draws_df().\n\nm4.3 |&gt; \n  as_draws_df() |&gt; \n  summarise_draws()\n\n# A tibble: 4 × 10\n  variable     mean   median     sd    mad       q5      q95  rhat ess_bulk\n  &lt;chr&gt;       &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;\n1 a         155.     155.    0.269  0.266   154.     155.     1.00    4520.\n2 b           0.905    0.904 0.0414 0.0419    0.837    0.973  1.00    4063.\n3 sigma       5.11     5.10  0.190  0.189     4.82     5.44   1.00    3843.\n4 lp__     -749.    -749.    1.19   0.968  -751.    -748.     1.00    2101.\n# ℹ 1 more variable: ess_tail &lt;dbl&gt;\n\n\nCompute the variance/covariance matrix with as_draws_df() and cov().\n\nm4.3 |&gt; \n  as_draws_df() |&gt; \n  select(mu:sigma) |&gt; \n  cov() |&gt; \n  round(digits = 3)\n\n          a     b sigma\na     0.072 0.000 0.001\nb     0.000 0.002 0.000\nsigma 0.001 0.000 0.036\n\n\nHere’s how the pairs() function works for a model fit with stan().\n\npairs(m4.3)\n\n\n\n\nThe pairs() function takes several arguments which can alter its output.\n\npairs(m4.3, \n      cex = 1/10,\n      gap = 0.25,\n      panel = \"points\",\n      pars = c(\"a\", \"b\", \"sigma\"),\n      pch = 19)  \n\n\n\n\n\n\n4.4.3.2 Plotting posterior inference against the data.\nHere is the code for Figure 4.6. Note how we extract the posterior means first, save the values, and input those into the arguments within geom_abline().\n\n# Compute, extract, and save the posterior means\na_stan &lt;- summarise_draws(m4.3) |&gt; \n  filter(variable == \"a\") |&gt; \n  pull(mean)\n\nb_stan &lt;- summarise_draws(m4.3) |&gt; \n  filter(variable == \"b\") |&gt; \n  pull(mean)\n\n# Add the `weight_c` column\nd2 &lt;- d2 |&gt;\n  mutate(weight_c = weight - mean(weight)) \n\n# Plot\nd2 |&gt; \n  ggplot(aes(x = weight_c, y = height)) +\n  geom_point(shape = 1, size = 2) +\n  geom_abline(intercept = a_stan, slope = b_stan,\n              color = \"royalblue\", linewidth = 1) +\n  scale_x_continuous(\"weight\",\n                     breaks = 3:6 * 10 - mean(d2$weight),\n                     labels = 3:6 * 10)\n\n\n\n\n\n\n4.4.3.3 Adding uncertainty around the mean.\nIt’s easy to extract all the posterior draws from a stan() model with as_draws_df().\n\nas_draws_df(m4.3) |&gt; \n  glimpse()\n\nRows: 4,000\nColumns: 7\n$ a          &lt;dbl&gt; 154.4306, 154.5734, 154.4522, 154.3828, 154.4476, 154.4773,…\n$ b          &lt;dbl&gt; 0.9446215, 0.9187776, 0.9058252, 0.8661769, 0.9061876, 0.89…\n$ sigma      &lt;dbl&gt; 4.900342, 5.098300, 4.958741, 5.076583, 5.114658, 5.211086,…\n$ lp__       &lt;dbl&gt; -748.7815, -747.6992, -747.9981, -748.3969, -747.8140, -747…\n$ .chain     &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n$ .iteration &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, …\n$ .draw      &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, …\n\n\nAs far as the workflow in McElreath’s R code 4.48 and 4.49 goes, we’ll do this in a series of steps. First, we make a tibble with a column showing the four levels of n, and then save the subset versions of the d2 data in a nested column by way of map(). We save the results as n_df.\n\nn_df &lt;- tibble(n = c(10, 50, 150, 352)) |&gt; \n  mutate(data = map(.x = n, .f =~ d2 |&gt; \n                      slice(1:.x)))\n\n# What?\nprint(n_df)\n\n# A tibble: 4 × 2\n      n data          \n  &lt;dbl&gt; &lt;list&gt;        \n1    10 &lt;df [10 × 5]&gt; \n2    50 &lt;df [50 × 5]&gt; \n3   150 &lt;df [150 × 5]&gt;\n4   352 &lt;df [352 × 5]&gt;\n\n\nNow make a stan_data column with the data in a list for rstan. Note how we included the xbar component in the list by defining it right within compose_data().\n\nn_df &lt;- n_df |&gt; \n  mutate(stan_data = map(.x = data, .f =~ .x |&gt; \n                           compose_data(xbar = mean(.x$weight))))\n\n# What?\nprint(n_df)\n\n# A tibble: 4 × 3\n      n data           stan_data       \n  &lt;dbl&gt; &lt;list&gt;         &lt;list&gt;          \n1    10 &lt;df [10 × 5]&gt;  &lt;named list [7]&gt;\n2    50 &lt;df [50 × 5]&gt;  &lt;named list [7]&gt;\n3   150 &lt;df [150 × 5]&gt; &lt;named list [7]&gt;\n4   352 &lt;df [352 × 5]&gt; &lt;named list [7]&gt;\n\n\nNext, redefine the model_code object.\n\nmodel_code &lt;- '\ndata {\n  int&lt;lower=1&gt; n;\n  real xbar;         // new data point\n  vector[n] height;\n  vector[n] weight;\n}\nparameters {\n  real a;\n  real&lt;lower=0&gt; b;\n  real&lt;lower=0,upper=50&gt; sigma;\n}\nmodel {\n  vector[n] mu;\n  mu = a + b * (weight - xbar);\n  height ~ normal(mu, sigma);\n  a ~ normal(178, 20);\n  b ~ lognormal(0, 1);\n  sigma ~ uniform(0, 50);\n}\n'\n\nUnlike with the models above where we compiled and samples from the models all in one stan() call, here we’ll use a 2-step procedure. For the first step, we compile the model_code object with the stan_model() function. We’ll save the results as an object called stan_dso.\n\nstan_dso &lt;- stan_model(model_code = model_code)\n\nThe stan_model() function returns an object of S4 class stanmodel, and the code is compiled into a so-called dynamic shared object (DSO), which is why we’ve save our results as stan_dso. To learn more, execute ?stan_model for the documentation.\nFor the second step, we sample from the stan_dso object with the sampling() function, saving the model fits in the sampling column.\n\nn_df &lt;- n_df |&gt; \n  mutate(sampling = map(.x = stan_data, \n                        .f =~ sampling(\n                          data = .x,\n                          object = stan_dso, \n                          seed = 4)))\n\nNow extract 20 rows from the model fits with as_draws_df() and slice_sample().\n\nset.seed(1)\n\nn_df &lt;- n_df |&gt; \n  mutate(as_draws_df = map(.x = sampling,\n                           .f =~ as_draws_df(.x) |&gt; \n                             slice_sample(n = 20)))\n\n# What?\nprint(n_df)\n\n# A tibble: 4 × 5\n      n data           stan_data        sampling        as_draws_df        \n  &lt;dbl&gt; &lt;list&gt;         &lt;list&gt;           &lt;list&gt;          &lt;list&gt;             \n1    10 &lt;df [10 × 5]&gt;  &lt;named list [7]&gt; &lt;stanfit[,4,4]&gt; &lt;draws_df [20 × 7]&gt;\n2    50 &lt;df [50 × 5]&gt;  &lt;named list [7]&gt; &lt;stanfit[,4,4]&gt; &lt;draws_df [20 × 7]&gt;\n3   150 &lt;df [150 × 5]&gt; &lt;named list [7]&gt; &lt;stanfit[,4,4]&gt; &lt;draws_df [20 × 7]&gt;\n4   352 &lt;df [352 × 5]&gt; &lt;named list [7]&gt; &lt;stanfit[,4,4]&gt; &lt;draws_df [20 × 7]&gt;\n\n\nWe’ll need to extract the xbar values for easy tidyverse wrangling, and then we’ll adjust the n column for nicer plot formatting.\n\nn_df &lt;- n_df |&gt; \n  mutate(xbar = map_dbl(.x = stan_data,\n                        .f =~ .x[[\"xbar\"]]),\n         n = str_c(\"italic(n)==\", n) |&gt; \n           factor(levels = str_c(\"italic(n)==\", c(10, 50, 150, 352))))\n\n# What?\nprint(n_df)\n\n# A tibble: 4 × 6\n  n              data           stan_data    sampling        as_draws_df  xbar\n  &lt;fct&gt;          &lt;list&gt;         &lt;list&gt;       &lt;list&gt;          &lt;list&gt;      &lt;dbl&gt;\n1 italic(n)==10  &lt;df [10 × 5]&gt;  &lt;named list&gt; &lt;stanfit[,4,4]&gt; &lt;draws_df&gt;   45.7\n2 italic(n)==50  &lt;df [50 × 5]&gt;  &lt;named list&gt; &lt;stanfit[,4,4]&gt; &lt;draws_df&gt;   44.9\n3 italic(n)==150 &lt;df [150 × 5]&gt; &lt;named list&gt; &lt;stanfit[,4,4]&gt; &lt;draws_df&gt;   45.5\n4 italic(n)==352 &lt;df [352 × 5]&gt; &lt;named list&gt; &lt;stanfit[,4,4]&gt; &lt;draws_df&gt;   45.0\n\n\nNow we plot.\n\nn_df |&gt; \n  select(n, data, xbar) |&gt; \n  unnest(data) |&gt; \n  \n  ggplot(aes(x = weight - xbar, y = height)) +\n  geom_point() +\n  geom_abline(data = n_df |&gt; \n                select(n, xbar, as_draws_df) |&gt; \n                unnest(as_draws_df),\n              aes(intercept = a, slope = b,\n                  group = .draw),\n              color = \"royalblue\", linewidth = 1/4) +\n  scale_x_continuous(\"weight\",\n                     breaks = 3:6 * 10 - mean(d2$weight),\n                     labels = 3:6 * 10) +\n  facet_wrap(~ n, labeller = label_parsed)\n\n\n\n\n\n\n4.4.3.4 Plotting regression intervals and contours.\nSince we used weight_c to fit our model, we might first want to understand what exactly the mean value is for weight.\n\nmean(d2$weight)\n\n[1] 44.99049\n\n\nThis is the same as the xbar value saved in the stan_data object from above.\n\nstan_data$xbar\n\n[1] 44.99049\n\n\nIf we’re interested in \\(\\mu\\) at weight = 50, that implies we’re also interested in \\(\\mu\\) at weight_c + 5.01. Within the context of our model, we compute this with \\(\\alpha + \\beta \\cdot 5.01\\). Here we’ll extract the HMC draws from m4.3 with as_draws_df(), and then define the mu_at_50 column using the same basic algebra McElreath used in his R code 4.50.\n\ndraws &lt;- as_draws_df(m4.3) |&gt; \n  mutate(mu_at_50 = a + b * (50 - stan_data$xbar))\n\n# What?\nhead(draws)\n\n# A draws_df: 6 iterations, 1 chains, and 5 variables\n    a    b sigma lp__ mu_at_50\n1 154 0.94   4.9 -749      159\n2 155 0.92   5.1 -748      159\n3 154 0.91   5.0 -748      159\n4 154 0.87   5.1 -748      159\n5 154 0.91   5.1 -748      159\n6 154 0.90   5.2 -748      159\n# ... hidden reserved variables {'.chain', '.iteration', '.draw'}\n\n\nHere is a version McElreath’s Figure 4.8 density plot.\n\ndraws |&gt;\n  ggplot(aes(x = mu_at_50)) +\n  geom_density(adjust = 1/2, fill = \"gray65\", linewidth = 0) +\n  scale_y_continuous(NULL, breaks = NULL) +\n  xlab(expression(mu[\"height | weight = 50\"]))\n\n\n\n\nWe’ll use mean_hdi() to get both 89% and 95% HDIs, along with the mean.\n\ndraws |&gt; \n  mean_hdi(mu_at_50, .width = c(0.89, 0.95))\n\n# A tibble: 2 × 6\n  mu_at_50 .lower .upper .width .point .interval\n     &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;    \n1     159.   159.   160.   0.89 mean   hdi      \n2     159.   158.   160.   0.95 mean   hdi      \n\n\nThe fitted() functions are not available for stan() models. However, we can adjust our as_draws_df() output (i.e., draws) with expand_grid() to compute the fitted values by hand. We save the results as draws_fitted_df.\n\ndraws_fitted_df &lt;- draws |&gt; \n  select(.draw, a, b, sigma) |&gt; \n  expand_grid(weight = 25:70) |&gt; \n  mutate(height = a + b * (weight - stan_data$xbar))\n\n# What?\nhead(draws_fitted_df)\n\n# A tibble: 6 × 6\n  .draw     a     b sigma weight height\n  &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;int&gt;  &lt;dbl&gt;\n1     1  154. 0.945  4.90     25   136.\n2     1  154. 0.945  4.90     26   136.\n3     1  154. 0.945  4.90     27   137.\n4     1  154. 0.945  4.90     28   138.\n5     1  154. 0.945  4.90     29   139.\n6     1  154. 0.945  4.90     30   140.\n\n\nHere’s how to use that output to make Figure 4.9.\n\np1 &lt;- draws_fitted_df |&gt; \n  filter(.draw &lt;= 100) |&gt; \n  \n  ggplot(aes(x = weight, y = height)) +\n  geom_point(alpha = 0.05, color = \"navyblue\", size = 1/2)\n\np2 &lt;- d2 |&gt;\n  ggplot(aes(x = weight, y = height)) +\n  geom_point(alpha = 1/2, size = 1/2) +\n  stat_lineribbon(data = draws_fitted_df,\n                  .width = 0.89,\n                  color = \"royalblue\", fill = alpha(\"royalblue\", alpha = 1/2), \n                  linewidth = 1/3) +\n  scale_y_continuous(NULL, breaks = NULL)\n\n# Combine, adjust, and display\n(p1 | p2) &\n  coord_cartesian(xlim = range(d2$weight),\n                  ylim = range(d2$height))\n\n\n\n\n\n4.4.3.4.1 Rethinking: Overconfident intervals.\n\n\n4.4.3.4.2 Overthinking: How link works.\nWith a brms-based workflow, we can use functions like base-R fitted() and tidybayes convenience functions like add_epred_draws() in places where McElreath used link() in the text. Sadly, those functions aren’t available for models fit with rstan. Either we hand-compute the expected values with a workflow like above, or in later chapters we’ll see how to build them into the Stan model via the generated quantities block.\n\n\n\n4.4.3.5 Prediction intervals.\nWe can add posterior-predictions to draws_fitted_df by way of the rnorm() function.\n\ndraws_fitted_df &lt;- draws_fitted_df |&gt; \n  mutate(height_pred = rnorm(n = n(), mean = height, sd = sigma))\n\n# What?\nhead(draws_fitted_df)\n\n# A tibble: 6 × 7\n  .draw     a     b sigma weight height height_pred\n  &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;int&gt;  &lt;dbl&gt;       &lt;dbl&gt;\n1     1  154. 0.945  4.90     25   136.        142.\n2     1  154. 0.945  4.90     26   136.        140.\n3     1  154. 0.945  4.90     27   137.        144.\n4     1  154. 0.945  4.90     28   138.        134.\n5     1  154. 0.945  4.90     29   139.        139.\n6     1  154. 0.945  4.90     30   140.        136.\n\n\nHere’s Figure 4.10.\n\nd2 |&gt;\n  ggplot(aes(x = weight, y = height)) +\n  geom_point(alpha = 1/2, size = 1/2) +\n  # This is new\n  stat_lineribbon(data = draws_fitted_df,\n                  aes(y = height_pred),\n                  .width = 0.89,\n                  fill = alpha(\"royalblue\", alpha = 1/3), \n                  linewidth = 0) +\n  stat_lineribbon(data = draws_fitted_df,\n                  .width = 0.89,\n                  color = \"royalblue\", fill = alpha(\"royalblue\", alpha = 1/3), \n                  linewidth = 1/3) +\n  coord_cartesian(xlim = range(d2$weight),\n                  ylim = range(d2$height))\n\n\n\n\n\n4.4.3.5.1 Rethinking: Two kinds of uncertainty.\n\n\n4.4.3.5.2 Overthinking: Rolling your own sim.\nWith a brms-based workflow, we can use functions like base-R predict() and tidybayes convenience functions like add_predicted_draws() in places where McElreath used sim() in the text. Sadly, those functions aren’t available for models fit with rstan. Either we hand-compute the expected values with a workflow like above, or in later chapters we’ll see how to build them into the Stan model via the generated quantities block."
  },
  {
    "objectID": "04.html#curves-from-lines",
    "href": "04.html#curves-from-lines",
    "title": "4  Geocentric Models",
    "section": "4.5 Curves from lines",
    "text": "4.5 Curves from lines\n\n4.5.1 Polynomial regression.\nRemember d?\n\nglimpse(d)\n\nRows: 544\nColumns: 4\n$ height &lt;dbl&gt; 151.7650, 139.7000, 136.5250, 156.8450, 145.4150, 163.8300, 149…\n$ weight &lt;dbl&gt; 47.82561, 36.48581, 31.86484, 53.04191, 41.27687, 62.99259, 38.…\n$ age    &lt;dbl&gt; 63.0, 63.0, 65.0, 41.0, 51.0, 35.0, 32.0, 27.0, 19.0, 54.0, 47.…\n$ male   &lt;int&gt; 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, …\n\n\nMcElreath suggested we plot height against weight using the full sample.\n\nd |&gt; \n  ggplot(aes(x = weight, y = height)) +\n  geom_point(alpha = 2/3, shape = 1, size = 1.5) +\n  annotate(geom = \"text\",\n           x = 42, y = 115,\n           label = \"This relation is\\nvisibly curved.\")\n\n\n\n\nWe might standardize our weight variable like so.\n\nd &lt;- d |&gt;\n  mutate(weight_s = (weight - mean(weight)) / sd(weight)) |&gt; \n  mutate(weight_s2 = weight_s^2)\n\nWhile we were at it, we just went ahead and computed the weight_s2 variable. We can express our statistical model as\n\\[\n\\begin{align*}\n\\text{height}_i & \\sim \\operatorname{Normal}(\\mu_i, \\sigma) \\\\\n\\mu_i   & = \\alpha + \\beta_1 \\text{weight-s}_i + \\beta_2 \\text{weight-s}^2_i \\\\\n\\alpha  & \\sim \\operatorname{Normal}(178, 20) \\\\\n\\beta_1 & \\sim \\operatorname{Log-Normal}(0, 1) \\\\\n\\beta_2 & \\sim \\operatorname{Normal}(0, 1) \\\\\n\\sigma  & \\sim \\operatorname{Uniform}(0, 50).\n\\end{align*}\n\\]\nDefine and save the quadratic_model_code.\n\nquadratic_model_code &lt;- '\ndata {\n  int&lt;lower=1&gt; n;\n  vector[n] height;\n  vector[n] weight_s;\n}\nparameters {\n  real a;\n  real&lt;lower=0&gt; b1;\n  real b2;\n  real&lt;lower=0,upper=50&gt; sigma;\n}\nmodel {\n  vector[n] mu;\n  mu = a + b1 * weight_s + b2 * weight_s^2;\n  height ~ normal(mu, sigma);\n  \n  a ~ normal(178, 20);\n  b1 ~ lognormal(0, 1);\n  b2 ~ normal(0, 1);\n  sigma ~ uniform(0, 50);\n}\n'\n\nUpdate the stan_data to include weight_s.\n\nstan_data &lt;- d |&gt;\n  select(height, weight_s) |&gt; \n  compose_data()\n\n# What?\nstr(stan_data)\n\nList of 3\n $ height  : num [1:544(1d)] 152 140 137 157 145 ...\n $ weight_s: num [1:544(1d)] 0.8299 0.0595 -0.2545 1.1843 0.385 ...\n $ n       : int 544\n\n\nFit the quadratic model, m4.5.\n\nm4.5 &lt;- stan(\n  data = stan_data,\n  model_code = quadratic_model_code,\n  seed = 4)\n\nCheck the summary.\n\nprint(m4.5, probs = c(0.055, 0.945))\n\nInference for Stan model: anon_model.\n4 chains, each with iter=2000; warmup=1000; thin=1; \npost-warmup draws per chain=1000, total post-warmup draws=4000.\n\n          mean se_mean   sd     5.5%    94.5% n_eff Rhat\na       146.05    0.01 0.37   145.45   146.65  2286    1\nb1       21.74    0.01 0.30    21.27    22.22  2707    1\nb2       -7.79    0.01 0.28    -8.24    -7.33  2381    1\nsigma     5.81    0.00 0.18     5.54     6.10  3165    1\nlp__  -1263.66    0.03 1.44 -1266.31 -1262.00  1880    1\n\nSamples were drawn using NUTS(diag_e) at Wed Jul 31 18:01:20 2024.\nFor each parameter, n_eff is a crude measure of effective sample size,\nand Rhat is the potential scale reduction factor on split chains (at \nconvergence, Rhat=1).\n\n\nHere’s how to make the middle panel of Figure 4.11.\n\n# Extract the HMC draws and wrangle\np2 &lt;- as_draws_df(m4.5) |&gt; \n  expand_grid(weight_s = seq(from = min(d$weight_s), to = max(d$weight_s), length.out = 50)) |&gt; \n  mutate(fitted = a + b1 * weight_s + b2 * weight_s^2) |&gt; \n  mutate(predict = rnorm(n = n(), mean = fitted, sd = sigma)) |&gt;\n  \n  # Plot\n  ggplot(aes(x = weight_s)) +\n  geom_point(data = d,\n             aes(y = height),\n             alpha = 1/2, size = 1/2) +\n  stat_lineribbon(aes(y = predict),\n                  .width = 0.89,\n                  fill = alpha(\"royalblue\", alpha = 1/3), \n                  linewidth = 0) +\n  stat_lineribbon(aes(y = fitted),\n                  .width = 0.89,\n                  color = \"royalblue\", fill = alpha(\"royalblue\", alpha = 1/3), \n                  linewidth = 1/3) +\n  scale_y_continuous(NULL, breaks = NULL) +\n  facet_wrap(~ \"quadratic\")\n\np2\n\n\n\n\nDefine and fit the cubic model.\n\ncubic_model_code &lt;- '\ndata {\n  int&lt;lower=1&gt; n;\n  vector[n] height;\n  vector[n] weight_s;\n}\nparameters {\n  real a;\n  real&lt;lower=0&gt; b1;\n  real b2;\n  real b3;\n  real&lt;lower=0,upper=50&gt; sigma;\n}\nmodel {\n  vector[n] mu;\n  mu = a + b1 * weight_s + b2 * weight_s^2 + b3 * weight_s^3;\n  height ~ normal(mu, sigma);\n  \n  a ~ normal(178, 20);\n  b1 ~ lognormal(0, 1);\n  b2 ~ normal(0, 10);\n  b3 ~ normal(0, 10);\n  sigma ~ uniform(0, 50);\n}\n'\n\nm4.6 &lt;- stan(\n  data = stan_data,\n  model_code = cubic_model_code, \n  cores = 4, seed = 4)\n\nCheck the summary.\n\nprint(m4.6, probs = c(0.055, 0.945))\n\nInference for Stan model: anon_model.\n4 chains, each with iter=2000; warmup=1000; thin=1; \npost-warmup draws per chain=1000, total post-warmup draws=4000.\n\n          mean se_mean   sd     5.5%    94.5% n_eff Rhat\na       146.74    0.01 0.33   146.22   147.26  2579    1\nb1       15.01    0.01 0.49    14.22    15.77  2239    1\nb2       -6.54    0.01 0.27    -6.97    -6.11  2404    1\nb3        3.60    0.00 0.23     3.21     3.97  2195    1\nsigma     4.86    0.00 0.15     4.62     5.11  2984    1\nlp__  -1134.88    0.04 1.61 -1137.82 -1132.93  1661    1\n\nSamples were drawn using NUTS(diag_e) at Wed Jul 31 18:02:32 2024.\nFor each parameter, n_eff is a crude measure of effective sample size,\nand Rhat is the potential scale reduction factor on split chains (at \nconvergence, Rhat=1).\n\n\nHere’s how to make the right panel of Figure 4.11.\n\np3 &lt;- as_draws_df(m4.6) |&gt; \n  expand_grid(weight_s = seq(from = min(d$weight_s), to = max(d$weight_s), length.out = 50)) |&gt; \n  mutate(fitted = a + b1 * weight_s + b2 * weight_s^2 + b3 * weight_s^3) |&gt; \n  mutate(predict = rnorm(n = n(), mean = fitted, sd = sigma)) |&gt;\n  \n  # Plot\n  ggplot(aes(x = weight_s)) +\n  geom_point(data = d,\n             aes(y = height),\n             alpha = 1/2, size = 1/2) +\n  stat_lineribbon(aes(y = predict),\n                  .width = 0.89,\n                  fill = alpha(\"royalblue\", alpha = 1/3), \n                  linewidth = 0) +\n  stat_lineribbon(aes(y = fitted),\n                  .width = 0.89,\n                  color = \"royalblue\", fill = alpha(\"royalblue\", alpha = 1/3), \n                  linewidth = 1/3) +\n  scale_y_continuous(NULL, breaks = NULL) +\n  facet_wrap(~ \"cubic\")\np3\n\n\n\n\nFit the simple linear model.\n\nlinear_model_code &lt;- '\ndata {\n  int&lt;lower=1&gt; n;\n  vector[n] height;\n  vector[n] weight_s;\n}\nparameters {\n  real a;\n  real&lt;lower=0&gt; b1;\n  real&lt;lower=0,upper=50&gt; sigma;\n}\nmodel {\n  vector[n] mu;\n  mu = a + b1 * weight_s;\n  height ~ normal(mu, sigma);\n  \n  a ~ normal(178, 20);\n  b1 ~ lognormal(0, 1);\n  sigma ~ uniform(0, 50);\n}\n'\n\nm4.7 &lt;- stan(\n  data = stan_data,\n  model_code = linear_model_code,\n  cores = 4, seed = 4)\n\nHere’s how to make the first panel of Figure 4.11, and then combine to display the full figure.\n\np1 &lt;- as_draws_df(m4.7) |&gt; \n  expand_grid(weight_s = seq(from = min(d$weight_s), to = max(d$weight_s), length.out = 50)) |&gt; \n  mutate(fitted = a + b1 * weight_s) |&gt; \n  mutate(predict = rnorm(n = n(), mean = fitted, sd = sigma)) |&gt;\n  \n  # Plot\n  ggplot(aes(x = weight_s)) +\n  geom_point(data = d,\n             aes(y = height),\n             alpha = 1/2, size = 1/2) +\n  stat_lineribbon(aes(y = predict),\n                  .width = 0.89,\n                  fill = alpha(\"royalblue\", alpha = 1/3), \n                  linewidth = 0) +\n  stat_lineribbon(aes(y = fitted),\n                  .width = 0.89,\n                  color = \"royalblue\", fill = alpha(\"royalblue\", alpha = 1/3), \n                  linewidth = 1/3) +\n  facet_wrap(~ \"linear\")\n\n# Combine\n(p1 | p2 | p3) &\n  coord_cartesian(ylim = range(d$height))\n\n\n\n\n\n4.5.1.0.1 Rethinking: Linear, additive, funky.\n\n\n4.5.1.0.2 Overthinking: Converting back to natural scale.\n\n\n\n4.5.2 Splines.\nI’ll flesh this section out, later. For now, check out Arel-Bundock’s code for this part of the chapter.\n\n\n4.5.3 Smooth functions for a rough world."
  },
  {
    "objectID": "04.html#session-info",
    "href": "04.html#session-info",
    "title": "4  Geocentric Models",
    "section": "Session info",
    "text": "Session info\n\nsessionInfo()\n\nR version 4.4.0 (2024-04-24)\nPlatform: aarch64-apple-darwin20\nRunning under: macOS Ventura 13.4\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: America/Chicago\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n [1] posterior_1.6.0    rstan_2.32.6       StanHeaders_2.32.7 tidybayes_3.0.6   \n [5] patchwork_1.2.0    lubridate_1.9.3    forcats_1.0.0      stringr_1.5.1     \n [9] dplyr_1.1.4        purrr_1.0.2        readr_2.1.5        tidyr_1.3.1       \n[13] tibble_3.2.1       ggplot2_3.5.1      tidyverse_2.0.0   \n\nloaded via a namespace (and not attached):\n [1] gtable_0.3.5         tensorA_0.36.2.1     xfun_0.43           \n [4] QuickJSR_1.1.3       htmlwidgets_1.6.4    processx_3.8.4      \n [7] inline_0.3.19        lattice_0.22-6       callr_3.7.6         \n[10] tzdb_0.4.0           ps_1.7.6             vctrs_0.6.5         \n[13] tools_4.4.0          generics_0.1.3       curl_5.2.1          \n[16] stats4_4.4.0         parallel_4.4.0       fansi_1.0.6         \n[19] pkgconfig_2.0.3      KernSmooth_2.23-22   Matrix_1.7-0        \n[22] checkmate_2.3.1      distributional_0.4.0 RcppParallel_5.1.7  \n[25] lifecycle_1.0.4      farver_2.1.1         compiler_4.4.0      \n[28] munsell_0.5.1        codetools_0.2-20     htmltools_0.5.8.1   \n[31] yaml_2.3.8           pillar_1.9.0         arrayhelpers_1.1-0  \n[34] abind_1.4-5          tidyselect_1.2.1     digest_0.6.35       \n[37] svUnit_1.0.6         stringi_1.8.4        labeling_0.4.3      \n[40] fastmap_1.1.1        grid_4.4.0           colorspace_2.1-0    \n[43] cli_3.6.3            magrittr_2.0.3       loo_2.8.0           \n[46] pkgbuild_1.4.4       utf8_1.2.4           withr_3.0.0         \n[49] scales_1.3.0         backports_1.5.0      timechange_0.3.0    \n[52] rmarkdown_2.26       matrixStats_1.3.0    gridExtra_2.3       \n[55] hms_1.1.3            coda_0.19-4.1        evaluate_0.23       \n[58] knitr_1.46           V8_4.4.2             ggdist_3.3.2        \n[61] viridisLite_0.4.2    rlang_1.1.4          isoband_0.2.7       \n[64] Rcpp_1.0.12          glue_1.7.0           rstudioapi_0.16.0   \n[67] jsonlite_1.8.8       R6_2.5.1"
  },
  {
    "objectID": "04.html#comments",
    "href": "04.html#comments",
    "title": "4  Geocentric Models",
    "section": "Comments",
    "text": "Comments\n\n\n\n\nHowell, N. (2001). Demography of the dobe! Kung (2nd Edition). Routledge. https://www.routledge.com/Demography-of-the-Dobe-Kung/Howell/p/book/9780202306490\n\n\nHowell, N. (2010). Life histories of the Dobe! Kung: Food, fatness, and well-being over the life span (Vol. 4). Univ of California Press. https://www.ucpress.edu/book/9780520262348/life-histories-of-the-dobe-kung"
  },
  {
    "objectID": "05.html#sec-Spurious-associations",
    "href": "05.html#sec-Spurious-associations",
    "title": "5  The Many Variables & The Spurious Waffles",
    "section": "5.1 Spurious associations",
    "text": "5.1 Spurious associations\nLoad the Waffle House data.\n\ndata(WaffleDivorce, package = \"rethinking\")\nd &lt;- WaffleDivorce\nrm(WaffleDivorce)\n\nNow standardize the focal variables with the rethinking::standardize() function.\n\nd &lt;- d |&gt; \n  mutate(d = rethinking::standardize(Divorce),\n         m = rethinking::standardize(Marriage),\n         a = rethinking::standardize(MedianAgeMarriage))\n\nInvestigate the data.\n\nglimpse(d)\n\nRows: 50\nColumns: 16\n$ Location          &lt;fct&gt; Alabama, Alaska, Arizona, Arkansas, California, Colo…\n$ Loc               &lt;fct&gt; AL, AK, AZ, AR, CA, CO, CT, DE, DC, FL, GA, HI, ID, …\n$ Population        &lt;dbl&gt; 4.78, 0.71, 6.33, 2.92, 37.25, 5.03, 3.57, 0.90, 0.6…\n$ MedianAgeMarriage &lt;dbl&gt; 25.3, 25.2, 25.8, 24.3, 26.8, 25.7, 27.6, 26.6, 29.7…\n$ Marriage          &lt;dbl&gt; 20.2, 26.0, 20.3, 26.4, 19.1, 23.5, 17.1, 23.1, 17.7…\n$ Marriage.SE       &lt;dbl&gt; 1.27, 2.93, 0.98, 1.70, 0.39, 1.24, 1.06, 2.89, 2.53…\n$ Divorce           &lt;dbl&gt; 12.7, 12.5, 10.8, 13.5, 8.0, 11.6, 6.7, 8.9, 6.3, 8.…\n$ Divorce.SE        &lt;dbl&gt; 0.79, 2.05, 0.74, 1.22, 0.24, 0.94, 0.77, 1.39, 1.89…\n$ WaffleHouses      &lt;int&gt; 128, 0, 18, 41, 0, 11, 0, 3, 0, 133, 381, 0, 0, 2, 1…\n$ South             &lt;int&gt; 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1…\n$ Slaves1860        &lt;int&gt; 435080, 0, 0, 111115, 0, 0, 0, 1798, 0, 61745, 46219…\n$ Population1860    &lt;int&gt; 964201, 0, 0, 435450, 379994, 34277, 460147, 112216,…\n$ PropSlaves1860    &lt;dbl&gt; 4.5e-01, 0.0e+00, 0.0e+00, 2.6e-01, 0.0e+00, 0.0e+00…\n$ d                 &lt;dbl&gt; 1.6542053, 1.5443643, 0.6107159, 2.0935693, -0.92705…\n$ m                 &lt;dbl&gt; 0.02264406, 1.54980162, 0.04897436, 1.65512283, -0.2…\n$ a                 &lt;dbl&gt; -0.6062895, -0.6866993, -0.2042408, -1.4103870, 0.59…\n\n\nNow we have our data, we can reproduce Figure 5.1.\n\nd |&gt;\n  ggplot(aes(x = WaffleHouses/Population, y = Divorce)) +\n  stat_smooth(method = \"lm\", formula = 'y ~ x', fullrange = TRUE, \n              alpha = 1/5, linewidth = 1/2) +\n  geom_point(alpha = 1/2, size = 1.5) +\n  geom_text(data = d |&gt; \n              filter(Loc %in% c(\"ME\", \"OK\", \"AR\", \"AL\", \"GA\", \"SC\", \"NJ\")),  \n            aes(label = Loc), \n            hjust = -0.2, size = 3, vjust = -0.4) +\n  scale_x_continuous(\"Waffle Houses per million\", limits = c(0, 55)) +\n  ylab(\"Divorce rate\") +\n  coord_cartesian(xlim = c(0, 50), ylim = c(5, 15))\n\n\n\n\nSince these are geographically-based data, we might plot our three major variables in a map format. The tigris package (Walker, 2022) provides functions for retrieving latitude and longitude data for the 50 states and we can plot then with the ggplot2::geom_sf() function. We’ll use the right_join() function to combine those data with our primary data d.\n\n# Get the map data\nd_states &lt;- states(cb = TRUE, resolution = \"20m\") |&gt;\n  shift_geometry() |&gt; \n  # Add the primary data\n  right_join(d |&gt; \n               mutate(NAME = Location |&gt; as.character()) |&gt; \n               select(d:a, NAME),\n             by = \"NAME\") |&gt; \n  # Convert to the long format for faceting\n  pivot_longer(cols = c(\"d\", \"m\", \"a\"), names_to = \"variable\")\n\nNow plot.\n\nd_states |&gt;\n  ggplot() +\n  geom_sf(aes(fill = value, geometry = geometry),\n          size = 0) +\n  scale_fill_gradient(low = \"lightblue\", high = \"blue4\", breaks = NULL) +\n  theme_void() +\n  theme(strip.text = element_text(margin = margin(0, 0, .5, 0))) +\n  facet_wrap(~ variable, labeller = label_both) \n\n\n\n\nHere’s the standard deviation for MedianAgeMarriage in its current metric.\n\nsd(d$MedianAgeMarriage)\n\n[1] 1.24363\n\n\nOur first statistical model follows the form\n\\[\n\\begin{align*}\n\\text{divorce-std}_i & \\sim \\operatorname{Normal}(\\mu_i, \\sigma) \\\\\n\\mu_i   & = \\alpha + \\beta_1 \\text{median-age-at-marriage-std}_i \\\\\n\\alpha  & \\sim \\operatorname{Normal}(0, 0.2) \\\\\n\\beta_1 & \\sim \\operatorname{Normal}(0, 0.5) \\\\\n\\sigma  & \\sim \\operatorname{Exponential}(1),\n\\end{align*}\n\\]\nwhere the “std” suffix indicates the variables are standardized (i.e., zero centered, with a standard deviation of one).\nFirst, we define the model_code_5.1.\n\nmodel_code_5.1 &lt;- '\ndata {\n  int&lt;lower=1&gt; n;\n  vector[n] d;\n  vector[n] a;\n}\nparameters {\n  real b0;\n  real b2;  // Planning ahead for m5.3, we call this parameter b2\n  real&lt;lower=0&gt; sigma;\n}\nmodel {\n  vector[n] mu;\n  mu = b0 + b2 * a;\n  d ~ normal(mu, sigma);\n  \n  b0 ~ normal(0, 0.2);\n  b2 ~ normal(0, 0.5);\n  sigma ~ exponential(1);\n}\ngenerated quantities {\n  // To be discusssed in Chapter 7\n  vector[n] log_lik;\n  for (i in 1:n) log_lik[i] = normal_lpdf(d[i] | b0 + b2 * a[i], sigma);\n}\n'\n\nYou may have noticed we have an exciting new generated quantities with some mysterious code defining log_lik. We’ll have similar code for the next two models, but we won’t be ready to discuss those bits until later in Section 7.2.4 and Section 7.5.2. For now, just let the tension build.\nMake the stan_data with the compose_data() function.\n\nstan_data &lt;- d |&gt;\n  select(d, a) |&gt; \n  compose_data()\n\n# What?\nstr(stan_data)\n\nList of 3\n $ d: num [1:50(1d)] 1.654 1.544 0.611 2.094 -0.927 ...\n  ..- attr(*, \"scaled:center\")= num 9.69\n  ..- attr(*, \"scaled:scale\")= num 1.82\n $ a: num [1:50(1d)] -0.606 -0.687 -0.204 -1.41 0.6 ...\n  ..- attr(*, \"scaled:center\")= num 26.1\n  ..- attr(*, \"scaled:scale\")= num 1.24\n $ n: int 50\n\n\nFit the model with stan().\n\nm5.1 &lt;- stan(\n  data = stan_data,\n  model_code = model_code_5.1,\n  cores = 4, seed = 5)\n\nThere are two basic ways to sample from the priors using stan(), which Michael Betancourt explained in this thread in the Stan forums. The first is to fit a single model with an if statement that turns the likelihood on an off, as needed. The second is the fit two separate models: one for just the prior, and the other for the posterior. We’ll do the second. Here it is in bulk.\n\nmodel_code_5.1_prior &lt;- '\ndata {\n  int&lt;lower=1&gt; n;\n  vector[n] d;\n  vector[n] a;\n}\nparameters {\n  real b0;\n  real b2;\n  real&lt;lower=0&gt; sigma;\n}\nmodel {\n  // The model only contains the prior\n  b0 ~ normal(0, 0.2);\n  b2 ~ normal(0, 0.5);\n  sigma ~ exponential(1);\n}\n'\n\nm5.1_prior &lt;- stan(\n  data = stan_data,\n  model_code = model_code_5.1_prior,\n  cores = 4, seed = 5)\n\nHere are the samples from m5.1_prior in a half-eye plot.\n\nas_draws_df(m5.1_prior) |&gt; \n  pivot_longer(b0:sigma) |&gt; \n  mutate(name = case_when(\n    name == \"b0\" ~ \"b[0]\",\n    name == \"b2\" ~ \"b[2]\",\n    name == \"sigma\" ~ \"sigma\"\n  )) |&gt; \n  \n  ggplot(aes(x = value, y = name)) +\n  stat_halfeye(point_interval = mean_qi, .width = 0.89) +\n  scale_y_discrete(NULL, labels = ggplot2:::parse_safe, expand = expansion(mult = 0.1)) +\n  xlab(\"prior\") +\n  coord_cartesian(xlim = c(-1, 5))\n\n\n\n\nHere’s Figure 5.3.\n\nset.seed(5)\n\nas_draws_df(m5.1_prior) |&gt; \n  slice_sample(n = 50) |&gt; \n  \n  ggplot() +\n  geom_abline(aes(intercept = b0, slope = b2, group = .draw),\n              alpha = 3/4, linewidth = 1/4) +\n  scale_x_continuous(\"Median age marriage (std)\", limits = c(-2, 2)) +\n  scale_y_continuous(\"Divorce rate (std)\", limits = c(-2, 2))\n\n\n\n\nHere’s the right panel of Figure 5.2.\n\np2 &lt;- as_draws_df(m5.1) |&gt; \n  expand_grid(a = seq(from = min(d$a), to = max(d$a), length.out = 30)) |&gt; \n  mutate(mu = b0 + b2 * a) |&gt; \n  \n  ggplot(aes(x = a)) +\n  stat_lineribbon(aes(y = mu),\n                  .width = 0.89, color = \"blue\", fill = alpha(\"blue\", 1/3)) +\n  geom_point(data = d,\n             aes(y = d),\n             size = 2/3) +\n  labs(x = \"Median age marriage (std)\",\n       y = \"Divorce rate (std)\")\n\np2\n\n\n\n\nTo make the other panel of the figure, first we need to fit m5.2.\n\n# Define the new model code\nmodel_code_5.2 &lt;- '\ndata {\n  int&lt;lower=1&gt; n;\n  vector[n] m;\n  vector[n] d;\n}\nparameters {\n  real b0;\n  real b1;\n  real&lt;lower=0&gt; sigma;\n}\nmodel {\n  // This time we use the more compact notation\n  d ~ normal(b0 + b1 * m, sigma);\n  \n  b0 ~ normal(0, 0.2);\n  b1 ~ normal(0, 0.5);\n  sigma ~ exponential(1);\n}\ngenerated quantities {\n  // To be discusssed in Chapter 7\n  vector[n] log_lik;\n  for (i in 1:n) log_lik[i] = normal_lpdf(d[i] | b0 + b1 * m[i], sigma);\n}\n'\n\n# Update `stan_data`\nstan_data &lt;- d |&gt;\n  select(d, a, m) |&gt; \n  compose_data()\n\n# Compile and sample\nm5.2 &lt;- stan(\n  data = stan_data,\n  model_code = model_code_5.2,\n  cores = 4, seed = 5)\n\nCheck the summary.\n\nprint(m5.2, pars = c(\"b0\", \"b1\", \"sigma\"), probs = c(0.055, 0.945))\n\nInference for Stan model: anon_model.\n4 chains, each with iter=2000; warmup=1000; thin=1; \npost-warmup draws per chain=1000, total post-warmup draws=4000.\n\n      mean se_mean   sd  5.5% 94.5% n_eff Rhat\nb0    0.00       0 0.11 -0.19  0.18  4148    1\nb1    0.35       0 0.13  0.13  0.56  3901    1\nsigma 0.95       0 0.10  0.81  1.12  3418    1\n\nSamples were drawn using NUTS(diag_e) at Fri Aug  2 12:46:11 2024.\nFor each parameter, n_eff is a crude measure of effective sample size,\nand Rhat is the potential scale reduction factor on split chains (at \nconvergence, Rhat=1).\n\n\nHere’s the rest of Figure 5.2.\n\np1 &lt;- as_draws_df(m5.2) |&gt; \n  expand_grid(m = seq(from = min(d$m), to = max(d$m), length.out = 30)) |&gt; \n  mutate(mu = b0 + b1 * m) |&gt; \n  \n  ggplot(aes(x = m)) +\n  stat_lineribbon(aes(y = mu),\n                  .width = 0.89, color = \"blue\", fill = alpha(\"blue\", 1/3)) +\n  geom_point(data = d,\n             aes(y = d),\n             size = 2/3) +\n  labs(x = \"Marriage rate (std)\",\n       y = \"Divorce rate (std)\")\n\n# Combine\np1 | (p2 + scale_y_continuous(NULL, breaks = NULL))\n\n\n\n\n\n5.1.1 Think before you regress.\nIf all you want is a quick and dirty DAG for our three variables, you might execute something like this.\n\nset.seed(5)\n\ndagify(M ~ A,\n       D ~ A + M) |&gt;\n  ggdag(node_size = 8)\n\n\n\n\nWe can pretty it up a little, too.\n\ndag_coords &lt;- tibble(\n  name = c(\"A\", \"M\", \"D\"),\n  x    = c(1, 3, 2),\n  y    = c(2, 2, 1))\n\np1 &lt;- dagify(\n  M ~ A,\n  D ~ A + M,\n  coords = dag_coords) |&gt;\n  \n  ggplot(aes(x = x, y = y, xend = xend, yend = yend)) +\n  geom_dag_point(alpha = 1/4, size = 10) +\n  geom_dag_text() +\n  geom_dag_edges() +\n  scale_x_continuous(NULL, breaks = NULL, expand = c(0.1, 0.1)) +\n  scale_y_continuous(NULL, breaks = NULL, expand = c(0.2, 0.2)) +\n  theme_dag()\n\np1\n\n\n\n\nConsidering alternative models, “It could be that the association between \\(M\\) and \\(D\\) arises entirely from \\(A\\)’s influence on both \\(M\\) and \\(D\\). Like this:” (p. 129)\n\np2 &lt;- dagify(\n  M ~ A,\n  D ~ A,\n  coords = dag_coords) |&gt;\n  \n  ggplot(aes(x = x, y = y, xend = xend, yend = yend)) +\n  geom_dag_point(alpha = 1/4, size = 10) +\n  geom_dag_text() +\n  geom_dag_edges() +\n  scale_x_continuous(NULL, breaks = NULL, expand = c(0.1, 0.1)) +\n  scale_y_continuous(NULL, breaks = NULL, expand = c(0.2, 0.2)) +\n  theme_dag()\n\np1 | p2\n\n\n\n\n\n5.1.1.1 Rethinking: What’s a cause?\n\n\n5.1.1.2 Overthinking: Drawing a DAG.\n\n\n\n5.1.2 Testable implications.\n\n\n5.1.3 Multiple regression notation.\nWe can write the statistical formula for our first multivariable model as\n\\[\n\\begin{align*}\n\\text{Divorce-std}_i & \\sim \\operatorname{Normal}(\\mu_i, \\sigma) \\\\\n\\mu_i   & = \\alpha + \\beta_1 \\text{Marriage-std}_i + \\beta_2 \\text{MedianAgeMarriage-std}_i \\\\\n\\alpha  & \\sim \\operatorname{Normal}(0, 0.2) \\\\\n\\beta_1 & \\sim \\operatorname{Normal}(0, 0.5) \\\\\n\\beta_2 & \\sim \\operatorname{Normal}(0, 0.5) \\\\\n\\sigma  & \\sim \\operatorname{Exponential}(1).\n\\end{align*}\n\\]\n\n5.1.3.1 Overthinking: Compact notation and the design matrix.\n\nOften, linear models are written using a compact form like:\n\\[\n\\mu_i = \\alpha + \\sum_{j=1}^n \\beta_j x_{ji}\n\\]\nwhere \\(j\\) is an index over predictor variables and \\(n\\) is the number of predictor variables. This may be read as the mean is modeled as the sum of an intercept and an additive combination of the products of parameters and predictors. Even more compactly, using matrix notation:\n\\[\n\\mathbf{m} = \\mathbf{Xb}\n\\]\nwhere \\(\\mathbf{m}\\) is a vector of predicted means, one for each row in the data, \\(\\mathbf{b}\\) is a (column) vector of parameters, one for each predictor variable, and \\(\\mathbf{X}\\) is a matrix. This matrix is called a design matrix. (p. 132, emphasis in the original)\n\nI generally do not like this style of notation, and I rarely use it. It’s not common to see it in papers in my field, and I suspect it many of my colleagues would find it actively discouraging. However, this style of notation will come in handy for some of the stan() code to come, starting with the models in Section 6.3.2.1.\n\n\n\n5.1.4 Approximating the posterior.\nDefine model_code_5.3.\n\nmodel_code_5.3 &lt;- '\ndata {\n  int&lt;lower=1&gt; n;\n  vector[n] d;\n  vector[n] m;\n  vector[n] a;\n}\nparameters {\n  real b0;\n  real b1;\n  real b2;\n  real&lt;lower=0&gt; sigma;\n}\nmodel {\n  vector[n] mu;\n  mu = b0 + b1 * m + b2 * a;\n  d ~ normal(mu, sigma);\n  \n  b0 ~ normal(0, 0.2);\n  b1 ~ normal(0, 0.5);\n  b2 ~ normal(0, 0.5);\n  sigma ~ exponential(1);\n}\ngenerated quantities {\n  // To be discusssed in Chapter 7\n  vector[n] log_lik;\n  for (i in 1:n) log_lik[i] = normal_lpdf(d[i] | b0 + b1 * m[i] + b2 * a[i], sigma);\n}\n'\n\nThe stan_data list already has all we need.\n\nstr(stan_data)\n\nList of 3\n $ d: num [1:50(1d)] 1.654 1.544 0.611 2.094 -0.927 ...\n  ..- attr(*, \"scaled:center\")= num 9.69\n  ..- attr(*, \"scaled:scale\")= num 1.82\n $ a: num [1:50(1d)] -0.606 -0.687 -0.204 -1.41 0.6 ...\n  ..- attr(*, \"scaled:center\")= num 26.1\n  ..- attr(*, \"scaled:scale\")= num 1.24\n $ n: int 50\n\n\nFit the model with stan().\n\nm5.3 &lt;- stan(\n  data = stan_data,\n  model_code = model_code_5.3,\n  cores = 4, seed = 5)\n\nBehold the summary.\n\nprint(m5.3, pars = c(\"b0\", \"b1\", \"b2\", \"sigma\"),  probs = c(0.055, 0.945))\n\nInference for Stan model: anon_model.\n4 chains, each with iter=2000; warmup=1000; thin=1; \npost-warmup draws per chain=1000, total post-warmup draws=4000.\n\n       mean se_mean   sd  5.5% 94.5% n_eff Rhat\nb0     0.00       0 0.10 -0.16  0.17  3594    1\nb1    -0.06       0 0.16 -0.31  0.20  2939    1\nb2    -0.60       0 0.16 -0.85 -0.35  2997    1\nsigma  0.83       0 0.09  0.70  0.97  3434    1\n\nSamples were drawn using NUTS(diag_e) at Fri Aug  2 12:47:48 2024.\nFor each parameter, n_eff is a crude measure of effective sample size,\nand Rhat is the potential scale reduction factor on split chains (at \nconvergence, Rhat=1).\n\n\nHere’s a variant of McElreath’s rethinking::coeftab() plot (p. 133).\n\nbind_rows(\n  as_draws_df(m5.1) |&gt; mutate(model = \"m5.1\"),\n  as_draws_df(m5.2) |&gt; mutate(model = \"m5.2\"),\n  as_draws_df(m5.3) |&gt; mutate(model = \"m5.3\")\n) |&gt; \n  pivot_longer(starts_with(\"b\")) |&gt; \n  filter(name != \"b0\") |&gt; \n  drop_na(value) |&gt; \n  mutate(name = case_when(\n    name == \"b1\" ~ \"beta[1]\",\n    name == \"b2\" ~ \"beta[2]\"\n  ) |&gt; factor(levels = c(\"beta[2]\", \"beta[1]\"))) |&gt; \n  \n  ggplot(aes(x = value, y = model)) +\n  geom_vline(xintercept = 0, color = \"white\") +\n  stat_pointinterval(.width = 0.89) +\n  labs(x = \"posterior\",\n       y = NULL) +\n  facet_wrap(~ name, labeller = label_parsed, ncol = 1)\n\n\n\n\n\n5.1.4.1 Overthinking: Simulating the divorce example.\nOkay, let’s simulate our divorce data in a tidyverse sort of way.\n\n# How many states would you like?\nn &lt;- 50 \n\nset.seed(5)\nsim_d &lt;- tibble(a = rnorm(n, mean = 0, sd = 1)) |&gt;  # A \n  mutate(m = rnorm(n, mean = -a, sd = 1),           # A -&gt; M \n         d = rnorm(n, mean =  a, sd = 1))           # A -&gt; D\n\n# What?\nhead(sim_d)\n\n# A tibble: 6 × 3\n        a      m      d\n    &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n1 -0.841   2.30  -2.84 \n2  1.38   -1.20   2.52 \n3 -1.26    2.28  -0.580\n4  0.0701 -0.662  0.279\n5  1.71   -1.82   1.65 \n6 -0.603  -0.322  0.291\n\n\nWe simulated those data based on this formulation.\n\ndagitty('dag{divorce &lt;- age -&gt; marriage}') |&gt; \n  impliedConditionalIndependencies()\n\ndvrc _||_ mrrg | age\n\n\nUpdate the stan_data.\n\nstan_data &lt;- sim_d |&gt;\n  compose_data()\n\n# What?\nstr(stan_data)\n\nList of 4\n $ a: num [1:50(1d)] -0.8409 1.3844 -1.2555 0.0701 1.7114 ...\n $ m: num [1:50(1d)] 2.304 -1.197 2.278 -0.662 -1.824 ...\n $ d: num [1:50(1d)] -2.836 2.52 -0.58 0.279 1.654 ...\n $ n: int 50\n\n\nSince the goal of this section is to simulate data like those in the d data frame and then fit three models corresponding to those from above, we can re-use the Stan model DSO’s. If you execute str(m5.1, max.level = 2), you’ll notice the stan() fit object has a stanmodel section which is a “S4 class stanmodel.” We can input that directly into the object argument of the sampling() function, and then sample from the posterior when applied to the new stan_data from the simulation. We’ll save the results as m5.1_sim.\n\nm5.1_sim &lt;- sampling(\n  object = m5.1@stanmodel,\n  data = stan_data,\n  cores = 4, seed = 5)\n\nCheck the summary.\n\nprint(m5.1_sim, probs = c(0.055, 0.945))\n\nInference for Stan model: anon_model.\n4 chains, each with iter=2000; warmup=1000; thin=1; \npost-warmup draws per chain=1000, total post-warmup draws=4000.\n\n        mean se_mean   sd   5.5%  94.5% n_eff Rhat\nb0     -0.02    0.00 0.12  -0.22   0.18  4070    1\nb2      0.94    0.00 0.15   0.70   1.18  4141    1\nsigma   1.13    0.00 0.12   0.96   1.33  4135    1\nlp__  -34.08    0.03 1.25 -36.40 -32.74  1864    1\n\nSamples were drawn using NUTS(diag_e) at Wed Jul 31 17:17:34 2024.\nFor each parameter, n_eff is a crude measure of effective sample size,\nand Rhat is the potential scale reduction factor on split chains (at \nconvergence, Rhat=1).\n\n\nNow do the same thing for the next two models.\n\nm5.2_sim &lt;- sampling(\n  object = m5.2@stanmodel,\n  data = stan_data,\n  cores = 4, seed = 5)\n\nm5.3_sim &lt;- sampling(\n  object = m5.3@stanmodel,\n  data = stan_data,\n  cores = 4, seed = 5)\n\nHere’s our new rethinking::coeftab() plot variant for the simulated data.\n\nbind_rows(\n  as_draws_df(m5.1_sim) |&gt; mutate(model = \"m5.1\"),\n  as_draws_df(m5.2_sim) |&gt; mutate(model = \"m5.2\"),\n  as_draws_df(m5.3_sim) |&gt; mutate(model = \"m5.3\")\n) |&gt; \n  pivot_longer(starts_with(\"b\")) |&gt; \n  filter(name != \"b0\") |&gt; \n  drop_na(value) |&gt; \n  mutate(name = case_when(\n    name == \"b1\" ~ \"beta[1]\",\n    name == \"b2\" ~ \"beta[2]\"\n  ) |&gt; factor(levels = c(\"beta[2]\", \"beta[1]\"))) |&gt; \n  \n  ggplot(aes(x = value, y = model)) +\n  geom_vline(xintercept = 0, color = \"white\") +\n  stat_pointinterval(.width = 0.89) +\n  labs(x = \"posterior\",\n       y = NULL) +\n  facet_wrap(~ name, labeller = label_parsed, ncol = 1)\n\n\n\n\n\n\n\n5.1.5 Plotting multivariate posteriors.\n\n5.1.5.1 Predictor residual plots.\nAs we start this section, it’s important to clarify some wording. When McElreath described residuals, he used the following wording:\n\nAnd then we compute the residuals by subtracting the observed marriage rate in each State from the predicted rate, based upon the model above. (p. 135, emphasis added)\n\nIn this context, a prediction for each State is a fitted or expected value. This is in contrast with the kind of predicted values that come from posterior-predictive checks. With brms, this would mean we’d use fitted(), rather than predict(). Since those options are not available for a stan()-based workflow, we need more technical language. The predictions we’re making are done using the linear model \\(\\eta\\), but not the stochastic term, \\(\\sigma\\).\nUntil this point, we have made predictions by hand using the as_draws_df() output. Another option is to build them into the generated quantities block of the model_code. Here we’ll define our predicted values as a vector of mu[i] parameters.\n\nmodel_code_5.4 &lt;- '\ndata {\n  int&lt;lower=1&gt; n;\n  vector[n] m;\n  vector[n] a;\n}\nparameters {\n  real b0;\n  real b1;\n  real&lt;lower=0&gt; sigma;\n}\nmodel {\n  m ~ normal(b0 + b1 * a, sigma);  // Model `m` as the criterion\n  \n  b0 ~ normal(0, 0.2);\n  b1 ~ normal(0, 0.5);\n  sigma ~ exponential(1);\n}\ngenerated quantities {\n  vector[n] mu;\n  mu = b0 + b1 * a;  // Expected values defined w/o the stochastic parameter\n}\n'\n\nUpdate the stan_data to include values from good-old d, again.\n\nstan_data &lt;- d |&gt; \n  select(d, a, m) |&gt; \n  compose_data()\n\n# What?\nstr(stan_data)\n\nList of 4\n $ d: num [1:50(1d)] 1.654 1.544 0.611 2.094 -0.927 ...\n  ..- attr(*, \"scaled:center\")= num 9.69\n  ..- attr(*, \"scaled:scale\")= num 1.82\n $ a: num [1:50(1d)] -0.606 -0.687 -0.204 -1.41 0.6 ...\n  ..- attr(*, \"scaled:center\")= num 26.1\n  ..- attr(*, \"scaled:scale\")= num 1.24\n $ m: num [1:50(1d)] 0.0226 1.5498 0.049 1.6551 -0.267 ...\n  ..- attr(*, \"scaled:center\")= num 20.1\n  ..- attr(*, \"scaled:scale\")= num 3.8\n $ n: int 50\n\n\nFit the model with stan().\n\nm5.4 &lt;- stan(\n  data = stan_data,\n  model_code = model_code_5.4,\n  cores = 4, seed = 5)\n\nBehold the summary.\n\nprint(m5.4, probs = c(0.055, 0.945))\n\nInference for Stan model: anon_model.\n4 chains, each with iter=2000; warmup=1000; thin=1; \npost-warmup draws per chain=1000, total post-warmup draws=4000.\n\n        mean se_mean   sd   5.5% 94.5% n_eff Rhat\nb0      0.00    0.00 0.09  -0.15  0.15  3739    1\nb1     -0.69    0.00 0.10  -0.85 -0.52  3318    1\nsigma   0.71    0.00 0.08   0.61  0.85  3789    1\nmu[1]   0.42    0.00 0.11   0.25  0.59  3384    1\nmu[2]   0.47    0.00 0.11   0.29  0.66  3351    1\nmu[3]   0.14    0.00 0.09  -0.01  0.29  3566    1\nmu[4]   0.97    0.00 0.17   0.70  1.24  3197    1\nmu[5]  -0.42    0.00 0.11  -0.59 -0.24  3553    1\nmu[6]   0.19    0.00 0.10   0.04  0.35  3549    1\nmu[7]  -0.86    0.00 0.16  -1.11 -0.61  3446    1\nmu[8]  -0.31    0.00 0.10  -0.47 -0.14  3602    1\nmu[9]  -2.03    0.01 0.31  -2.51 -1.52  3406    1\nmu[10] -0.19    0.00 0.10  -0.35 -0.04  3658    1\nmu[11]  0.08    0.00 0.09  -0.07  0.23  3616    1\nmu[12] -0.47    0.00 0.12  -0.65 -0.29  3533    1\nmu[13]  1.58    0.00 0.25   1.18  1.97  3158    1\nmu[14] -0.53    0.00 0.12  -0.72 -0.33  3514    1\nmu[15]  0.19    0.00 0.10   0.04  0.35  3549    1\nmu[16]  0.36    0.00 0.11   0.20  0.53  3421    1\nmu[17]  0.58    0.00 0.12   0.38  0.78  3296    1\nmu[18]  0.69    0.00 0.14   0.48  0.91  3256    1\nmu[19]  0.08    0.00 0.09  -0.07  0.23  3616    1\nmu[20] -0.19    0.00 0.10  -0.35 -0.04  3658    1\nmu[21] -0.69    0.00 0.14  -0.91 -0.47  3472    1\nmu[22] -1.36    0.00 0.22  -1.70 -1.01  3414    1\nmu[23] -0.19    0.00 0.10  -0.35 -0.04  3658    1\nmu[24] -0.14    0.00 0.09  -0.29  0.01  3687    1\nmu[25]  0.14    0.00 0.09  -0.01  0.29  3566    1\nmu[26]  0.25    0.00 0.10   0.10  0.41  3510    1\nmu[27]  0.19    0.00 0.10   0.04  0.35  3549    1\nmu[28]  0.36    0.00 0.11   0.20  0.53  3421    1\nmu[29] -0.42    0.00 0.11  -0.59 -0.24  3553    1\nmu[30] -0.92    0.00 0.16  -1.17 -0.66  3440    1\nmu[31]  0.14    0.00 0.09  -0.01  0.29  3566    1\nmu[32] -1.31    0.00 0.21  -1.64 -0.96  3415    1\nmu[33]  0.19    0.00 0.10   0.04  0.35  3549    1\nmu[34]  0.42    0.00 0.11   0.25  0.59  3384    1\nmu[35] -0.14    0.00 0.09  -0.29  0.01  3687    1\nmu[36]  0.92    0.00 0.16   0.66  1.17  3205    1\nmu[37]  0.03    0.00 0.09  -0.12  0.18  3696    1\nmu[38] -0.58    0.00 0.13  -0.78 -0.38  3498    1\nmu[39] -1.19    0.00 0.20  -1.50 -0.88  3420    1\nmu[40] -0.19    0.00 0.10  -0.35 -0.04  3658    1\nmu[41]  0.25    0.00 0.10   0.10  0.41  3510    1\nmu[42]  0.47    0.00 0.11   0.29  0.66  3351    1\nmu[43]  0.47    0.00 0.11   0.29  0.66  3351    1\nmu[44]  1.53    0.00 0.24   1.14  1.91  3160    1\nmu[45] -0.47    0.00 0.12  -0.65 -0.29  3533    1\nmu[46] -0.19    0.00 0.10  -0.35 -0.04  3658    1\nmu[47]  0.08    0.00 0.09  -0.07  0.23  3616    1\nmu[48]  0.58    0.00 0.12   0.38  0.78  3296    1\nmu[49] -0.14    0.00 0.09  -0.29  0.01  3687    1\nmu[50]  1.03    0.00 0.17   0.75  1.30  3190    1\nlp__   -9.79    0.03 1.31 -12.18 -8.42  1986    1\n\nSamples were drawn using NUTS(diag_e) at Wed Jul 31 15:07:53 2024.\nFor each parameter, n_eff is a crude measure of effective sample size,\nand Rhat is the potential scale reduction factor on split chains (at \nconvergence, Rhat=1).\n\n\nNow we have a series of mu[i] rows in the summary. These show up in the as_draws_df() output, too.\n\nas_draws_df(m5.4) |&gt; \n  colnames()\n\n [1] \"b0\"         \"b1\"         \"sigma\"      \"mu[1]\"      \"mu[2]\"     \n [6] \"mu[3]\"      \"mu[4]\"      \"mu[5]\"      \"mu[6]\"      \"mu[7]\"     \n[11] \"mu[8]\"      \"mu[9]\"      \"mu[10]\"     \"mu[11]\"     \"mu[12]\"    \n[16] \"mu[13]\"     \"mu[14]\"     \"mu[15]\"     \"mu[16]\"     \"mu[17]\"    \n[21] \"mu[18]\"     \"mu[19]\"     \"mu[20]\"     \"mu[21]\"     \"mu[22]\"    \n[26] \"mu[23]\"     \"mu[24]\"     \"mu[25]\"     \"mu[26]\"     \"mu[27]\"    \n[31] \"mu[28]\"     \"mu[29]\"     \"mu[30]\"     \"mu[31]\"     \"mu[32]\"    \n[36] \"mu[33]\"     \"mu[34]\"     \"mu[35]\"     \"mu[36]\"     \"mu[37]\"    \n[41] \"mu[38]\"     \"mu[39]\"     \"mu[40]\"     \"mu[41]\"     \"mu[42]\"    \n[46] \"mu[43]\"     \"mu[44]\"     \"mu[45]\"     \"mu[46]\"     \"mu[47]\"    \n[51] \"mu[48]\"     \"mu[49]\"     \"mu[50]\"     \"lp__\"       \".chain\"    \n[56] \".iteration\" \".draw\"     \n\n\nThese are our expected or fitted values, one for each case in the data. Again, we technically don’t need those expected mu[i] values. We can also compute them by hand. To prove it, here we connect the mu[i] rows to their original Loc values, and then summarize them by their means and 89% intervals.\n\n# Isolate and wrangle the `mu[i]` values from the `generated quantities` block\nmu_mean_qi &lt;- as_draws_df(m5.4) |&gt; \n  select(.draw, starts_with(\"mu\")) |&gt; \n  pivot_longer(starts_with(\"mu\"), \n               names_to = \"rownumber\",\n               values_to = \"m_hat\") |&gt; \n  mutate(rownumber = str_extract(rownumber, \"\\\\d+\") |&gt; \n           as.integer()) |&gt; \n  # Match them up with the data\n  left_join(d |&gt; \n              mutate(rownumber = 1:n()) |&gt; \n              select(rownumber, Loc, a, m, d),\n            by = join_by(rownumber)) |&gt; \n  group_by(Loc, a, m, d) |&gt; \n  mean_qi(m_hat, .width = 0.89)\n\n# What?\nhead(mu_mean_qi)\n\n# A tibble: 6 × 10\n  Loc        a       m      d  m_hat  .lower .upper .width .point .interval\n  &lt;fct&gt;  &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;    \n1 AK    -0.687  1.55    1.54   0.472  0.291   0.657   0.89 mean   qi       \n2 AL    -0.606  0.0226  1.65   0.417  0.245   0.594   0.89 mean   qi       \n3 AR    -1.41   1.66    2.09   0.972  0.702   1.24    0.89 mean   qi       \n4 AZ    -0.204  0.0490  0.611  0.139 -0.0107  0.291   0.89 mean   qi       \n5 CA     0.600 -0.267  -0.927 -0.417 -0.592  -0.241   0.89 mean   qi       \n6 CO    -0.285  0.892   1.05   0.194  0.0447  0.349   0.89 mean   qi       \n\n\nNow we compute the expected values for the Loc levels by hand with the b0 and b1 posteriors.\n\nbeta_mean_qi &lt;- as_draws_df(m5.4) |&gt; \n  select(.draw, b0, b1) |&gt; \n  expand_grid(select(d, Loc, a, m, d)) |&gt; \n  mutate(m_hat = b0 + b1 * a) |&gt; \n  group_by(Loc, a, m, d) |&gt; \n  mean_qi(m_hat, .width = 0.89)\n\n# What?\nhead(beta_mean_qi)\n\n# A tibble: 6 × 10\n  Loc        a       m      d  m_hat  .lower .upper .width .point .interval\n  &lt;fct&gt;  &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;    \n1 AK    -0.687  1.55    1.54   0.472  0.291   0.657   0.89 mean   qi       \n2 AL    -0.606  0.0226  1.65   0.417  0.245   0.594   0.89 mean   qi       \n3 AR    -1.41   1.66    2.09   0.972  0.702   1.24    0.89 mean   qi       \n4 AZ    -0.204  0.0490  0.611  0.139 -0.0107  0.291   0.89 mean   qi       \n5 CA     0.600 -0.267  -0.927 -0.417 -0.592  -0.241   0.89 mean   qi       \n6 CO    -0.285  0.892   1.05   0.194  0.0447  0.349   0.89 mean   qi       \n\n\nAre they the same? The all.equal() function will tell.\n\nall.equal(mu_mean_qi, beta_mean_qi)\n\n[1] TRUE\n\n\nYes, they are the same to the exact values. Sometimes it might be easier to compute expected values by hand, like in Chapter 4. Other times, it might be easier to use the generated quantities block approach. It’s good to know both.\nHere’s how to make Figure 5.4, top row, left column, with the mu[i] summaries from our generated quantities block.\n\nloc_vector &lt;- c(\"WY\", \"ND\", \"ME\", \"HI\", \"DC\")\n\np1 &lt;- mu_mean_qi |&gt; \n  ggplot(aes(x = a)) +\n  geom_line(aes(y = m_hat),\n            color = \"blue\") +\n  geom_segment(aes(xend = a, y = m_hat, yend = m),\n               color = \"blue\") +\n  geom_point(aes(y = m)) +\n  geom_text(data = d |&gt; \n              filter(Loc %in% loc_vector),\n            aes(y = m, label = Loc),\n            hjust = 1.2, size = 3, vjust = -0.2)\n\np1\n\n\n\n\nHere’s how to make Figure 5.4, bottom row, left column, with the mu[i] summaries from our generated quantities block.\n\np2 &lt;- mu_mean_qi |&gt; \n  # Define the residual means\n  mutate(r_hat = m - m_hat) |&gt; \n  \n  ggplot(aes(x = r_hat, y = d)) +\n  geom_vline(xintercept = 0, color = \"white\") +\n  stat_smooth(method = \"lm\", formula = 'y ~ x',\n              alpha = 1/5, color = \"blue\", \n              fill = \"blue\", level = 0.89, linewidth = 1/2) +\n  geom_point(color = \"blue\") +\n  geom_text(data = mu_mean_qi |&gt; \n              mutate(r_hat = m - m_hat) |&gt; \n              filter(Loc %in% loc_vector),\n            aes(label = Loc),\n            hjust = 1.2, size = 3, vjust = -0.2)\n\np2\n\n\n\n\nHow define the model_code for what we’ll call m5.4b, the residual model for the other predictor, a. Note we continue to practice with the generated quantities block.\n\nmodel_code_5.4b &lt;- '\ndata {\n  int&lt;lower=1&gt; n;\n  vector[n] a;\n  vector[n] m;\n}\nparameters {\n  real b0;\n  real b1;\n  real&lt;lower=0&gt; sigma;\n}\nmodel {\n  a ~ normal(b0 + b1 * m, sigma);  // This time we model a as the criterion\n  \n  b0 ~ normal(0, 0.2);\n  b1 ~ normal(0, 0.5);\n  sigma ~ exponential(1);\n}\ngenerated quantities {\n  vector[n] mu;\n  mu = b0 + b1 * m;  // Expected values for m\n}\n'\n\nFit the model with stan().\n\nm5.4b &lt;- stan(\n  data = stan_data,\n  model_code = model_code_5.4b,\n  cores = 4, seed = 5)\n\nCheck the model summary.\n\nprint(m5.4b, pars = c(\"b0\", \"b1\", \"sigma\"), probs = c(0.055, 0.945))\n\nInference for Stan model: anon_model.\n4 chains, each with iter=2000; warmup=1000; thin=1; \npost-warmup draws per chain=1000, total post-warmup draws=4000.\n\n       mean se_mean   sd  5.5% 94.5% n_eff Rhat\nb0     0.00       0 0.09 -0.15  0.14  3623    1\nb1    -0.69       0 0.10 -0.85 -0.52  3663    1\nsigma  0.71       0 0.07  0.61  0.84  2649    1\n\nSamples were drawn using NUTS(diag_e) at Wed Jul 31 15:15:40 2024.\nFor each parameter, n_eff is a crude measure of effective sample size,\nand Rhat is the potential scale reduction factor on split chains (at \nconvergence, Rhat=1).\n\n\nDid you notice our use of the pars argument, there? That restricted the print() output to the parameters listed in that character vector. Had we left that out, the output would also have contained the summaries of the 50 rows of mu[i] parameters.\nSpeaking of which, the 50 rows of mu[i] from this model are the expected values for a, conditional on m. This time we’ll compute the mean and 89% intervals for the mu[i] posteriors with the summarise_draws() function from posterior. Note that this time, the mean will be saved in a column named mean. We continue to call the summary object mu_mean_qi.\n\nmu_mean_qi &lt;- as_draws_df(m5.4b) |&gt; \n  select(.draw, starts_with(\"mu\")) |&gt; \n  summarise_draws(mean, ~quantile(.x, probs = c(0.055, 0.945))) |&gt; \n  rename(rownumber = variable) |&gt; \n  mutate(rownumber = str_extract(rownumber, \"\\\\d+\") |&gt; \n           as.integer()) |&gt; \n  left_join(d |&gt; \n              mutate(rownumber = 1:n()) |&gt; \n              select(rownumber, Loc, a, m, d),\n            by = join_by(rownumber))\n\n# What?\nhead(mu_mean_qi)\n\n# A tibble: 6 × 8\n  rownumber    mean  `5.5%` `94.5%` Loc        a       m      d\n      &lt;int&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;fct&gt;  &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;\n1         1 -0.0161 -0.166    0.129 AL    -0.606  0.0226  1.65 \n2         2 -1.07   -1.36    -0.776 AK    -0.687  1.55    1.54 \n3         3 -0.0342 -0.185    0.111 AZ    -0.204  0.0490  0.611\n4         4 -1.14   -1.44    -0.834 AR    -1.41   1.66    2.09 \n5         5  0.184   0.0305   0.337 CA     0.600 -0.267  -0.927\n6         6 -0.615  -0.818   -0.408 CO    -0.285  0.892   1.05 \n\n\nNow make Figure 5.4, top row, right column.\n\np3 &lt;- mu_mean_qi |&gt; \n  rename(a_hat = mean) |&gt; \n  \n  ggplot(aes(x = m)) +\n  geom_line(aes(y = a_hat),\n            color = \"blue\") +\n  geom_segment(aes(xend = m, y = a_hat, yend = a),\n               color = \"blue\") +\n  geom_point(aes(y = a)) +\n  geom_text(data = d |&gt; \n              filter(Loc %in% loc_vector),\n            aes(y = a, label = Loc),\n            hjust = 1.2, size = 3, vjust = -0.2)\n\np3\n\n\n\n\nMake Figure 5.4, bottom row, right column.\n\np4 &lt;- mu_mean_qi |&gt; \n  rename(a_hat = mean) |&gt; \n  # Define the residual means\n  mutate(r_hat = a - a_hat) |&gt; \n  \n  ggplot(aes(x = r_hat, y = d)) +\n  geom_vline(xintercept = 0, color = \"white\") +\n  stat_smooth(method = \"lm\", formula = 'y ~ x',\n              alpha = 1/5, color = \"blue\", \n              fill = \"blue\", level = 0.89, linewidth = 1/2) +\n  geom_point(color = \"blue\") +\n  geom_text(data = mu_mean_qi |&gt; \n              rename(a_hat = mean) |&gt; \n              mutate(r_hat = a - a_hat) |&gt; \n              filter(Loc %in% loc_vector),\n            aes(label = Loc),\n            hjust = 1.2, size = 3, vjust = -0.2)\n\np4\n\n\n\n\nHere’s the full Figure 5.4.\n\n(p1 / p2) | (p3 / p4)\n\n\n\n\n\n5.1.5.1.1 Rethinking: Residuals are parameters, not data.\nTo give a sense of the residual distributions for each case, here’s the lower right panel of Figure 5.4, again, but including the 89% interval ranges.\n\nmu_mean_qi &lt;- mu_mean_qi |&gt; \n  # Define the residual summaries\n  mutate(r_hat = a - mean,\n         .lower = a - `5.5%`, \n         .upper = a - `94.5%`)\n\nmu_mean_qi |&gt; \n  ggplot(aes(x = r_hat, y = d)) +\n  geom_vline(xintercept = 0, color = \"white\") +\n  stat_smooth(method = \"lm\", formula = 'y ~ x',\n              alpha = 1/5, color = \"blue\", \n              fill = \"blue\", level = 0.89, linewidth = 1/2) +\n  geom_pointinterval(aes(xmin = .lower, xmax = .upper),\n                     color = \"blue\", linewidth = 1/10, point_size = 1/2) +  \n  geom_text(data = mu_mean_qi |&gt; \n              filter(Loc %in% loc_vector),\n            aes(label = Loc),\n            hjust = 1.2, size = 3, vjust = -0.2)\n\n\n\n\n\n\n\n5.1.5.2 Posterior prediction plots.\nYou can refresh your memory of the model for m5.3 by indexing the stanmodel part of the stanfit object.\n\nm5.3@stanmodel\n\nS4 class stanmodel 'anon_model' coded as follows:\ndata {\n  int&lt;lower=1&gt; n;\n  vector[n] d;\n  vector[n] m;\n  vector[n] a;\n}\nparameters {\n  real b0;\n  real b1;\n  real b2;\n  real&lt;lower=0&gt; sigma;\n}\nmodel {\n  vector[n] mu;\n  mu = b0 + b1 * m + b2 * a;\n  d ~ normal(mu, sigma);\n\n  b0 ~ normal(0, 0.2);\n  b1 ~ normal(0, 0.5);\n  b2 ~ normal(0, 0.5);\n  sigma ~ exponential(1);\n}\ngenerated quantities {\n  // To be discusssed in Chapter 7\n  vector[n] log_lik;\n  for (i in 1:n) log_lik[i] = normal_lpdf(d[i] | b0 + b1 * m[i] + b2 * a[i], sigma);\n} \n\n\nWe can make Figure 5.5 by computing the predictions (i.e., the expected or fitted values) by hand with the model parameters b0 through b2 from the as_draws_df() output.\n\nloc_vector &lt;- c(\"ID\", \"RI\", \"UT\", \"ME\")\n\ndraws &lt;- as_draws_df(m5.3) |&gt; \n  select(.draw, b0, b1, b2) |&gt; \n  expand_grid(select(d, Loc, d, a, m)) |&gt; \n  mutate(mu = b0 + b1 * m + b2 * a) \n\ndraws |&gt; \n  ggplot(aes(x = d, y = mu)) +\n  geom_abline(color = \"white\") +\n  stat_pointinterval(aes(group = Loc),\n                     point_interval = mean_qi, .width = 0.89, \n                     color = \"blue\", linewidth = 1/4, shape = 1) +  \n  geom_text(data = draws |&gt; \n              filter(Loc %in% loc_vector) |&gt; \n              group_by(Loc, d) |&gt; \n              summarise(mu = mean(mu)),\n            aes(label = Loc),\n            hjust = -0.4, size = 3) +\n  ylab(expression(widehat(divorce)))\n\n\n\n\nHad we fit m5.3 with a generated quantities, we could have also made the same plot with summaries from the mu[i] posteriors. For the sake of practice, here’s such a plot for m5.4, the residual model for m.\n\ndraws &lt;- m5.4 |&gt; \n  summarise_draws(mean, ~quantile(.x, probs = c(0.055, 0.945))) |&gt; \n  filter(str_detect(variable, \"mu\")) |&gt; \n  rename(rownumber = variable) |&gt; \n  mutate(rownumber = str_extract(rownumber, \"\\\\d+\") |&gt; \n           as.integer()) |&gt; \n  left_join(d |&gt; \n              mutate(rownumber = 1:n()), \n            by = join_by(rownumber))\n\ndraws |&gt; \n  ggplot(aes(x = m, y = mean)) +\n  geom_abline(color = \"white\") +\n  geom_pointinterval(aes(group = Loc, ymin = `5.5%`, ymax = `94.5%`),\n                     color = \"blue\", linewidth = 1/4, shape = 1) +  \n  geom_text(data = draws |&gt; \n              filter(Loc %in% loc_vector),\n            aes(label = Loc),\n            hjust = -0.4, size = 3) +\n  ylab(expression(widehat(m)))\n\n\n\n\n\n5.1.5.2.1 Rethinking: Stats, huh, yeah what is it good for?\n\n\n5.1.5.2.2 Overthinking: Simulating spurious association.\nHere’s the simulated data.\n\n# Number of cases\nn &lt;- 100\n\n# Setting the seed makes the results reproducible\nset.seed(5)\n\nd_spur &lt;- tibble(\n  x_real = rnorm(n = n),                 # Gaussian with mean 0 and SD 1 (i.e., the defaults)\n  x_spur = rnorm(n = n, mean = x_real),  # Gaussian with `mean = x_real`\n  y =      rnorm(n = n, mean = x_real))  # Gaussian with `mean = x_real`\n\nFit the model.\n\nmodel_code_spur &lt;- '\ndata {\n  int&lt;lower=1&gt; n;\n  vector[n] x_real;\n  vector[n] x_spur;\n  vector[n] y;\n}\nparameters {\n  real b0;\n  real b1;\n  real b2;\n  real&lt;lower=0&gt; sigma;\n}\nmodel {\n  y ~ normal(b0 + b1 * x_real + b2 * x_spur, sigma);\n  \n  b0 ~ normal(0, 0.2);\n  b1 ~ normal(0, 0.5);\n  b2 ~ normal(0, 0.5);\n  sigma ~ exponential(1);\n}\n'\n\nstan_data &lt;- d_spur |&gt; \n  compose_data()\n\nm5.0_spur &lt;- stan(\n  data = stan_data,\n  model_code = model_code_spur,\n  cores = 4, seed = 5)\n\nSummarize.\n\nprint(m5.0_spur, probs = c(0.055, 0.945))\n\nInference for Stan model: anon_model.\n4 chains, each with iter=2000; warmup=1000; thin=1; \npost-warmup draws per chain=1000, total post-warmup draws=4000.\n\n        mean se_mean   sd   5.5%  94.5% n_eff Rhat\nb0      0.00    0.00 0.09  -0.14   0.14  3830    1\nb1      0.93    0.00 0.14   0.70   1.14  3057    1\nb2      0.08    0.00 0.09  -0.06   0.23  3362    1\nsigma   0.97    0.00 0.07   0.87   1.09  4137    1\nlp__  -49.98    0.03 1.43 -52.69 -48.29  1837    1\n\nSamples were drawn using NUTS(diag_e) at Wed Jul 31 17:07:47 2024.\nFor each parameter, n_eff is a crude measure of effective sample size,\nand Rhat is the potential scale reduction factor on split chains (at \nconvergence, Rhat=1).\n\n\nIf we let “r” stand for x_rel and “s” stand for x_spur, here’s how we might depict that our simulation in a DAG.\n\ndag_coords &lt;- tibble(\n  name = c(\"r\", \"s\", \"y\"),\n  x    = c(1, 3, 2),\n  y    = c(2, 2, 1))\n\ndagify(s ~ r,\n       y ~ r,\n       coords = dag_coords) |&gt;\n  \n  ggplot(aes(x = x, y = y, xend = xend, yend = yend)) +\n  geom_dag_point(alpha = 1/4, size = 10) +\n  geom_dag_text() +\n  geom_dag_edges() +\n  scale_x_continuous(NULL, breaks = NULL, expand = c(0.1, 0.1)) +\n  scale_y_continuous(NULL, breaks = NULL, expand = c(0.2, 0.2)) +\n  theme_dag()\n\n\n\n\n\n\n\n5.1.5.3 Counterfactual plots.\nTake another look at one of the DAGs from back in Section 5.1.2.\n\ndag_coords &lt;- tibble(\n  name = c(\"A\", \"M\", \"D\"),\n  x    = c(1, 3, 2),\n  y    = c(2, 2, 1))\n\ndagify(M ~ A,\n       D ~ A + M,\n       coords = dag_coords) |&gt;\n  \n  ggplot(aes(x = x, y = y, xend = xend, yend = yend)) +\n  geom_dag_point(alpha = 1/4, size = 10) +\n  geom_dag_text() +\n  geom_dag_edges() +\n  scale_x_continuous(NULL, breaks = NULL, expand = c(0.1, 0.1)) +\n  scale_y_continuous(NULL, breaks = NULL, expand = c(0.2, 0.2)) +\n  theme_dag()\n\n\n\n\nDefine the bivariate model.\n\nmodel_code_5.3_a &lt;- '\ndata {\n  int&lt;lower=1&gt; n;\n  vector[n] a;\n  vector[n] d;\n  vector[n] m;\n}\nparameters {\n  real b0;\n  real b1;\n  real b2;\n  real&lt;lower=0&gt; sigma;\n  real g0;\n  real g1;\n  real&lt;lower=0&gt; zeta;\n}\nmodel {\n  d ~ normal(b0 + b1 * m + b2 * a, sigma);\n  m ~ normal(g0 + g1 * a, zeta);\n  \n  b0 ~ normal(0, 0.2);\n  b1 ~ normal(0, 0.5);\n  b2 ~ normal(0, 0.5);\n  sigma ~ exponential(1);\n  g0 ~ normal(0, 0.2);\n  g1 ~ normal(0, 0.5);\n  zeta ~ exponential(1);\n}\n'\n\nUpdate the stan_data.\n\nstan_data &lt;- d |&gt; \n  select(a, d, m) |&gt; \n  compose_data()\n\n# What?\nstr(stan_data)\n\nList of 4\n $ a: num [1:50(1d)] -0.606 -0.687 -0.204 -1.41 0.6 ...\n  ..- attr(*, \"scaled:center\")= num 26.1\n  ..- attr(*, \"scaled:scale\")= num 1.24\n $ d: num [1:50(1d)] 1.654 1.544 0.611 2.094 -0.927 ...\n  ..- attr(*, \"scaled:center\")= num 9.69\n  ..- attr(*, \"scaled:scale\")= num 1.82\n $ m: num [1:50(1d)] 0.0226 1.5498 0.049 1.6551 -0.267 ...\n  ..- attr(*, \"scaled:center\")= num 20.1\n  ..- attr(*, \"scaled:scale\")= num 3.8\n $ n: int 50\n\n\nFit the bivariate model with stan().\n\nm5.3_a &lt;- stan(\n  data = stan_data,\n  model_code = model_code_5.3_a,\n  cores = 4, seed = 5)\n\nCheck the model summary.\n\nprint(m5.3_a, probs = c(0.055, 0.945))\n\nInference for Stan model: anon_model.\n4 chains, each with iter=2000; warmup=1000; thin=1; \npost-warmup draws per chain=1000, total post-warmup draws=4000.\n\n        mean se_mean   sd   5.5%  94.5% n_eff Rhat\nb0      0.00    0.00 0.10  -0.16   0.16  5101    1\nb1     -0.06    0.00 0.16  -0.31   0.19  3360    1\nb2     -0.61    0.00 0.16  -0.86  -0.35  3331    1\nsigma   0.82    0.00 0.09   0.70   0.98  5616    1\ng0      0.00    0.00 0.09  -0.15   0.14  5870    1\ng1     -0.69    0.00 0.10  -0.84  -0.54  5676    1\nzeta    0.71    0.00 0.07   0.60   0.84  5399    1\nlp__  -26.86    0.05 1.93 -30.41 -24.43  1683    1\n\nSamples were drawn using NUTS(diag_e) at Wed Jul 31 15:30:42 2024.\nFor each parameter, n_eff is a crude measure of effective sample size,\nand Rhat is the potential scale reduction factor on split chains (at \nconvergence, Rhat=1).\n\n\nMake Figure 5.6.\n\np1 &lt;- as_draws_df(m5.3_a) |&gt; \n  expand_grid(a = seq(from = -2, to = 2, length.out = 30),\n              m = 0) |&gt; \n  mutate(pred_d = rnorm(n = n(), mean = b0 + b1 * m + b2 * a, sd = sigma)) |&gt; \n  \n  ggplot(aes(x = a, y = pred_d)) +\n  stat_lineribbon(.width = 0.89, fill = \"gray67\", linewidth = 1/2) +\n  facet_wrap(~ \"Total counterfactual effect of A on D\")\n\np2 &lt;- as_draws_df(m5.3_a) |&gt; \n  expand_grid(a = seq(from = -2, to = 2, length.out = 30),\n              m = 0) |&gt; \n  mutate(pred_m = rnorm(n = n(), mean = g0 + g1 * a, sd = zeta)) |&gt; \n  \n  ggplot(aes(x = a, y = pred_m)) +\n  stat_lineribbon(.width = 0.89, fill = \"gray67\", linewidth = 1/2) +\n  facet_wrap(~ \"Counterfactual effect of A on M\")\n\n(p1 + p2) & coord_cartesian(ylim = c(-2, 2))\n\n\n\n\nWe can compute “the expected causal effect of increasing median age at marriage from 20 to 30” with the compare_levels() function.\n\nas_draws_df(m5.3_a) |&gt; \n  expand_grid(a = (c(20, 30) - 26.1) / 1.24,\n              m = 0) |&gt; \n  mutate(pred_d = rnorm(n = n(), mean = b0 + b1 * m + b2 * a, sd = sigma)) |&gt; \n  compare_levels(variable = pred_d, by = a) |&gt; \n  ungroup() |&gt; \n  summarise(expectation = mean(pred_d))\n\n# A tibble: 1 × 1\n  expectation\n        &lt;dbl&gt;\n1       -4.88\n\n\n\nThe trick with simulating counterfactuals is to realize that when we manipulate some variable \\(X\\), we break the causal influence of other variables on \\(X\\). This is the same as saying we modify the DAG so that no arrows enter \\(X\\). Suppose for example that we now simulate the effect of manipulating \\(M.\\) (p. 143)\n\nHere’s how to plot that DAG.\n\ndag_coords &lt;- tibble(\n  name = c(\"A\", \"M\", \"D\"),\n  x    = c(1, 3, 2),\n  y    = c(2, 2, 1))\n\ndagify(D ~ A + M,\n       coords = dag_coords) |&gt;\n  \n  ggplot(aes(x = x, y = y, xend = xend, yend = yend)) +\n  geom_dag_point(alpha = 1/4, size = 10) +\n  geom_dag_text() +\n  geom_dag_edges() +\n  scale_x_continuous(NULL, breaks = NULL, expand = c(0.1, 0.1)) +\n  scale_y_continuous(NULL, breaks = NULL, expand = c(0.2, 0.2)) +\n  theme_dag()\n\n\n\n\nHere’s the new counterfactual plot focusing on \\(M \\rightarrow D\\), holding \\(A = 0\\), Figure 5.7.\n\nas_draws_df(m5.3_a) |&gt; \n  expand_grid(a = 0,\n              m = seq(from = -2, to = 2, length.out = 30)) |&gt; \n  mutate(pred_d = rnorm(n = n(), mean = b0 + b1 * m + b2 * a, sd = sigma)) |&gt; \n  \n  ggplot(aes(x = m, y = pred_d)) +\n  stat_lineribbon(.width = 0.89, fill = \"gray67\", linewidth = 1/2) +\n  coord_cartesian(ylim = c(-2, 2)) +\n  facet_wrap(~ \"Total counterfactual effect of M on D\")\n\n\n\n\n\n5.1.5.3.1 Overthinking: Simulating counterfactuals."
  },
  {
    "objectID": "05.html#masked-relationship",
    "href": "05.html#masked-relationship",
    "title": "5  The Many Variables & The Spurious Waffles",
    "section": "5.2 Masked relationship",
    "text": "5.2 Masked relationship\nLoad the milk data (Hinde & Milligan, 2011).\n\ndata(milk, package = \"rethinking\")\nd &lt;- milk\nrm(milk)\n\n# What?\nglimpse(d)\n\nRows: 29\nColumns: 8\n$ clade          &lt;fct&gt; Strepsirrhine, Strepsirrhine, Strepsirrhine, Strepsirrh…\n$ species        &lt;fct&gt; Eulemur fulvus, E macaco, E mongoz, E rubriventer, Lemu…\n$ kcal.per.g     &lt;dbl&gt; 0.49, 0.51, 0.46, 0.48, 0.60, 0.47, 0.56, 0.89, 0.91, 0…\n$ perc.fat       &lt;dbl&gt; 16.60, 19.27, 14.11, 14.91, 27.28, 21.22, 29.66, 53.41,…\n$ perc.protein   &lt;dbl&gt; 15.42, 16.91, 16.85, 13.18, 19.50, 23.58, 23.46, 15.80,…\n$ perc.lactose   &lt;dbl&gt; 67.98, 63.82, 69.04, 71.91, 53.22, 55.20, 46.88, 30.79,…\n$ mass           &lt;dbl&gt; 1.95, 2.09, 2.51, 1.62, 2.19, 5.25, 5.37, 2.51, 0.71, 0…\n$ neocortex.perc &lt;dbl&gt; 55.16, NA, NA, NA, NA, 64.54, 64.54, 67.64, NA, 68.85, …\n\n\nLet’s standardize our variables by hand.\n\nd &lt;- d |&gt; \n  mutate(k = (kcal.per.g - mean(kcal.per.g)) / sd(kcal.per.g), \n         n = (neocortex.perc - mean(neocortex.perc, na.rm = TRUE)) / sd(neocortex.perc, na.rm = TRUE), \n         m = (log(mass) - mean(log(mass))) / sd(log(mass)))\n\nDefine the stan_data.\n\nstan_data &lt;- d |&gt; \n  select(k, n, m) |&gt; \n  compose_data(.n_name = n_prefix(\"N\"))\n\n# What?\nstr(stan_data)\n\nList of 4\n $ k: num [1:29(1d)] -0.94 -0.816 -1.126 -1.002 -0.259 ...\n $ n: num [1:29(1d)] -2.08 NA NA NA NA ...\n $ m: num [1:29(1d)] -0.456 -0.415 -0.307 -0.565 -0.387 ...\n $ N: int 29\n\n\nDefine model_code_5.5_draft.\n\nmodel_code_5.5_draft &lt;- '\ndata {\n  int&lt;lower=1&gt; N;\n  vector[N] k;\n  vector[N] n;\n}\nparameters {\n  real b0;\n  real b1;\n  real&lt;lower=0&gt; sigma;\n}\nmodel {\n  k ~ normal(b0 + b1 * n, sigma);\n\n  b0 ~ normal(0, 1);\n  b1 ~ normal(0, 1);\n  sigma ~ exponential(1);\n}\n'\n\nNow attempt to fit m5.5_draft.\n\nm5.5_draft &lt;- stan(\n  data = stan_data,\n  model_code = model_code_5.5_draft,\n  cores = 4, seed = 5)\n\nThe model did not fit due to the NA values, as indicated by the warning message: Stan does not support NA (in n) in data.\nDrop cases with missingness in any of our three focal variables.\n\ndcc &lt;- d |&gt;\n  drop_na(k, n, m)\n\nUpdate the data_list.\n\nstan_data &lt;- dcc |&gt; \n  select(k, n, m) |&gt; \n  compose_data(.n_name = n_prefix(\"N\"))\n\n# What?\nstr(stan_data)\n\nList of 4\n $ k: num [1:17(1d)] -0.94 -1.064 -0.506 1.538 1.724 ...\n $ n: num [1:17(1d)] -2.0802 -0.5086 -0.5086 0.0107 0.2135 ...\n $ m: num [1:17(1d)] -0.456 0.127 0.141 -0.307 -1.076 ...\n $ N: int 17\n\n\n\nm5.5_draft &lt;- stan(\n  data = stan_data,\n  model_code = model_code_5.5_draft,\n  cores = 4, seed = 5)\n\nCheck the model summary.\n\nprint(m5.5_draft, probs = c(0.055, 0.945))\n\nInference for Stan model: anon_model.\n4 chains, each with iter=2000; warmup=1000; thin=1; \npost-warmup draws per chain=1000, total post-warmup draws=4000.\n\n        mean se_mean   sd   5.5%  94.5% n_eff Rhat\nb0      0.09    0.00 0.27  -0.32   0.52  3807    1\nb1      0.15    0.00 0.28  -0.29   0.60  3361    1\nsigma   1.13    0.00 0.21   0.85   1.50  2745    1\nlp__  -11.57    0.03 1.27 -13.93 -10.17  1854    1\n\nSamples were drawn using NUTS(diag_e) at Wed Jul 31 15:45:31 2024.\nFor each parameter, n_eff is a crude measure of effective sample size,\nand Rhat is the potential scale reduction factor on split chains (at \nconvergence, Rhat=1).\n\n\nTake samples from just the priors with stan().\n\nmodel_code_5.5_draft_prior &lt;- '\ndata {\n  int&lt;lower=1&gt; N;\n  vector[N] k;\n  vector[N] n;\n}\nparameters {\n  real b0;\n  real b1;\n  real&lt;lower=0&gt; sigma;\n}\nmodel {\n  b0 ~ normal(0, 1);\n  b1 ~ normal(0, 1);\n  sigma ~ exponential(1);\n}\n'\n\nm5.5_draft_prior &lt;- stan(\n  data = stan_data,\n  model_code = model_code_5.5_draft_prior,\n  cores = 4, seed = 5)\n\nHere’s the left panel of Figure 5.8.\n\nset.seed(5)\n\np1 &lt;- as_draws_df(m5.5_draft_prior) |&gt; \n  slice_sample(n = 30) |&gt; \n  \n  ggplot() +\n  geom_abline(aes(intercept = b0, slope = b1, group = .draw)) +\n  scale_x_continuous(\"neocortex percent (std)\", limits = c(-2, 2)) +\n  scale_y_continuous(\"kilocal per g (std)\", limits = c(-2, 2)) +\n  facet_wrap(~ \"a ~ dnorm(0, 1)\\nbN ~ dnorm(0, 1)\")\n\np1\n\n\n\n\nNow take samples from the tighter priors.\n\nmodel_code_5.5_prior &lt;- '\ndata {\n  int&lt;lower=1&gt; N;\n  vector[N] k;\n  vector[N] n;\n}\nparameters {\n  real b0;\n  real b1;\n  real&lt;lower=0&gt; sigma;\n}\nmodel {\n  b0 ~ normal(0, 0.2);\n  b1 ~ normal(0, 0.5);\n  sigma ~ exponential(1);\n}\n'\n\nm5.5_prior &lt;- stan(\n  data = stan_data,\n  model_code = model_code_5.5_prior,\n  cores = 4, seed = 5)\n\nNow complete Figure 5.8.\n\nset.seed(5)\n\np2 &lt;- as_draws_df(m5.5_prior) |&gt; \n  slice_sample(n = 30) |&gt; \n  \n  ggplot() +\n  geom_abline(aes(intercept = b0, slope = b1, group = .draw)) +\n  scale_x_continuous(\"neocortex percent (std)\", limits = c(-2, 2)) +\n  scale_y_continuous(NULL, breaks = NULL, limits = c(-2, 2)) +\n  facet_wrap(~ \"a ~ dnorm(0, 0.2)\\nbN ~ dnorm(0, 0.5)\")\n\np1 | p2\n\n\n\n\nDefine model_code_5.5 and fit m5.5.\n\nmodel_code_5.5 &lt;- '\ndata {\n  int&lt;lower=1&gt; N;\n  vector[N] k;\n  vector[N] n;\n}\nparameters {\n  real b0;\n  real b1;\n  real&lt;lower=0&gt; sigma;\n}\nmodel {\n  k ~ normal(b0 + b1 * n, sigma);\n\n  b0 ~ normal(0, 0.2);\n  b1 ~ normal(0, 0.5);\n  sigma ~ exponential(1);\n}\n'\n\nm5.5 &lt;- stan(\n  data = stan_data,\n  model_code = model_code_5.5,\n  cores = 4, seed = 5)\n\nCheck the model summary.\n\nprint(m5.5, probs = c(0.055, 0.945))\n\nInference for Stan model: anon_model.\n4 chains, each with iter=2000; warmup=1000; thin=1; \npost-warmup draws per chain=1000, total post-warmup draws=4000.\n\n        mean se_mean   sd   5.5%  94.5% n_eff Rhat\nb0      0.03    0.00 0.16  -0.22   0.28  3560    1\nb1      0.12    0.00 0.24  -0.27   0.52  3617    1\nsigma   1.11    0.00 0.21   0.84   1.47  2844    1\nlp__  -11.60    0.03 1.28 -13.99 -10.23  1814    1\n\nSamples were drawn using NUTS(diag_e) at Wed Jul 31 15:48:12 2024.\nFor each parameter, n_eff is a crude measure of effective sample size,\nand Rhat is the potential scale reduction factor on split chains (at \nconvergence, Rhat=1).\n\n\nMake Figure 5.9, upper left.\n\np1 &lt;- as_draws_df(m5.5) |&gt; \n  expand_grid(n = seq(from = -2.5, to = 2.5, length.out = 50)) |&gt; \n  mutate(mu = b0 + b1 * n) |&gt; \n  \n  ggplot(aes(x = n)) +\n  stat_lineribbon(aes(y = mu),\n                  .width = 0.89, \n                  color = \"blue\", fill = alpha(\"blue\", 1/3), linewidth = 1/2) +\n  geom_point(data = dcc,\n             aes(y = k)) +\n  coord_cartesian(xlim = range(dcc$n),\n                  ylim = range(dcc$k)) +\n  labs(x = \"neocortex percent (std)\",\n       y = \"kilocal per g (std)\")\n\np1\n\n\n\n\nNow we use m as the new sole predictor.\n\nmodel_code_5.6 &lt;- '\ndata {\n  int&lt;lower=1&gt; N;\n  vector[N] k;\n  vector[N] m;\n}\nparameters {\n  real b0;\n  real b2;\n  real&lt;lower=0&gt; sigma;\n}\nmodel {\n  k ~ normal(b0 + b2 * m, sigma);\n\n  b0 ~ normal(0, 0.2);\n  b2 ~ normal(0, 0.5);\n  sigma ~ exponential(1);\n}\n'\n\nm5.6 &lt;- stan(\n  data = stan_data,\n  model_code = model_code_5.6,\n  cores = 4, seed = 5)\n\nCheck the model summary.\n\nprint(m5.6, probs = c(0.055, 0.945))\n\nInference for Stan model: anon_model.\n4 chains, each with iter=2000; warmup=1000; thin=1; \npost-warmup draws per chain=1000, total post-warmup draws=4000.\n\n        mean se_mean   sd   5.5% 94.5% n_eff Rhat\nb0      0.04    0.00 0.16  -0.21  0.29  3720    1\nb2     -0.27    0.00 0.21  -0.59  0.07  3686    1\nsigma   1.06    0.00 0.19   0.80  1.40  3143    1\nlp__  -10.81    0.03 1.27 -13.21 -9.47  1937    1\n\nSamples were drawn using NUTS(diag_e) at Wed Jul 31 15:49:42 2024.\nFor each parameter, n_eff is a crude measure of effective sample size,\nand Rhat is the potential scale reduction factor on split chains (at \nconvergence, Rhat=1).\n\n\nMake Figure 5.9, upper right.\n\np2 &lt;- as_draws_df(m5.6) |&gt; \n  expand_grid(m = seq(from = -2.5, to = 2.5, length.out = 50)) |&gt; \n  mutate(mu = b0 + b2 * m) |&gt; \n  \n  ggplot(aes(x = m)) +\n  stat_lineribbon(aes(y = mu),\n                  .width = 0.89, \n                  color = \"blue\", fill = alpha(\"blue\", 1/3), linewidth = 1/2) +\n  geom_point(data = dcc,\n             aes(y = k)) +\n  coord_cartesian(xlim = range(dcc$m),\n                  ylim = range(dcc$k)) +\n  labs(x = \"log body mass (std)\",\n       y = \"kilocal per g (std)\") +\n  facet_grid(\"Univariable\" ~ .)\n\np2\n\n\n\n\nFinally, we’re ready to fit with both predictors included in a multivariable model. The statistical formula is\n\\[\n\\begin{align*}\n\\text{k}_i & \\sim \\operatorname{Normal}(\\mu_i, \\sigma) \\\\\n\\mu_i & = \\alpha + \\beta_1 \\text{n}_i + \\beta_2 \\text{m} \\\\\n\\alpha  & \\sim \\operatorname{Normal}(0, 0.2) \\\\\n\\beta_1 & \\sim \\operatorname{Normal}(0, 0.5) \\\\\n\\beta_2 & \\sim \\operatorname{Normal}(0, 0.5) \\\\\n\\sigma  & \\sim \\operatorname{Exponential}(1).\n\\end{align*}\n\\]\nFit the multivariable model.\n\nmodel_code_5.7 &lt;- '\ndata {\n  int&lt;lower=1&gt; N;\n  vector[N] k;\n  vector[N] n;\n  vector[N] m;\n}\nparameters {\n  real b0;\n  real b1;\n  real b2;\n  real&lt;lower=0&gt; sigma;\n}\nmodel {\n  k ~ normal(b0 + b1 * n + b2 * m, sigma);\n\n  b0 ~ normal(0, 0.2);\n  b1 ~ normal(0, 0.5);\n  b2 ~ normal(0, 0.5);\n  sigma ~ exponential(1);\n}\n'\n\nm5.7 &lt;- stan(\n  data = stan_data,\n  model_code = model_code_5.7,\n  cores = 4, seed = 5)\n\n\nprint(m5.7, probs = c(0.055, 0.945))\n\nInference for Stan model: anon_model.\n4 chains, each with iter=2000; warmup=1000; thin=1; \npost-warmup draws per chain=1000, total post-warmup draws=4000.\n\n       mean se_mean   sd   5.5% 94.5% n_eff Rhat\nb0     0.05    0.00 0.15  -0.18  0.28  3025    1\nb1     0.59    0.01 0.28   0.11  1.03  1667    1\nb2    -0.63    0.01 0.25  -1.00 -0.21  1701    1\nsigma  0.88    0.00 0.19   0.64  1.20  1869    1\nlp__  -8.87    0.04 1.56 -11.68 -7.10  1514    1\n\nSamples were drawn using NUTS(diag_e) at Wed Jul 31 15:50:50 2024.\nFor each parameter, n_eff is a crude measure of effective sample size,\nand Rhat is the potential scale reduction factor on split chains (at \nconvergence, Rhat=1).\n\n\nHere’s an alternative to McElreath’s coefplot() plot code.\n\nbind_rows(\n  as_draws_df(m5.5) |&gt; \n    transmute(`b[0]` = b0, `b[1]` = b1, fit = \"m5.5\"),\n  as_draws_df(m5.6) |&gt; \n    transmute(`b[0]` = b0, `b[2]` = b2, fit = \"m5.6\"),\n  as_draws_df(m5.7) |&gt; \n    transmute(`b[0]` = b0, `b[1]` = b1, `b[2]` = b2, fit = \"m5.7\")\n) |&gt; \n  pivot_longer(contains(\"[\")) |&gt; \n  drop_na(value) |&gt; \n  \n  ggplot(aes(x = value, y = fit)) +\n  stat_pointinterval(.width = 0.89, linewidth = 1/4, shape = 1) +\n  labs(x = \"posterior\",\n       y = NULL) +\n  facet_wrap(~ name, labeller = label_parsed)\n\n\n\n\nOn page 151, McElreath suggested we look at a pairs plot to get a sense of the zero-order correlations.\n\ndcc |&gt; \n  select(k, n, m) |&gt; \n  pairs()\n\n\n\n\nI’m not aware we can facet dagify() objects. But we can take cues from Chapter 4 to link our three DAGs like McElreath did his. First, we’ll recognize the ggplot2 code will be nearly identical for each DAG. So we can just wrap the ggplot2 code into a compact function, like so.\n\ngg_dag &lt;- function(d) {\n  \n  d |&gt; \n    ggplot(aes(x = x, y = y, xend = xend, yend = yend)) +\n    geom_dag_point(alpha = 1/4, size = 10) +\n    geom_dag_text() +\n    geom_dag_edges() +\n    scale_x_continuous(NULL, breaks = NULL, expand = c(0.1, 0.1)) +\n    scale_y_continuous(NULL, breaks = NULL, expand = c(0.2, 0.2)) +\n    theme_dag()\n  \n}\n\nNow we’ll make the three individual DAGs, saving each.\n\n# Left DAG\ndag_coords &lt;- tibble(\n  name = c(\"M\", \"N\", \"K\"),\n  x    = c(1, 3, 2),\n  y    = c(2, 2, 1))\n\ndag1 &lt;- dagify(\n  N ~ M,\n  K ~ M + N,\n  coords = dag_coords) |&gt;\n  gg_dag()\n\n# Middle DAG\ndag2 &lt;- dagify(\n  M ~ N,\n  K ~ M + N,\n  coords = dag_coords) |&gt;\n  gg_dag()\n\n# Right DAG\ndag_coords &lt;- tibble(\n  name = c(\"M\", \"N\", \"K\", \"U\"),\n  x    = c(1, 3, 2, 2),\n  y    = c(2, 2, 1, 2))\n\ndag3 &lt;- dagify(\n  M ~ U,\n  N ~ U,\n  K ~ M + N,\n  coords = dag_coords) |&gt;\n  gg_dag() +\n  geom_point(x = 2, y = 2,\n             shape = 1, size = 10, stroke = 1.25)\n\nNow we combine our gg_dag() plots together with patchwork syntax.\n\ndag1 + dag2 + dag3\n\n\n\n\nLet’s make the counterfactual plots at the bottom of Figure 5.9. Here’s the one on the left. We start with Figure 5.9, lower left.\n\np3 &lt;- as_draws_df(m5.7) |&gt; \n  expand_grid(n = seq(from = -2.5, to = 2.5, length.out = 50),\n              m = 0) |&gt; \n  mutate(mu = b0 + b1 * n + b2 * m) |&gt; \n  \n  ggplot(aes(x = n)) +\n  stat_lineribbon(aes(y = mu),\n                  .width = 0.89, \n                  color = \"blue\", fill = alpha(\"blue\", 1/3), linewidth = 1/2) +\n  coord_cartesian(xlim = range(dcc$n),\n                  ylim = range(dcc$k)) +\n  labs(x = \"neocortex percent (std)\",\n       y = \"kilocal per g (std)\")\n\np3\n\n\n\n\nNext we make Figure 5.9, lower right.\n\np4 &lt;- as_draws_df(m5.7) |&gt; \n  expand_grid(n = 0,\n              m = seq(from = -2.5, to = 2.5, length.out = 50)) |&gt; \n  mutate(mu = b0 + b1 * n + b2 * m) |&gt; \n  \n  ggplot(aes(x = m)) +\n  stat_lineribbon(aes(y = mu),\n                  .width = 0.89, \n                  color = \"blue\", fill = alpha(\"blue\", 1/3), linewidth = 1/2) +\n  coord_cartesian(xlim = range(dcc$n),\n                  ylim = range(dcc$k)) +\n  labs(x = \"log body mass (std)\",\n       y = \"kilocal per g (std)\") +\n  facet_grid(\"Multivariable\" ~ .)\n\np4\n\n\n\n\nNow combine all 4 panels to make the full Figure 5.9.\n\n((p1 + scale_x_continuous(NULL, breaks = NULL)) / p3) |\n  ((p2 + scale_x_continuous(NULL, breaks = NULL)) / p4) & \n  scale_y_continuous(NULL, breaks = NULL)\n\n\n\n\n\n5.2.0.1 Overthinking: Simulating a masking relationship.\nAs a refresher, here’s our focal DAG.\n\ndag_coords &lt;- tibble(\n  name = c(\"M\", \"N\", \"K\"),\n  x    = c(1, 3, 2),\n  y    = c(2, 2, 1))\n\ndagify(N ~ M,\n       K ~ M + N,\n       coords = dag_coords) |&gt;\n  gg_dag()\n\n\n\n\nNow simulate data consistent with that DAG.\n\n# How many cases would you like?\nn &lt;- 100\n\nset.seed(5)\nd_sim &lt;- tibble(m = rnorm(n = n, mean = 0, sd = 1)) |&gt; \n  mutate(n = rnorm(n = n, mean = m, sd = 1)) |&gt; \n  mutate(k = rnorm(n = n, mean = n - m, sd = 1))\n\nUse pairs() to get a sense of what we just simulated.\n\nd_sim |&gt; \n  pairs()\n\n\n\n\nUpdate the stan_data.\n\nstan_data &lt;- d_sim |&gt;\n  compose_data(.n_name = n_prefix(\"N\"))\n\n# What?\nstr(stan_data)\n\nList of 4\n $ m: num [1:100(1d)] -0.8409 1.3844 -1.2555 0.0701 1.7114 ...\n $ n: num [1:100(1d)] -2.836 2.52 -0.58 0.279 1.654 ...\n $ k: num [1:100(1d)] -2.109 0.84 1.665 -0.567 0.218 ...\n $ N: int 100\n\n\nFit the three models to the new data with the sampling() function.\n\nm5.5_sim &lt;- sampling(\n  object = m5.5@stanmodel,\n  data = stan_data,\n  cores = 4, seed = 5)\n\nm5.6_sim &lt;- sampling(\n  object = m5.6@stanmodel,\n  data = stan_data,\n  cores = 4, seed = 5)\n\nm5.7_sim &lt;- sampling(\n  object = m5.7@stanmodel,\n  data = stan_data,\n  cores = 4, seed = 5)\n\nHere’s the coefficient plot.\n\nbind_rows(\n  as_draws_df(m5.5_sim) |&gt; mutate(model = \"m5.5_sim\"),\n  as_draws_df(m5.6_sim) |&gt; mutate(model = \"m5.6_sim\"),\n  as_draws_df(m5.7_sim) |&gt; mutate(model = \"m5.7_sim\")\n) |&gt; \n  pivot_longer(starts_with(\"b\")) |&gt; \n  filter(name != \"b0\") |&gt; \n  drop_na(value) |&gt; \n  mutate(name = case_when(\n    name == \"b1\" ~ \"beta[1]\",\n    name == \"b2\" ~ \"beta[2]\"\n  ) |&gt; factor(levels = c(\"beta[2]\", \"beta[1]\"))) |&gt; \n  \n  ggplot(aes(x = value, y = model)) +\n  geom_vline(xintercept = 0, color = \"white\") +\n  stat_pointinterval(.width = 0.89,\n                     linewidth = 1/2, shape = 1) +\n  labs(x = \"posterior\",\n       y = NULL) +\n  facet_wrap(~ name, labeller = label_parsed, ncol = 1)"
  },
  {
    "objectID": "05.html#categorical-variables",
    "href": "05.html#categorical-variables",
    "title": "5  The Many Variables & The Spurious Waffles",
    "section": "5.3 Categorical variables",
    "text": "5.3 Categorical variables\n\n5.3.0.1 Rethinking: Continuous countries.\n\n\n5.3.1 Binary categories.\nReload the Howell1 data.\n\ndata(Howell1, package = \"rethinking\")\nd &lt;- Howell1\nrm(Howell1)\n\nIf you forgot what these data were like, take a glimpse().\n\nd |&gt;\n  glimpse()\n\nRows: 544\nColumns: 4\n$ height &lt;dbl&gt; 151.7650, 139.7000, 136.5250, 156.8450, 145.4150, 163.8300, 149…\n$ weight &lt;dbl&gt; 47.82561, 36.48581, 31.86484, 53.04191, 41.27687, 62.99259, 38.…\n$ age    &lt;dbl&gt; 63.0, 63.0, 65.0, 41.0, 51.0, 35.0, 32.0, 27.0, 19.0, 54.0, 47.…\n$ male   &lt;int&gt; 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, …\n\n\nThe statistical model including a male dummy might follow the form\n\\[\n\\begin{align*}\n\\text{height}_i & \\sim \\operatorname{Normal}(\\mu_i, \\sigma) \\\\\n\\mu_i   & = \\alpha + \\beta_1 \\text{male}_i \\\\\n\\alpha  & \\sim \\operatorname{Normal}(178, 20) \\\\\n\\beta_1 & \\sim \\operatorname{Normal}(0, 10) \\\\\n\\sigma  & \\sim \\operatorname{Uniform}(0, 50),\n\\end{align*}\n\\]\nwhere \\(\\beta_1\\) is the expected (i.e., average) difference between males and females for height. Here we simulate from our priors and summarise() the results.\n\nset.seed(5)\n\nprior &lt;- tibble(mu_female = rnorm(n = 1e4, mean = 178, sd = 20)) |&gt; \n  mutate(mu_male = mu_female + rnorm(n = 1e4, mean = 0, sd = 10))\n\nprior |&gt; \n  pivot_longer(everything()) |&gt; \n  group_by(name) |&gt; \n  summarise(mean = mean(value),\n            sd   = sd(value),\n            ll   = quantile(value, prob = 0.055),\n            ul   = quantile(value, prob = 0.945)) |&gt; \n  mutate_if(is.double, round, digits = 2)\n\n# A tibble: 2 × 5\n  name       mean    sd    ll    ul\n  &lt;chr&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 mu_female  178.  20.2  146.  210.\n2 mu_male    178.  22.5  142.  214.\n\n\nWe might visualize the two prior predictive distributions as overlapping densities.\n\nprior |&gt; \n  pivot_longer(everything()) |&gt; \n  ggplot(aes(x = value, fill = name, color = name)) +\n  geom_density(linewidth = 2/3, alpha = 2/3) +\n  scale_fill_manual(NULL, values = c(\"red\", \"blue\")) +\n  scale_color_manual(NULL, values = c(\"red\", \"blue\")) +\n  scale_y_continuous(NULL, breaks = NULL) +\n  xlab(\"prior predictive distribution for our dummy groups\") \n\n\n\n\nYep, this parameterization makes \\(\\alpha + \\beta_1\\) more uncertain than \\(\\alpha\\). A nice alternative is to make an index variable. We’ll call it sex, for which 1 = female and 2 = male. “No order is implied. These are just labels” (p. 155).\n\nd &lt;- d |&gt; \n  mutate(sex = ifelse(male == 1, 2, 1) |&gt; as.character())\n\nhead(d)\n\n   height   weight age male sex\n1 151.765 47.82561  63    1   2\n2 139.700 36.48581  63    0   1\n3 136.525 31.86484  65    0   1\n4 156.845 53.04191  41    1   2\n5 145.415 41.27687  51    0   1\n6 163.830 62.99259  35    1   2\n\n\nNote how we have saved sex as a character variable. This will come in handy in just a moment.\nWe can update our statistical model to include sex with the formula\n\\[\n\\begin{align*}\n\\text{height}_i & \\sim \\operatorname{Normal}(\\mu_i, \\sigma) \\\\\n\\mu_i    & = \\alpha_{\\text{sex}[i]} \\\\\n\\alpha_j & \\sim \\operatorname{Normal}(178, 20) & \\text{for } j = 1 \\; \\& \\; 2 \\\\\n\\sigma   & \\sim \\operatorname{Uniform}(0, 50),\n\\end{align*}\n\\]\nwhere now we have rows indexed by \\(i\\) and two levels of sex indexed by \\(j\\).\nWe’ll fit the model 2 ways. The first, m5.8 will follow McElreath’s index-variable approach. The second, m5.8b will use the dummy approach. First, we’ll make the stan_data with the compose_data() function.\n\nstan_data &lt;- d |&gt;\n  compose_data()\n\n# What?\nstr(stan_data)\n\nList of 7\n $ height: num [1:544(1d)] 152 140 137 157 145 ...\n $ weight: num [1:544(1d)] 47.8 36.5 31.9 53 41.3 ...\n $ age   : num [1:544(1d)] 63 63 65 41 51 35 32 27 19 54 ...\n $ male  : int [1:544(1d)] 1 0 0 1 0 1 0 1 0 1 ...\n $ sex   : num [1:544(1d)] 2 1 1 2 1 2 1 2 1 2 ...\n $ n_sex : int 2\n $ n     : int 544\n\n\nDo you see the n_sex value there? When you save variables as characters or as factors, the compose_data() function will automatically compute a corresponding n_ value. To learn more, execute ?compose_data in your console.\nHere we define the two model_codes. I should make a couple comments on the data blocks. Notice how we’ve defined the n_sex scalar in the first, and how we later use that value to define the length of the a vector in the parameters block. When we use values like that, as well as how we’ve been using n in all previous models, those values are always integers, which we declared in the data block by stating int. Up until this point, we have only been using integers as scalars. All of our primary data values have been placed in vectors. In Stan, vectors an be used for real and complex values, but not integers. If you want to feed in a series of integer values as data, you generally need to use an array, which is what we’re doing with the syntax of array[n] int sex; in the first data block, below. This is important because if you want to use McElreath’s index-variable approach, the index variable should be an integer. Note, however, that when you use the dummy-variable approach, you can save the dummy variables as either integers (saved in an array) or as real values (typically saved in a vector, but also possibly in an array). In my experience, this is all easy to mix up, so do spend some time looking through the Data Types and Declarations section of the Stan Reference Manual (Stan Development Team, 2024).\n\n# Index variable approach\nmodel_code_5.8 &lt;- '\ndata {\n  int&lt;lower=1&gt; n;\n  int&lt;lower=1&gt; n_sex;\n  vector[n] height;\n  array[n] int sex;\n}\nparameters {\n  vector[n_sex] a;\n  real&lt;lower=0,upper=50&gt; sigma;\n}\nmodel {\n  height ~ normal(a[sex], sigma);\n  \n  a ~ normal(178, 20);\n  \n  // As an alternative, this syntax works in this example, \n  // and allows the prior to differ by level\n  // a[1] ~ normal(178, 20);\n  // a[2] ~ normal(178, 20);\n  \n  // This snytax does not work\n  // a[sex] ~ normal(178, 20);\n  \n  sigma ~ uniform(0, 50);\n}\n'\n\n# Dummy variable approach\nmodel_code_5.8b &lt;- '\ndata {\n  int&lt;lower=1&gt; n;\n  vector[n] height;\n  vector[n] male;\n}\nparameters {\n  real b0;\n  real b1;\n  real&lt;lower=0,upper=50&gt; sigma;\n}\nmodel {\n  height ~ normal(b0 + b1 * male, sigma);\n  \n  b0 ~ normal(178, 20);\n  b1 ~ normal(0, 10);\n  sigma ~ uniform(0, 50);\n}\n'\n\nFit the models with stan().\n\nm5.8 &lt;- stan(\n  data = stan_data,\n  model_code = model_code_5.8,\n  cores = 4, seed = 5)\n\nm5.8b &lt;- stan(\n  data = stan_data,\n  model_code = model_code_5.8b,\n  cores = 4, seed = 5)\n\nCheck the model summaries.\n\nprint(m5.8, probs = c(0.055, 0.945))\n\nInference for Stan model: anon_model.\n4 chains, each with iter=2000; warmup=1000; thin=1; \npost-warmup draws per chain=1000, total post-warmup draws=4000.\n\n          mean se_mean   sd     5.5%    94.5% n_eff Rhat\na[1]    134.92    0.02 1.64   132.30   137.51  4469    1\na[2]    142.54    0.03 1.70   139.82   145.30  3741    1\nsigma    27.41    0.01 0.84    26.11    28.77  3513    1\nlp__  -2074.04    0.03 1.26 -2076.34 -2072.71  1896    1\n\nSamples were drawn using NUTS(diag_e) at Wed Aug 14 09:18:56 2024.\nFor each parameter, n_eff is a crude measure of effective sample size,\nand Rhat is the potential scale reduction factor on split chains (at \nconvergence, Rhat=1).\n\nprint(m5.8b, probs = c(0.055, 0.945))\n\nInference for Stan model: anon_model.\n4 chains, each with iter=2000; warmup=1000; thin=1; \npost-warmup draws per chain=1000, total post-warmup draws=4000.\n\n          mean se_mean   sd     5.5%    94.5% n_eff Rhat\nb0      135.10    0.03 1.59   132.52   137.65  2371    1\nb1        7.02    0.05 2.26     3.48    10.55  2519    1\nsigma    27.42    0.02 0.84    26.16    28.80  2585    1\nlp__  -2072.70    0.03 1.24 -2075.06 -2071.39  1616    1\n\nSamples were drawn using NUTS(diag_e) at Wed Aug 14 09:19:22 2024.\nFor each parameter, n_eff is a crude measure of effective sample size,\nand Rhat is the potential scale reduction factor on split chains (at \nconvergence, Rhat=1).\n\n\nCompare the posteriors, by model type.\n\nbind_rows(\n  as_draws_df(m5.8) |&gt; \n    transmute(.draw = .draw,\n              female = `a[1]`,\n              male = `a[2]`,\n              diff = `a[1]` - `a[2]`),\n  as_draws_df(m5.8b) |&gt; \n    transmute(.draw = .draw,\n              female = b0,\n              male = b0 + b1,\n              diff = -b1)\n) |&gt; \n  mutate(type = rep(c(\"index\", \"dummy\"), each = n() / 2)) |&gt; \n  pivot_longer(female:diff) |&gt; \n  \n  ggplot(aes(x = value, color = type, fill = type)) +\n  stat_slab(alpha = 0.5, normalize = \"panels\", linewidth = 0) +\n  # At the moment, this method fails of you alter the .width argument;\n  # see: https://github.com/mjskay/ggdist/issues/27\n  stat_pointinterval(position = position_dodge(width = 0.15, preserve = \"single\")) +\n  scale_y_continuous(NULL, breaks = NULL, expand = expansion(mult = 0)) +\n  xlab(\"posterior\") +\n  facet_wrap( ~ name, scales = \"free_x\")\n\n\n\n\n\n\n5.3.2 Many categories.\nLoad the milk data.\n\ndata(milk, package = \"rethinking\")\nd &lt;- milk\nrm(milk)\n\nWith the tidyverse, we can peek at clade with distinct() in the place of base-R unique().\n\nd |&gt;\n  distinct(clade)\n\n             clade\n1    Strepsirrhine\n2 New World Monkey\n3 Old World Monkey\n4              Ape\n\n\nNow add a clade_id index variable.\n\nd &lt;- d |&gt; \n  mutate(clade_id = as.integer(clade) |&gt; as.character()) |&gt; \n  # Add `clade` dummies\n  mutate(ape = ifelse(clade == \"Ape\", 1, 0),\n         nwm = ifelse(clade == \"New World Monkey\", 1, 0),\n         owm = ifelse(clade == \"Old World Monkey\", 1, 0),\n         strepsirrhine = ifelse(clade == \"Strepsirrhine\", 1, 0)) |&gt; \n  # Standardize the criterion\n  mutate(k = (kcal.per.g - mean(kcal.per.g)) / sd(kcal.per.g))\n\n# What?\nd |&gt;\n  distinct(clade, clade_id, ape, nwm, owm, strepsirrhine) |&gt; \n  arrange(clade)\n\n             clade clade_id ape nwm owm strepsirrhine\n1              Ape        1   1   0   0             0\n2 New World Monkey        2   0   1   0             0\n3 Old World Monkey        3   0   0   1             0\n4    Strepsirrhine        4   0   0   0             1\n\n\nOur statistical model follows the form\n\\[\n\\begin{align*}\n\\text{k}_i & \\sim \\operatorname{Normal}(\\mu_i, \\sigma) \\\\\n\\mu_i    & = \\alpha_{\\text{clade-id}[i]} \\\\\n\\alpha_j & \\sim \\operatorname{Normal}(0, 0.5), & \\text{for } j = 1, \\dots, 4 \\\\\n\\sigma   & \\sim \\operatorname{Exponential}(1).\n\\end{align*}\n\\]\nWe might also fit this model using one-hot encoding, following the form\n\\[\n\\begin{align*}\n\\text{k}_i & \\sim \\operatorname{Normal}(\\mu_i, \\sigma) \\\\\n\\mu_i    & = \\beta_0 \\text{ape}_i + \\beta_1 \\text{nwm}_i + \\beta_2 \\text{owm}_i + \\beta_3 \\text{strepsirrhine}_i \\\\\n\\beta_0, \\dots, \\beta_3 & \\sim \\operatorname{Normal}(0, 0.5), \\\\\n\\sigma   & \\sim \\operatorname{Exponential}(1).\n\\end{align*}\n\\]\nMake the stan_data with the compose_data() function.\n\nstan_data &lt;- d |&gt;\n  select(k, clade, clade_id, ape, nwm, owm, strepsirrhine) |&gt; \n  compose_data()\n\n# What?\nstr(stan_data)\n\nList of 10\n $ k            : num [1:29(1d)] -0.94 -0.816 -1.126 -1.002 -0.259 ...\n $ clade        : num [1:29(1d)] 4 4 4 4 4 2 2 2 2 2 ...\n $ n_clade      : int 4\n $ clade_id     : num [1:29(1d)] 4 4 4 4 4 2 2 2 2 2 ...\n $ n_clade_id   : int 4\n $ ape          : num [1:29(1d)] 0 0 0 0 0 0 0 0 0 0 ...\n $ nwm          : num [1:29(1d)] 0 0 0 0 0 1 1 1 1 1 ...\n $ owm          : num [1:29(1d)] 0 0 0 0 0 0 0 0 0 0 ...\n $ strepsirrhine: num [1:29(1d)] 1 1 1 1 1 0 0 0 0 0 ...\n $ n            : int 29\n\n\nDefine the two model_codes. Note how we’ve saved the n_clade_id variable as an integer in an array, in the first, which allows us to use it as an index in the model block.\n\n# Index variable approach\nmodel_code_5.9 &lt;- '\ndata {\n  int&lt;lower=1&gt; n;\n  int&lt;lower=1&gt; n_clade_id;\n  vector[n] k;\n  array[n] int clade_id;\n}\nparameters {\n  vector[n_clade_id] a;\n  real&lt;lower=0&gt; sigma;\n}\nmodel {\n  k ~ normal(a[clade_id], sigma);\n  \n  a ~ normal(0, 0.5);\n  sigma ~ exponential(1);\n}\n'\n\n# One-hot encoding approach\nmodel_code_5.9b &lt;- '\ndata {\n  int&lt;lower=1&gt; n;\n  vector[n] k;\n  vector[n] ape;\n  vector[n] nwm;\n  vector[n] owm;\n  vector[n] strepsirrhine;\n}\nparameters {\n  real b0;\n  real b1;\n  real b2;\n  real b3;\n  real&lt;lower=0&gt; sigma;\n}\nmodel {\n  k ~ normal(b0 * ape + b1 * nwm + b2 * owm + b3 * strepsirrhine, sigma);\n  \n  b0 ~ normal(0, 0.5);\n  b1 ~ normal(0, 0.5);\n  b2 ~ normal(0, 0.5);\n  b3 ~ normal(0, 0.5);\n  // This also works\n  // [b0, b1, b2, b3] ~ normal(0, 0.5);\n  sigma ~ exponential(1);\n}\n'\n\nFit the two versions of the model with stan().\n\nm5.9 &lt;- stan(\n  data = stan_data,\n  model_code = model_code_5.9,\n  cores = 4, seed = 5)\n\nm5.9b &lt;- stan(\n  data = stan_data,\n  model_code = model_code_5.9b,\n  cores = 4, seed = 5)\n\nCheck the model summaries.\n\nprint(m5.9, probs = c(0.055, 0.945))\n\nInference for Stan model: anon_model.\n4 chains, each with iter=2000; warmup=1000; thin=1; \npost-warmup draws per chain=1000, total post-warmup draws=4000.\n\n        mean se_mean   sd   5.5% 94.5% n_eff Rhat\na[1]   -0.47    0.00 0.24  -0.85 -0.08  5467    1\na[2]    0.34    0.00 0.24  -0.04  0.71  4266    1\na[3]    0.64    0.00 0.28   0.19  1.06  4810    1\na[4]   -0.54    0.00 0.30  -1.01 -0.05  4111    1\nsigma   0.80    0.00 0.12   0.64  1.00  3459    1\nlp__  -11.32    0.04 1.67 -14.28 -9.32  1753    1\n\nSamples were drawn using NUTS(diag_e) at Wed Aug 14 09:22:12 2024.\nFor each parameter, n_eff is a crude measure of effective sample size,\nand Rhat is the potential scale reduction factor on split chains (at \nconvergence, Rhat=1).\n\nprint(m5.9b, probs = c(0.055, 0.945))\n\nInference for Stan model: anon_model.\n4 chains, each with iter=2000; warmup=1000; thin=1; \npost-warmup draws per chain=1000, total post-warmup draws=4000.\n\n        mean se_mean   sd   5.5% 94.5% n_eff Rhat\nb0     -0.46    0.00 0.24  -0.84 -0.08  4740    1\nb1      0.35    0.00 0.24  -0.03  0.72  4518    1\nb2      0.63    0.00 0.27   0.20  1.06  4452    1\nb3     -0.56    0.00 0.30  -1.03 -0.07  4432    1\nsigma   0.80    0.00 0.12   0.64  1.01  3321    1\nlp__  -11.32    0.04 1.68 -14.37 -9.34  1759    1\n\nSamples were drawn using NUTS(diag_e) at Wed Jul 31 16:17:54 2024.\nFor each parameter, n_eff is a crude measure of effective sample size,\nand Rhat is the potential scale reduction factor on split chains (at \nconvergence, Rhat=1).\n\n\nThe results are the same within HMC variance.\nDisplay the results in a coefficient plot.\n\nbind_rows(\n  as_draws_df(m5.9) |&gt; \n    transmute(.draw = .draw,\n              ape = `a[1]`,\n              nwm = `a[2]`,\n              owm = `a[3]`,\n              strepsirrhine = `a[4]`),\n  as_draws_df(m5.9b) |&gt;\n    transmute(.draw = .draw,\n              ape = b0,\n              nwm = b1,\n              owm = b2,\n              strepsirrhine = b3)\n) |&gt;\n  mutate(type = rep(c(\"index\", \"one-hot\"), each = n() / 2)) |&gt; \n  pivot_longer(ape:strepsirrhine) |&gt; \n  mutate(name = fct_rev(name)) |&gt; \n  \n  ggplot(aes(x = value, y = name, color = type)) +\n  stat_pointinterval(point_interval = mean_qi, .width = 0.89, \n                     position = position_dodge(width = -0.5),\n                     linewidth = 1/2, shape = 1) +\n  labs(x = \"expected kcal (std)\",\n       y = NULL)\n\n\n\n\nThis is a good place to introduce the tidybayes::spread_draws() function, which can be handy for extracting posterior draws in a long format. When you have a model that uses an indexed parameter, such as the a parameter in m5.9, you can request the draws for each of those indices using [] notation. Note below how we have indicated we want those indices named j with our a[j] syntax. We could have also called them something more descriptive like clade_id, or more generic like index.\n\nm5.9 |&gt; \n  spread_draws(a[j]) |&gt;\n  # spread_draws(a[clade_id]) |&gt;  # More descriptive\n  # spread_draws(a[index]) |&gt;     # More generic \n  arrange(.draw) |&gt; \n  head(n = 10)\n\n# A tibble: 10 × 5\n# Groups:   j [4]\n       j      a .chain .iteration .draw\n   &lt;int&gt;  &lt;dbl&gt;  &lt;int&gt;      &lt;int&gt; &lt;int&gt;\n 1     1 -0.297      1          1     1\n 2     2  0.514      1          1     1\n 3     3  0.496      1          1     1\n 4     4 -0.671      1          1     1\n 5     1 -0.737      1          2     2\n 6     2  0.211      1          2     2\n 7     3  0.480      1          2     2\n 8     4 -0.169      1          2     2\n 9     1 -0.515      1          3     3\n10     2  0.567      1          3     3\n\n\nThis kind of long-formatted output can make for thriftier post-processing code for, say, coefficient plots like the one above.\n\nm5.9 |&gt; \n  spread_draws(a[clade_id]) |&gt;\n  left_join(d |&gt; \n              distinct(clade_id, clade) |&gt; \n              mutate(clade_id = as.integer(clade_id)),\n            by = join_by(clade_id)) |&gt; \n  mutate(clade = fct_rev(clade)) |&gt;\n  \n  ggplot(aes(x = a, y = clade)) +\n  stat_pointinterval(point_interval = mean_qi, .width = 0.89, \n                     linewidth = 1/2, shape = 1) +\n  labs(x = \"expected kcal (std)\",\n       y = NULL)\n\n\n\n\nOkay, let’s simulate some “made up categories” (p. 157). We’ll save the variable as a factor house, and an index house_id.\n\nhouses &lt;- c(\"Gryffindor\", \"Hufflepuff\", \"Ravenclaw\", \"Slytherin\")\n\nset.seed(63)\nd &lt;- d |&gt; \n  mutate(house = sample(rep(houses, each = 8), size = n()) |&gt; \n           factor(levels = houses)) |&gt; \n  mutate(house_id = as.integer(house) |&gt; as.character())\n\n# What?\nd |&gt; \n  count(house, house_id)\n\n       house house_id n\n1 Gryffindor        1 8\n2 Hufflepuff        2 7\n3  Ravenclaw        3 8\n4  Slytherin        4 6\n\n\nMcElreath’s m5.10 followed the statistical formula of\n\\[\n\\begin{align*}\n\\text{kcal.per.g-s}_i & \\sim \\operatorname{Normal}(\\mu_i, \\sigma) \\\\\n\\mu_i    & = \\alpha_{\\color{#8B1A1A}{\\text{clade}[i]}} + \\beta_{\\color{#8B1A1A}{\\text{house}[i]}} \\\\\n\\alpha_{\\color{#8B1A1A}{\\text{clade}, j}} & \\sim \\operatorname{Normal}(0, 0.5), && \\color{#8B1A1A}{\\text{for } j = 1, \\dots, 4} \\\\\n\\beta_{\\color{#8B1A1A}{\\text{house}, k}} & \\sim \\operatorname{Normal}(0, 0.5), && \\color{#8B1A1A}{\\text{for } k = 1, \\dots, 4} \\\\\n\\sigma   & \\sim \\operatorname{Exponential}(1),\n\\end{align*}\n\\]\nwhere there is an \\(\\alpha_\\text{clade}\\) “intercept” for each of the four levels of clade and an \\(\\beta_\\text{house}\\) “intercept” for each of the four levels of house. But there is no overall intercept, \\(\\alpha\\), that stands for the expected value when all the predictors are set to 0.\nUpdate the stan_data with the compose_data() function.\n\nstan_data &lt;- d |&gt;\n  select(k, clade, clade_id, ape, nwm, owm, strepsirrhine, house, house_id) |&gt; \n  compose_data()\n\n# What?\nstr(stan_data)\n\nList of 14\n $ k            : num [1:29(1d)] -0.94 -0.816 -1.126 -1.002 -0.259 ...\n $ clade        : num [1:29(1d)] 4 4 4 4 4 2 2 2 2 2 ...\n $ n_clade      : int 4\n $ clade_id     : num [1:29(1d)] 4 4 4 4 4 2 2 2 2 2 ...\n $ n_clade_id   : int 4\n $ ape          : num [1:29(1d)] 0 0 0 0 0 0 0 0 0 0 ...\n $ nwm          : num [1:29(1d)] 0 0 0 0 0 1 1 1 1 1 ...\n $ owm          : num [1:29(1d)] 0 0 0 0 0 0 0 0 0 0 ...\n $ strepsirrhine: num [1:29(1d)] 1 1 1 1 1 0 0 0 0 0 ...\n $ house        : num [1:29(1d)] 1 2 3 1 3 2 1 3 4 1 ...\n $ n_house      : int 4\n $ house_id     : num [1:29(1d)] 1 2 3 1 3 2 1 3 4 1 ...\n $ n_house_id   : int 4\n $ n            : int 29\n\n\nDefine model_code_5.10.\n\n# Index variable approach\nmodel_code_5.10 &lt;- '\ndata {\n  int&lt;lower=1&gt; n;\n  int&lt;lower=1&gt; n_clade_id;\n  int&lt;lower=1&gt; n_house_id;\n  vector[n] k;\n  array[n] int clade_id;\n  array[n] int house_id;\n}\nparameters {\n  vector[n_clade_id] a;\n  vector[n_house_id] b;\n  real&lt;lower=0&gt; sigma;\n}\nmodel {\n  k ~ normal(a[clade_id] + b[house_id], sigma);\n  \n  a ~ normal(0, 0.5);\n  b ~ normal(0, 0.5);\n  sigma ~ exponential(1);\n}\n'\n\nFit the models with stan().\n\nm5.10 &lt;- stan(\n  data = stan_data,\n  model_code = model_code_5.10,\n  cores = 4, seed = 5)\n\nCheck the summary.\n\nprint(m5.10, probs = c(0.055, 0.945))\n\nInference for Stan model: anon_model.\n4 chains, each with iter=2000; warmup=1000; thin=1; \npost-warmup draws per chain=1000, total post-warmup draws=4000.\n\n        mean se_mean   sd   5.5% 94.5% n_eff Rhat\na[1]   -0.40    0.01 0.28  -0.83  0.06  3048    1\na[2]    0.36    0.01 0.28  -0.08  0.80  2859    1\na[3]    0.52    0.01 0.32   0.01  1.02  3553    1\na[4]   -0.47    0.01 0.32  -0.97  0.06  3920    1\nb[1]   -0.09    0.01 0.29  -0.54  0.38  3243    1\nb[2]   -0.19    0.01 0.29  -0.66  0.28  3222    1\nb[3]   -0.15    0.01 0.29  -0.63  0.31  3250    1\nb[4]    0.47    0.01 0.31  -0.03  0.97  3603    1\nsigma   0.78    0.00 0.12   0.61  0.99  3714    1\nlp__  -11.32    0.06 2.38 -15.56 -8.22  1555    1\n\nSamples were drawn using NUTS(diag_e) at Wed Aug 14 09:24:36 2024.\nFor each parameter, n_eff is a crude measure of effective sample size,\nand Rhat is the potential scale reduction factor on split chains (at \nconvergence, Rhat=1).\n\n\nHere’s the coefficient plot for the \\(a_{[i]}\\) parameters.\n\nas_draws_df(m5.10) |&gt; \n  pivot_longer(starts_with(\"a\")) |&gt; \n  mutate(clade_id = str_extract(name, \"\\\\d\") |&gt; \n           as.integer()) |&gt; \n  left_join(d |&gt; \n              distinct(clade, clade_id) |&gt; \n              mutate(clade_id = as.integer(clade_id)),\n            by = join_by(clade_id)) |&gt; \n  mutate(y = str_c(name, \"~('\", clade, \"')\")) |&gt; \n  \n  ggplot(aes(x = value, y = y)) +\n  stat_halfeye(.width = 0.89) +\n  scale_y_discrete(labels = ggplot2:::parse_safe, expand = expansion(mult = 0.1)) +\n  labs(x = \"posterior\", \n       y = NULL) +\n  theme(axis.text.y = element_text(hjust = 0))\n\n\n\n\nHere’s the coefficient plot for the new \\(b_{[i]}\\) parameters.\n\nas_draws_df(m5.10) |&gt; \n  pivot_longer(starts_with(\"b\")) |&gt; \n  mutate(house_id = str_extract(name, \"\\\\d\") |&gt; \n           as.integer()) |&gt; \n  left_join(d |&gt; \n              distinct(house, house_id) |&gt; \n              mutate(house_id = as.integer(house_id)),\n            by = join_by(house_id)) |&gt; \n  mutate(y = str_c(name, \"~('\", house, \"')\")) |&gt; \n  \n  ggplot(aes(x = value, y = y)) +\n  stat_halfeye(.width = 0.89) +\n  scale_y_discrete(labels = ggplot2:::parse_safe, expand = expansion(mult = 0.1)) +\n  labs(x = \"posterior\", \n       y = NULL) +\n  theme(axis.text.y = element_text(hjust = 0))\n\n\n\n\nThe spread_draws() function can be handy for models with multiple index parameters, like a and b.\n\nm5.10 |&gt; \n  spread_draws(a[j], b[k]) |&gt; \n  head(n = 10)\n\n# A tibble: 10 × 7\n# Groups:   j, k [4]\n       j       a .chain .iteration .draw     k       b\n   &lt;int&gt;   &lt;dbl&gt;  &lt;int&gt;      &lt;int&gt; &lt;int&gt; &lt;int&gt;   &lt;dbl&gt;\n 1     1 -0.408       1          1     1     1  0.0491\n 2     1 -0.408       1          1     1     2 -0.623 \n 3     1 -0.408       1          1     1     3  0.0159\n 4     1 -0.408       1          1     1     4  0.152 \n 5     1  0.0574      1          2     2     1 -0.0444\n 6     1  0.0574      1          2     2     2 -0.760 \n 7     1  0.0574      1          2     2     3 -0.614 \n 8     1  0.0574      1          2     2     4 -0.130 \n 9     1 -0.362       1          3     3     1 -0.105 \n10     1 -0.362       1          3     3     2 -0.175 \n\n\nFor example, here’s how you can use spread_draws() to make the coefficient plots from above with slightly thriftier code.\n\nm5.10 |&gt; \n  spread_draws(a[clade_id]) |&gt; \n  left_join(d |&gt; \n              distinct(clade, clade_id) |&gt; \n              mutate(clade_id = as.integer(clade_id)),\n            by = join_by(clade_id)) |&gt; \n  mutate(y = str_c(\"a[\", clade_id,  \"]~('\", clade, \"')\")) |&gt; \n  \n  ggplot(aes(x = a, y = y)) +\n  stat_halfeye(.width = 0.89) +\n  scale_y_discrete(labels = ggplot2:::parse_safe, expand = expansion(mult = 0.1)) +\n  labs(x = \"posterior\", \n       y = NULL) +\n  theme(axis.text.y = element_text(hjust = 0))\n\n\n\nm5.10 |&gt; \n  spread_draws(b[house_id]) |&gt; \n  left_join(d |&gt; \n              distinct(house, house_id) |&gt; \n              mutate(house_id = as.integer(house_id)),\n            by = join_by(house_id)) |&gt; \n  mutate(y = str_c(\"b[\", house_id,  \"]~('\", house, \"')\")) |&gt; \n  \n  ggplot(aes(x = b, y = y)) +\n  stat_halfeye(.width = 0.89) +\n  scale_y_discrete(labels = ggplot2:::parse_safe, expand = expansion(mult = 0.1)) +\n  labs(x = \"posterior\", \n       y = NULL) +\n  theme(axis.text.y = element_text(hjust = 0))\n\n\n\n\n\n5.3.2.1 Rethinking: Differences and statistical significance."
  },
  {
    "objectID": "05.html#summary",
    "href": "05.html#summary",
    "title": "5  The Many Variables & The Spurious Waffles",
    "section": "5.4 Summary",
    "text": "5.4 Summary"
  },
  {
    "objectID": "05.html#session-info",
    "href": "05.html#session-info",
    "title": "5  The Many Variables & The Spurious Waffles",
    "section": "Session info",
    "text": "Session info\n\nsessionInfo()\n\nR version 4.4.0 (2024-04-24)\nPlatform: aarch64-apple-darwin20\nRunning under: macOS Ventura 13.4\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: America/Chicago\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n [1] dagitty_0.3-4      ggdag_0.2.12       tigris_2.1         posterior_1.6.0   \n [5] patchwork_1.2.0    rstan_2.32.6       StanHeaders_2.32.7 tidybayes_3.0.6   \n [9] lubridate_1.9.3    forcats_1.0.0      stringr_1.5.1      dplyr_1.1.4       \n[13] purrr_1.0.2        readr_2.1.5        tidyr_1.3.1        tibble_3.2.1      \n[17] ggplot2_3.5.1      tidyverse_2.0.0   \n\nloaded via a namespace (and not attached):\n [1] DBI_1.2.2            gridExtra_2.3        inline_0.3.19       \n [4] rlang_1.1.4          magrittr_2.0.3       matrixStats_1.3.0   \n [7] e1071_1.7-14         compiler_4.4.0       mgcv_1.9-1          \n[10] loo_2.8.0            vctrs_0.6.5          pkgconfig_2.0.3     \n[13] shape_1.4.6.1        arrayhelpers_1.1-0   fastmap_1.1.1       \n[16] backports_1.5.0      labeling_0.4.3       ggraph_2.2.1        \n[19] utf8_1.2.4           cmdstanr_0.8.1       rmarkdown_2.26      \n[22] tzdb_0.4.0           ps_1.7.6             xfun_0.43           \n[25] cachem_1.0.8         jsonlite_1.8.8       tweenr_2.0.3        \n[28] uuid_1.2-0           parallel_4.4.0       R6_2.5.1            \n[31] stringi_1.8.4        boot_1.3-30          Rcpp_1.0.12         \n[34] knitr_1.46           Matrix_1.7-0         splines_4.4.0       \n[37] igraph_2.0.3         timechange_0.3.0     tidyselect_1.2.1    \n[40] viridis_0.6.5        rstudioapi_0.16.0    abind_1.4-5         \n[43] yaml_2.3.8           codetools_0.2-20     rethinking_2.40     \n[46] curl_5.2.1           processx_3.8.4       pkgbuild_1.4.4      \n[49] lattice_0.22-6       withr_3.0.0          coda_0.19-4.1       \n[52] evaluate_0.23        sf_1.0-16            polyclip_1.10-6     \n[55] units_0.8-5          proxy_0.4-27         RcppParallel_5.1.7  \n[58] ggdist_3.3.2         pillar_1.9.0         tensorA_0.36.2.1    \n[61] KernSmooth_2.23-22   checkmate_2.3.1      stats4_4.4.0        \n[64] distributional_0.4.0 generics_0.1.3       hms_1.1.3           \n[67] munsell_0.5.1        scales_1.3.0         class_7.3-22        \n[70] glue_1.7.0           tools_4.4.0          graphlayouts_1.1.1  \n[73] mvtnorm_1.2-5        tidygraph_1.3.1      grid_4.4.0          \n[76] QuickJSR_1.1.3       colorspace_2.1-0     nlme_3.1-164        \n[79] ggforce_0.4.2        cli_3.6.3            rappdirs_0.3.3      \n[82] fansi_1.0.6          svUnit_1.0.6         viridisLite_0.4.2   \n[85] V8_4.4.2             gtable_0.3.5         digest_0.6.35       \n[88] classInt_0.4-10      ggrepel_0.9.5        htmlwidgets_1.6.4   \n[91] farver_2.1.1         memoise_2.0.1        htmltools_0.5.8.1   \n[94] lifecycle_1.0.4      httr_1.4.7           MASS_7.3-60.2"
  },
  {
    "objectID": "05.html#comments",
    "href": "05.html#comments",
    "title": "5  The Many Variables & The Spurious Waffles",
    "section": "Comments",
    "text": "Comments\n\n\n\n\nHinde, K., & Milligan, L. A. (2011). Primate milk: Proximate mechanisms and ultimate perspectives. Evolutionary Anthropology: Issues, News, and Reviews, 20(1), 9–23. https://doi.org/10.1002/evan.20289\n\n\nStan Development Team. (2024). Stan reference manual, Version 2.35. https://mc-stan.org/docs/reference-manual/\n\n\nWalker, K. (2022). Tigris: Load census TIGER/Line shapefiles [Manual]. https://github.com/walkerke/tigris"
  },
  {
    "objectID": "06.html#multicollinearity",
    "href": "06.html#multicollinearity",
    "title": "6  The Haunted DAG & The Causal Terror",
    "section": "6.1 Multicollinearity",
    "text": "6.1 Multicollinearity\n\n6.1.1 Multicollinear legs.\nLet’s simulate some leg data.\n\nn &lt;- 100\nset.seed(909)\n\nd &lt;- tibble(height   = rnorm(n = n, mean = 10, sd = 2),\n            leg_prop = runif(n = n, min = 0.4, max = 0.5)) |&gt; \n  mutate(leg_left  = leg_prop * height + rnorm(n = n, mean = 0, sd = 0.02),\n         leg_right = leg_prop * height + rnorm(n = n, mean = 0, sd = 0.02))\n\nAs you might expect in real-life data, the leg_left and leg_right columns are highly correlated.\n\nd |&gt; \n  summarise(r = cor(leg_left, leg_right) |&gt; round(digits = 4))\n\n# A tibble: 1 × 1\n      r\n  &lt;dbl&gt;\n1  1.00\n\n\nHave you ever even seen a \\(\\rho = .9997\\) correlation, before? Here’s what such data look like in a plot.\n\nd |&gt;\n  ggplot(aes(x = leg_left, y = leg_right)) +\n  geom_point(alpha = 1/2)\n\n\n\n\nAnyway, make the stan_data with the compose_data() function.\n\nstan_data &lt;- d |&gt;\n  compose_data()\n\n# What?\nstr(stan_data)\n\nList of 5\n $ height   : num [1:100(1d)] 5.93 6.51 9.35 9.23 10.36 ...\n $ leg_prop : num [1:100(1d)] 0.454 0.412 0.422 0.431 0.429 ...\n $ leg_left : num [1:100(1d)] 2.68 2.68 3.93 3.96 4.43 ...\n $ leg_right: num [1:100(1d)] 2.71 2.68 3.98 3.99 4.42 ...\n $ n        : int 100\n\n\nDefine the model_code_6.1.\n\nmodel_code_6.1 &lt;- '\ndata {\n  int&lt;lower=1&gt; n;\n  vector[n] height;\n  vector[n] leg_left;\n  vector[n] leg_right;\n}\nparameters {\n  real b0;\n  real b1;\n  real b2;\n  real&lt;lower=0&gt; sigma;\n}\nmodel {\n  vector[n] mu;\n  mu = b0 + b1 * leg_left + b2 * leg_right;\n  height ~ normal(mu, sigma);\n  \n  b0 ~ normal(10, 100);\n  b1 ~ normal(2, 10);\n  b2 ~ normal(2, 10);\n  sigma ~ exponential(1);\n}\n'\n\nHere’s our attempt to predict height with both legs with stan().\n\nm6.1 &lt;- stan(\n  data = stan_data,\n  model_code = model_code_6.1,\n  cores = 4, seed = 6)\n\nThe model did fit, but we got this warning:\n\nWarning: There were 2007 transitions after warmup that exceeded the maximum treedepth. Increase max_treedepth above 10\n\nWe don’t know that some of those words mean, yet, at this point in the text. But trust me, friends, it’s not good. For now, check the model summary.\n\nprint(m6.1, probs = c(0.055, 0.945))\n\nInference for Stan model: anon_model.\n4 chains, each with iter=2000; warmup=1000; thin=1; \npost-warmup draws per chain=1000, total post-warmup draws=4000.\n\n       mean se_mean   sd  5.5% 94.5% n_eff Rhat\nb0     0.98    0.01 0.28  0.53  1.42  2410    1\nb1     0.15    0.06 2.58 -4.03  4.30  1660    1\nb2     1.85    0.06 2.58 -2.32  6.05  1661    1\nsigma  0.63    0.00 0.05  0.57  0.71  2244    1\nlp__  -5.15    0.04 1.42 -7.87 -3.54  1479    1\n\nSamples were drawn using NUTS(diag_e) at Wed Jul 31 18:43:55 2024.\nFor each parameter, n_eff is a crude measure of effective sample size,\nand Rhat is the potential scale reduction factor on split chains (at \nconvergence, Rhat=1).\n\n\nThe results mimic those in the text. The posterior standard deviations are very large for \\(\\beta_1\\) and \\(\\beta_2\\). Here’s what the damage looks like in a coefficient plot.\n\nas_draws_df(m6.1) |&gt; \n  pivot_longer(b0:sigma) |&gt; \n  mutate(name = fct_rev(name)) |&gt; \n  \n  ggplot(aes(x = value, y = name)) +\n  stat_pointinterval(.width = 0.89, linewidth = 1/2, shape = 1) +\n  labs(x = \"posterior\", \n       y = NULL)\n\n\n\n\nIn the middle of page 164, McElreath suggested we might try this again with different seeds. This is a good place to practice some iteration. Our first step will be to make a custom function that will simulate new data of the same form as above and then immediately fit a model based on m6.1 to those new data. To speed up the process, we’ll use the update() function to avoid recompiling the model. Our custom function, sim_and_fit(), will take two arguments. The seed argument will allow us to keep the results reproducible by setting a seed for the data simulation. The n argument will allow us, should we wish, to change the sample size.\n\nsim_and_sample &lt;- function(seed, n = 100) {\n \n  set.seed(seed)\n  \n  # Simulate the new data\n  stan_data &lt;- tibble(\n    height   = rnorm(n = n, mean = 10, sd = 2),\n    leg_prop = runif(n = n, min = 0.4, max = 0.5)) |&gt; \n    mutate(leg_left  = leg_prop * height + rnorm(n = n, mean = 0, sd = 0.02),\n           leg_right = leg_prop * height + rnorm(n = n, mean = 0, sd = 0.02)) |&gt; \n    compose_data()\n  \n  # Update `m6.1` to the new data\n  sampling &lt;- sampling(\n    object = m6.1@stanmodel,\n    data = stan_data,\n    cores = 4, \n    seed = seed) \n  \n}\n\nNow use sim_and_sample() to make our simulations which correspond to seed values 1:4. By nesting the seed values and the sim_and_sample() function within purrr::map(), the results will be saved within our tibble, sim.\n\nsim &lt;- tibble(seed = 1:4) |&gt; \n  mutate(fit = map(.x = seed, .f = sim_and_sample))\n\nNow extract the posterior draws from each fit with the as_draws_df() function, saving the results in the as_draws_df column.\n\nsim &lt;- sim |&gt; \n  mutate(as_draws_df = map(.x = fit, .f = as_draws_df))\n\nTake a look at what we did.\n\nprint(sim)\n\n# A tibble: 4 × 3\n   seed fit             as_draws_df           \n  &lt;int&gt; &lt;list&gt;          &lt;list&gt;                \n1     1 &lt;stanfit[,4,5]&gt; &lt;draws_df [4,000 × 8]&gt;\n2     2 &lt;stanfit[,4,5]&gt; &lt;draws_df [4,000 × 8]&gt;\n3     3 &lt;stanfit[,4,5]&gt; &lt;draws_df [4,000 × 8]&gt;\n4     4 &lt;stanfit[,4,5]&gt; &lt;draws_df [4,000 × 8]&gt;\n\n\nNow plot.\n\nsim |&gt; \n  select(seed, as_draws_df) |&gt; \n  unnest(as_draws_df) |&gt; \n  pivot_longer(b0:sigma) |&gt; \n  mutate(name = fct_rev(name),\n         seed = factor(seed)) |&gt; \n  \n  ggplot(aes(x = value, y = name, group = seed, color = seed)) +\n  stat_pointinterval(.width = 0.89, linewidth = 1/2, shape = 1,\n                     position = position_dodge(width = -0.5)) +\n  scale_color_viridis_d(option = \"C\", end = 0.6) +\n  labs(x = \"posterior\", \n       y = NULL)\n\n\n\n\nThough the results varied across iterations, the overall pattern was massive uncertainty in the two \\(\\beta\\) parameters.\nHere’s Figure 6.2.\n\n# Left\np1 &lt;- as_draws_df(m6.1) |&gt; \n  ggplot(aes(x = b1, y = b2)) +\n  geom_point(alpha = 1/3) +\n  coord_equal(xlim = c(-8, 10),\n              ylim = c(-8, 10)) \n\n# Right\np2 &lt;- as_draws_df(m6.1) |&gt; \n  ggplot(aes(x = b1 + b2)) +\n  geom_density(adjust = 1/2)\n\n# Combine\np1 | p2\n\n\n\n\nOn page 165, McElreath clarified that from the perspective of stan(), this model may as well be\n\\[\n\\begin{align*}\ny_i   & \\sim \\operatorname{Normal}(\\mu_i, \\sigma) \\\\\n\\mu_i & = \\alpha + (\\beta_1 + \\beta_2) x_i.\n\\end{align*}\n\\]\nNow fit the revised model where we drop leg_right from the equation.\n\nmodel_code_6.2 &lt;- '\ndata {\n  int&lt;lower=1&gt; n;\n  vector[n] height;\n  vector[n] leg_left;\n}\nparameters {\n  real b0;\n  real b1;\n  real&lt;lower=0&gt; sigma;\n}\nmodel {\n  vector[n] mu;\n  mu = b0 + b1 * leg_left;\n  height ~ normal(mu, sigma);\n  \n  b0 ~ normal(10, 100);\n  b1 ~ normal(2, 10);\n  sigma ~ exponential(1);\n}\n'\n\nm6.2 &lt;- stan(\n  data = stan_data,\n  model_code = model_code_6.2,\n  cores = 4, seed = 6)\n\nCheck the new summary.\n\nprint(m6.2, probs = c(0.055, 0.945))\n\nInference for Stan model: anon_model.\n4 chains, each with iter=2000; warmup=1000; thin=1; \npost-warmup draws per chain=1000, total post-warmup draws=4000.\n\n       mean se_mean   sd  5.5% 94.5% n_eff Rhat\nb0     0.99    0.01 0.29  0.53  1.45  1410    1\nb1     1.99    0.00 0.06  1.89  2.09  1450    1\nsigma  0.63    0.00 0.04  0.57  0.71  1652    1\nlp__  -4.86    0.03 1.22 -7.22 -3.56  1424    1\n\nSamples were drawn using NUTS(diag_e) at Wed Jul 31 18:53:29 2024.\nFor each parameter, n_eff is a crude measure of effective sample size,\nand Rhat is the potential scale reduction factor on split chains (at \nconvergence, Rhat=1).\n\n\nThat posterior \\(\\textit{SD}\\) for the leg_left parameter looks much better. Compare this density to the one in Figure 6.2.b.\n\nas_draws_df(m6.2) |&gt; \n  ggplot(aes(x = b1)) +\n  stat_halfeye(.width = 0.89) +\n  scale_y_continuous(NULL, breaks = NULL) +\n  labs(title = \"Just one coefficient needed\")\n\n\n\n\n\n\n6.1.2 Multicollinear milk.\nLoad the milk data and standardize the focal variables with the rethinking::standardize() function.\n\ndata(milk, package = \"rethinking\")\nd &lt;- milk |&gt; \n  mutate(k = rethinking::standardize(kcal.per.g),\n         f = rethinking::standardize(perc.fat),\n         l = rethinking::standardize(perc.lactose))\n\nrm(milk)\n\nMake the stan_data with compose_data().\n\nstan_data &lt;- d |&gt; \n  select(k:l) |&gt; \n  compose_data()\n\n# What?\nglimpse(stan_data)\n\nList of 4\n $ k: num [1:29(1d)] -0.94 -0.816 -1.126 -1.002 -0.259 ...\n  ..- attr(*, \"scaled:center\")= num 0.642\n  ..- attr(*, \"scaled:scale\")= num 0.161\n $ f: num [1:29(1d)] -1.22 -1.03 -1.39 -1.34 -0.47 ...\n  ..- attr(*, \"scaled:center\")= num 34\n  ..- attr(*, \"scaled:scale\")= num 14.3\n $ l: num [1:29(1d)] 1.307 1.011 1.383 1.587 0.257 ...\n  ..- attr(*, \"scaled:center\")= num 49.6\n  ..- attr(*, \"scaled:scale\")= num 14.1\n $ n: int 29\n\n\nDefine the two univariable models, and define the multivariable model, too.\n\n# Univariable models\nmodel_code_6.3 &lt;- '\ndata {\n  int&lt;lower=1&gt; n;\n  vector[n] k;\n  vector[n] f;\n}\nparameters {\n  real b0;\n  real b1;\n  real&lt;lower=0&gt; sigma;\n}\nmodel {\n  vector[n] mu;\n  mu = b0 + b1 * f;\n  k ~ normal(mu, sigma);\n  \n  b0 ~ normal(0, 0.2);\n  b1 ~ normal(0, 0.5);\n  sigma ~ exponential(1);\n}\n'\n\nmodel_code_6.4 &lt;- '\ndata {\n  int&lt;lower=1&gt; n;\n  vector[n] k;\n  vector[n] l;\n}\nparameters {\n  real b0;\n  real b2;\n  real&lt;lower=0&gt; sigma;\n}\nmodel {\n  vector[n] mu;\n  mu = b0 + b2 * l;\n  k ~ normal(mu, sigma);\n  \n  b0 ~ normal(0, 0.2);\n  b2 ~ normal(0, 0.5);\n  sigma ~ exponential(1);\n}\n'\n\n# Multivariable model\nmodel_code_6.5 &lt;- '\ndata {\n  int&lt;lower=1&gt; n;\n  vector[n] k;\n  vector[n] f;\n  vector[n] l;\n}\nparameters {\n  real b0;\n  real b1;\n  real b2;\n  real&lt;lower=0&gt; sigma;\n}\nmodel {\n  vector[n] mu;\n  mu = b0 + b1 * f + b2 * l;\n  k ~ normal(mu, sigma);\n  \n  b0 ~ normal(0, 0.2);\n  b1 ~ normal(0, 0.5);\n  b2 ~ normal(0, 0.5);\n  sigma ~ exponential(1);\n}\n'\n\nFit the models with stan().\n\nm6.3 &lt;- stan(\n  data = stan_data,\n  model_code = model_code_6.3,\n  cores = 4, seed = 6)\n\nm6.4 &lt;- stan(\n  data = stan_data,\n  model_code = model_code_6.4,\n  cores = 4, seed = 6)\n\nm6.5 &lt;- stan(\n  data = stan_data,\n  model_code = model_code_6.5,\n  cores = 4, seed = 6)\n\nCheck the model summaries.\n\nprint(m6.3, probs = c(0.055, 0.945))\n\nInference for Stan model: anon_model.\n4 chains, each with iter=2000; warmup=1000; thin=1; \npost-warmup draws per chain=1000, total post-warmup draws=4000.\n\n      mean se_mean   sd  5.5% 94.5% n_eff Rhat\nb0    0.00    0.00 0.08 -0.13  0.13  3542    1\nb1    0.86    0.00 0.09  0.71  1.00  3619    1\nsigma 0.49    0.00 0.07  0.39  0.61  3083    1\nlp__  4.08    0.03 1.27  1.64  5.43  1595    1\n\nSamples were drawn using NUTS(diag_e) at Wed Jul 31 18:55:22 2024.\nFor each parameter, n_eff is a crude measure of effective sample size,\nand Rhat is the potential scale reduction factor on split chains (at \nconvergence, Rhat=1).\n\nprint(m6.4, probs = c(0.055, 0.945))\n\nInference for Stan model: anon_model.\n4 chains, each with iter=2000; warmup=1000; thin=1; \npost-warmup draws per chain=1000, total post-warmup draws=4000.\n\n       mean se_mean   sd  5.5% 94.5% n_eff Rhat\nb0     0.00    0.00 0.07 -0.12  0.11  3812    1\nb2    -0.90    0.00 0.08 -1.02 -0.77  3893    1\nsigma  0.41    0.00 0.06  0.33  0.51  3086    1\nlp__   8.77    0.03 1.30  6.35 10.15  1890    1\n\nSamples were drawn using NUTS(diag_e) at Wed Jul 31 18:55:48 2024.\nFor each parameter, n_eff is a crude measure of effective sample size,\nand Rhat is the potential scale reduction factor on split chains (at \nconvergence, Rhat=1).\n\nprint(m6.5, probs = c(0.055, 0.945))\n\nInference for Stan model: anon_model.\n4 chains, each with iter=2000; warmup=1000; thin=1; \npost-warmup draws per chain=1000, total post-warmup draws=4000.\n\n       mean se_mean   sd  5.5% 94.5% n_eff Rhat\nb0     0.00    0.00 0.07 -0.11  0.12  2620    1\nb1     0.26    0.00 0.20 -0.05  0.57  1890    1\nb2    -0.66    0.00 0.20 -0.98 -0.34  1845    1\nsigma  0.41    0.00 0.06  0.33  0.52  2367    1\nlp__   9.15    0.04 1.52  6.27 10.87  1361    1\n\nSamples were drawn using NUTS(diag_e) at Wed Jul 31 18:56:13 2024.\nFor each parameter, n_eff is a crude measure of effective sample size,\nand Rhat is the potential scale reduction factor on split chains (at \nconvergence, Rhat=1).\n\n\nHere’s a quick paris() plot of the data.\n\nd |&gt; \n  select(k, f, l) |&gt; \n  pairs()\n\n\n\n\nA DAG might help us make sense of this.\n\ndag_coords &lt;- tibble(\n  name = c(\"L\", \"D\", \"F\", \"K\"),\n  x    = c(1, 2, 3, 2),\n  y    = c(2, 2, 2, 1))\n\ndagify(L ~ D,\n       F ~ D,\n       K ~ L + F,\n       coords = dag_coords) |&gt;\n  \n  ggplot(aes(x = x, y = y, xend = xend, yend = yend)) +\n  geom_dag_point(aes(color = name == \"D\"),\n                 alpha = 1/2, show.legend = FALSE, size = 6.5) +\n  geom_point(x = 2, y = 2, \n             color = \"blue\", shape = 1, size = 6.5, stroke = 1) +\n  geom_dag_text() +\n  geom_dag_edges() +\n  scale_color_manual(values = c(\"black\", \"blue\")) +\n  scale_x_continuous(NULL, breaks = NULL, expand = c(0.1, 0.1)) +\n  scale_y_continuous(NULL, breaks = NULL, expand = c(0.1, 0.1)) +\n  theme_dag()\n\n\n\n\n\n6.1.2.1 Rethinking: Identification guaranteed; comprehension up to you.\n\n\n6.1.2.2 Overthinking: Simulating collinearity.\nFirst we’ll get the data and define the functions. You’ll note I’ve defined my sim_coll() a little differently from McElreath’s sim.coll() in the text. I’ve omitted rep.sim.coll() as an independent function altogether, but computed similar summary information with the summarise() code at the bottom of the block.\n\n# Define a custom function\nsim_coll &lt;- function(seed, rho) {\n  \n  # Simulate the data\n  set.seed(seed)\n  \n  d &lt;- d |&gt; \n    mutate(x = rnorm(n = n(),\n                     mean = perc.fat * rho,\n                     sd = sqrt((1 - rho^2) * var(perc.fat))))\n    \n  # Fit an OLS model\n  m &lt;- lm(data = d,\n          kcal.per.g ~ perc.fat + x)\n  \n  # Extract the parameter SD\n  sqrt(diag(vcov(m)))[2]\n  \n}\n\n# How many simulations per `rho`-value would you like?\nn_seed &lt;- 100\n# How many `rho`-values from 0 to .99 would you like to evaluate the process over?\nn_rho  &lt;- 30\n\nd &lt;- crossing(seed = 1:n_seed,\n              rho  = seq(from = 0, to = 0.99, length.out = n_rho))  |&gt; \n  mutate(parameter_sd = purrr::map2_dbl(.x = seed, .y = rho, .f = sim_coll)) |&gt; \n  group_by(rho) |&gt; \n  # Describe the output by the mean and 95% intervals\n  summarise(mean = mean(parameter_sd),\n            ll   = quantile(parameter_sd, prob = 0.025),\n            ul   = quantile(parameter_sd, prob = 0.975))\n\nWe’ve added 95% interval bands to our version of Figure 5.10.\n\nd |&gt; \n  ggplot(aes(x = rho, y = mean, ymin = ll, ymax = ul)) +\n  geom_smooth(stat = \"identity\",\n              alpha = 1/3, linewidth = 2/3) +\n  labs(x = expression(rho),\n       y = \"parameter SD\") +\n  coord_cartesian(ylim = c(0, 0.0072))"
  },
  {
    "objectID": "06.html#sec-Post-treatment-bias",
    "href": "06.html#sec-Post-treatment-bias",
    "title": "6  The Haunted DAG & The Causal Terror",
    "section": "6.2 Post-treatment bias",
    "text": "6.2 Post-treatment bias\nIt helped me understand the next example by mapping out the sequence of events McElreath described in the second paragraph:\n\nseed and sprout plants\nmeasure heights\napply different antifungal soil treatments (i.e., the experimental manipulation)\nmeasure (a) the heights and (b) the presence of fungus\n\nBased on the design, let’s simulate our data.\n\n# How many plants would you like?\nn &lt;- 100\n\nset.seed(71)\nd &lt;- tibble(h0        = rnorm(n = n, mean = 10, sd = 2), \n            treatment = rep(0:1, each = n / 2),\n            fungus    = rbinom(n = n, size = 1, prob = 0.5 - treatment * 0.4),\n            h1        = h0 + rnorm(n = n, mean = 5 - 3 * fungus, sd = 1))\n\nWe’ll use head() to peek at the data.\n\nhead(d)\n\n# A tibble: 6 × 4\n     h0 treatment fungus    h1\n  &lt;dbl&gt;     &lt;int&gt;  &lt;int&gt; &lt;dbl&gt;\n1  9.14         0      0  14.3\n2  9.11         0      0  15.6\n3  9.04         0      0  14.4\n4 10.8          0      0  15.8\n5  9.16         0      1  11.5\n6  7.63         0      0  11.1\n\n\nAnd here’s a quick summary with tidybayes::mean_qi().\n\nd |&gt; \n  pivot_longer(everything()) |&gt; \n  group_by(name) |&gt; \n  mean_qi(.width = 0.89) |&gt; \n  mutate_if(is.double, round, digits = 2)\n\n# A tibble: 4 × 7\n  name      value .lower .upper .width .point .interval\n  &lt;chr&gt;     &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;    \n1 fungus     0.23   0       1     0.89 mean   qi       \n2 h0         9.96   6.57   13.1   0.89 mean   qi       \n3 h1        14.4   10.6    17.9   0.89 mean   qi       \n4 treatment  0.5    0       1     0.89 mean   qi       \n\n\n\n6.2.1 A prior is born.\nLet’s take a look at the \\(p \\sim \\operatorname{Log-Normal}(0, 0.25)\\) prior distribution.\n\nset.seed(6)\n\n# Simulate\nsim_p &lt;- tibble(sim_p = rlnorm(1e4, meanlog = 0, sdlog = 0.25)) \n\n# Wrangle\nsim_p |&gt; \n  mutate(`exp(sim_p)` = exp(sim_p)) |&gt;\n  gather() |&gt; \n  \n  # Plot\n  ggplot(aes(x = value)) +\n  geom_density(fill = \"gray67\") +\n  scale_x_continuous(breaks = c(0, .5, 1, 1.5, 2, 3, 5)) +\n  scale_y_continuous(NULL, breaks = NULL) +\n  coord_cartesian(xlim = c(0, 6)) +\n  theme(panel.grid.minor.x = element_blank()) +\n  facet_wrap(~ key, scale = \"free_y\", ncol = 1)\n\n\n\n\nSummarize.\n\nsim_p |&gt; \n  mutate(`exp(sim_p)` = exp(sim_p)) |&gt;\n  pivot_longer(everything()) |&gt;\n  group_by(name) |&gt; \n  mean_qi(.width = .89) |&gt; \n  mutate_if(is.double, round, digits = 2)\n\n# A tibble: 2 × 7\n  name       value .lower .upper .width .point .interval\n  &lt;chr&gt;      &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;    \n1 exp(sim_p)  2.92   1.96   4.49   0.89 mean   qi       \n2 sim_p       1.03   0.67   1.5    0.89 mean   qi       \n\n\n“This prior expects anything from 40% shrinkage up to 50% growth” (p. 172). So then, our initial statistical model will follow the form\n\\[\n\\begin{align*}\nh_{1i} & \\sim \\operatorname{Normal}(\\mu_i, \\sigma) \\\\\n\\mu_i  & = h_{0i} \\times p \\\\\np      & \\sim \\operatorname{Log-Normal}(0, 0.25) \\\\\n\\sigma & \\sim \\operatorname{Exponential}(1).\n\\end{align*}\n\\]\nDefine the stan_data and the next model_code.\n\nstan_data &lt;- d |&gt; \n  compose_data()\n\n# str(stan_data)\n\nmodel_code_6.6 &lt;- '\ndata {\n  int&lt;lower=1&gt; n;\n  vector[n] h1;\n  vector[n] h0;\n}\nparameters {\n  real p;\n  real&lt;lower=0&gt; sigma;\n}\nmodel {\n  h1 ~ normal(p * h0, sigma);\n  \n  p ~ lognormal(0, 0.25);\n  sigma ~ exponential(1);\n}\ngenerated quantities {\n  // To be discusssed in Chapter 7\n  vector[n] log_lik;\n  for (i in 1:n) log_lik[i] = normal_lpdf(h1[i] | p * h0[i], sigma);\n}\n'\n\nYou may have noticed we have an exciting new generated quantities with some mysterious code defining log_lik. We won’t be ready to discuss those bits until later in Section 7.2.4 and Section 7.5.1. For now, just let the tension build.\nLet’s fit that model.\n\nm6.6 &lt;- stan(\n  data = stan_data,\n  model_code = model_code_6.6,\n  cores = 4, seed = 6)\n\nCheck the model summary.\n\nprint(m6.6, pars = c(\"p\", \"sigma\"), probs = c(0.055, 0.945))\n\nInference for Stan model: anon_model.\n4 chains, each with iter=2000; warmup=1000; thin=1; \npost-warmup draws per chain=1000, total post-warmup draws=4000.\n\n      mean se_mean   sd 5.5% 94.5% n_eff Rhat\np     1.43       0 0.02 1.40  1.46  3749    1\nsigma 1.82       0 0.13 1.63  2.05  2741    1\n\nSamples were drawn using NUTS(diag_e) at Thu Aug  1 20:47:35 2024.\nFor each parameter, n_eff is a crude measure of effective sample size,\nand Rhat is the potential scale reduction factor on split chains (at \nconvergence, Rhat=1).\n\n\nOur updated model follows the form\n\\[\n\\begin{align*}\nh_{1i}  & \\sim  \\operatorname{Normal}(\\mu_i, \\sigma) \\\\\n\\mu_i   & = h_{0,i} \\times p \\\\\np       & = \\alpha + \\beta_1 \\text{treatment}_i + \\beta_2 \\text{fungus}_i \\\\\n\\alpha  & \\sim \\operatorname{Log-Normal}(0, 0.25) \\\\\n\\beta_1 & \\sim \\operatorname{Normal}(0, 0.5) \\\\\n\\beta_2 & \\sim \\operatorname{Normal}(0, 0.5) \\\\\n\\sigma  & \\sim \\operatorname{Exponential}(1).\n\\end{align*}\n\\]\nDefine model_code_6.7.\n\nmodel_code_6.7 &lt;- '\ndata {\n  int&lt;lower=1&gt; n;\n  vector[n] h1;\n  vector[n] h0;\n  vector[n] treatment;\n  vector[n] fungus;\n}\nparameters {\n  // real p;  // Now defined below in the model section\n  real b0;\n  real b1;\n  real b2;\n  real&lt;lower=0&gt; sigma;\n}\nmodel {\n  vector[n] p;\n  p = b0 + b1 * treatment + b2 * fungus;\n  h1 ~ normal(p .* h0, sigma);\n  \n  b0 ~ lognormal(0, 0.2);\n  b1 ~ normal(0, 0.5);\n  b2 ~ normal(0, 0.5);\n  sigma ~ exponential(1);\n}\ngenerated quantities {\n  // To be discusssed in Chapter 7\n  vector[n] log_lik;\n  for (i in 1:n) log_lik[i] = normal_lpdf(h1[i] | b0 * h0[i] + b1 * treatment[i] * h0[i] + b2 * fungus[i] * h0[i], sigma);\n}\n'\n\nNote the use of the .* operator in the model code. This is a so-called elementwise function, about which you can learn more here.\nLet’s fit that model.\n\nm6.7 &lt;- stan(\n  data = stan_data,\n  model_code = model_code_6.7,\n  cores = 4, seed = 6)\n\nCheck the model summary.\n\nprint(m6.7, pars = c(\"b0\", \"b1\", \"b2\", \"sigma\"), probs = c(0.055, 0.945))\n\nInference for Stan model: anon_model.\n4 chains, each with iter=2000; warmup=1000; thin=1; \npost-warmup draws per chain=1000, total post-warmup draws=4000.\n\n       mean se_mean   sd  5.5% 94.5% n_eff Rhat\nb0     1.48       0 0.02  1.44  1.52  1581    1\nb1     0.00       0 0.03 -0.04  0.05  1633    1\nb2    -0.27       0 0.04 -0.33 -0.21  2099    1\nsigma  1.45       0 0.10  1.29  1.62  2999    1\n\nSamples were drawn using NUTS(diag_e) at Thu Aug  1 20:52:44 2024.\nFor each parameter, n_eff is a crude measure of effective sample size,\nand Rhat is the potential scale reduction factor on split chains (at \nconvergence, Rhat=1).\n\n\nThe results match those displayed in the text.\n\n\n6.2.2 Blocked by consequence.\nTo measure the treatment effect properly, we should omit fungus from the model. This leaves us with the equation\n\\[\n\\begin{align*}\nh_{1i}  & \\sim \\operatorname{Normal}(\\mu_i, \\sigma) \\\\\n\\mu_i   & = h_{0i} \\times (\\alpha + \\beta_1 \\text{treatment}_i) \\\\\n\\alpha  & \\sim \\operatorname{Log-Normal}(0, 0.25) \\\\\n\\beta_1 & \\sim \\operatorname{Normal}(0, 0.5) \\\\\n\\sigma  & \\sim \\operatorname{Exponential}(1).\n\\end{align*}\n\\]\nDefine model_code_6.8.\n\nmodel_code_6.8 &lt;- '\ndata {\n  int&lt;lower=1&gt; n;\n  vector[n] h1;\n  vector[n] h0;\n  vector[n] treatment;\n}\nparameters {\n  real b0;\n  real b1;\n  real&lt;lower=0&gt; sigma;\n}\nmodel {\n  h1 ~ normal(h0 .* (b0 + b1 * treatment), sigma);\n  \n  b0 ~ lognormal(0, 0.2);\n  b1 ~ normal(0, 0.5);\n  sigma ~ exponential(1);\n}\ngenerated quantities {\n  // To be discusssed in Chapter 7\n  vector[n] log_lik;\n  for (i in 1:n) log_lik[i] = normal_lpdf(h1[i] | b0 * h0[i] + b1 * treatment[i] * h0[i], sigma);\n}\n'\n\nFit that model.\n\nm6.8 &lt;- stan(\n  data = stan_data,\n  model_code = model_code_6.8,\n  cores = 4, seed = 6)\n\nCheck the model summary.\n\nprint(m6.8, pars = c(\"b0\", \"b1\", \"sigma\"), probs = c(0.055, 0.945))\n\nInference for Stan model: anon_model.\n4 chains, each with iter=2000; warmup=1000; thin=1; \npost-warmup draws per chain=1000, total post-warmup draws=4000.\n\n      mean se_mean   sd 5.5% 94.5% n_eff Rhat\nb0    1.38       0 0.03 1.34  1.42  1850    1\nb1    0.08       0 0.03 0.03  0.14  1928    1\nsigma 1.79       0 0.13 1.60  2.00  2602    1\n\nSamples were drawn using NUTS(diag_e) at Thu Aug  1 20:53:48 2024.\nFor each parameter, n_eff is a crude measure of effective sample size,\nand Rhat is the potential scale reduction factor on split chains (at \nconvergence, Rhat=1).\n\n\nNow we have a positive treatment effect, \\(\\beta_1\\).\n\n\n6.2.3 Fungus and \\(d\\)-separation.\nLet’s make a DAG.\n\n# define our coordinates\ndag_coords &lt;- tibble(\n  name = c(\"H0\", \"T\", \"F\", \"H1\"),\n  x    = c(1, 5, 4, 3),\n  y    = c(2, 2, 1.5, 1))\n\n# save our DAG\ndag &lt;- dagify(\n  F ~ T,\n  H1 ~ H0 + F,\n  coords = dag_coords)\n\n# plot \ndag |&gt;\n  ggplot(aes(x = x, y = y, xend = xend, yend = yend)) +\n  geom_dag_point(alpha = 1/2, size = 6.5) +\n  geom_dag_text() +\n  geom_dag_edges() + \n  theme_dag()\n\n\n\n\nWe’ll be making a lot of simple DAGs following this format over this chapter. To streamline out plotting code, let’s make a custom plotting function. I’ll call it gg_simple_dag().\n\ngg_simple_dag &lt;- function(d) {\n  \n  d |&gt; \n    ggplot(aes(x = x, y = y, xend = xend, yend = yend)) +\n    geom_dag_point(alpha = 1/2, size = 6.5) +\n    geom_dag_text() +\n    geom_dag_edges() + \n    theme_dag()\n  \n}\n\n# Try `gg_simple_dag()` out!\ndag |&gt; \n  gg_simple_dag()\n\n\n\n\nNote that our ggdag object, dag, will also work with the dagitty::dseparated() function.\n\ndag |&gt; \n  dseparated(\"T\", \"H1\")\n\n[1] FALSE\n\ndag |&gt; \n  dseparated(\"T\", \"H1\", \"F\")\n\n[1] TRUE\n\n\nThe descriptively-named dagitty::mpliedConditionalIndependencies() function will work, too.\n\nimpliedConditionalIndependencies(dag)\n\nF _||_ H0\nH0 _||_ T\nH1 _||_ T | F\n\n\nNow consider a DAG of a different kind of causal structure.\n\n# define our coordinates\ndag_coords &lt;- tibble(\n  name = c(\"H0\", \"H1\", \"M\", \"F\", \"T\"),\n  x    = c(1, 2, 2.5, 3, 4),\n  y    = c(2, 2, 1, 2, 2))\n\n# save our DAG\ndag &lt;- dagify(\n  F ~ M + T,\n  H1 ~ H0 + M,\n  coords = dag_coords)\n\n# plot \ndag |&gt;\n  ggplot(aes(x = x, y = y, xend = xend, yend = yend)) +\n  geom_dag_point(aes(color = name == \"M\"),\n                 alpha = 1/2, show.legend = FALSE, size = 6.5) +\n  geom_point(x = 2.5, y = 1, \n             color = \"blue\", shape = 1, size = 6.5, stroke = 1) +\n  geom_dag_text() +\n  geom_dag_edges() + \n  scale_color_manual(values = c(\"black\", \"blue\")) +\n  theme_dag()\n\n\n\n\nOur custom gg_simple_dag() was a little too brittle to accommodate DAGs that mark of unobserved variables. Since we’ll be making a few more DAGs of this kind, we’ll make one more custom plotting function. We’ll call this one gg_fancy_dag().\n\ngg_fancy_dag &lt;- function(d, x = 1, y = 1, circle = \"U\") {\n  \n  d |&gt; \n    ggplot(aes(x = x, y = y, xend = xend, yend = yend)) +\n    geom_dag_point(aes(color = name == circle),\n                   alpha = 1/2, size = 6.5, show.legend = FALSE) +\n    geom_point(x = x, y = y,\n               color = \"blue\", shape = 1, size = 6.5, stroke = 1) +\n    geom_dag_text() +\n    geom_dag_edges() + \n    scale_color_manual(values = c(\"black\", \"blue\")) +\n    theme_dag()\n  \n}\n\n# Check that `gg_fancy_dag()` out\ndag |&gt; \n  gg_fancy_dag(x = 2.5, y = 1, circle = \"M\")\n\n\n\n\nBased on McElreath’s R code 6.20, here we simulate some data based on the new DAG.\n\nset.seed(71)\nn &lt;- 1000\n\nd2 &lt;- tibble(\n  h0        = rnorm(n = n, mean = 10, sd = 2),\n  treatment = rep(0:1, each = n / 2),\n  m         = rbinom(n = n, size = 1, prob = 0.5),\n  fungus    = rbinom(n = n, size = 1, prob = 0.5 - treatment * 0.4 + 0.4 * m),\n  h1        = h0 + rnorm(n = n, mean = 5 + 3 * m, sd = 1))\n\nhead(d)\n\n# A tibble: 6 × 4\n     h0 treatment fungus    h1\n  &lt;dbl&gt;     &lt;int&gt;  &lt;int&gt; &lt;dbl&gt;\n1  9.14         0      0  14.3\n2  9.11         0      0  15.6\n3  9.04         0      0  14.4\n4 10.8          0      0  15.8\n5  9.16         0      1  11.5\n6  7.63         0      0  11.1\n\nhead(d2)\n\n# A tibble: 6 × 5\n     h0 treatment     m fungus    h1\n  &lt;dbl&gt;     &lt;int&gt; &lt;int&gt;  &lt;int&gt; &lt;dbl&gt;\n1  9.14         0     0      0  14.8\n2  9.11         0     0      0  15.3\n3  9.04         0     1      1  16.4\n4 10.8          0     1      1  19.1\n5  9.16         0     1      1  17.2\n6  7.63         0     0      0  13.4\n\n\nUpdate the stan_data with the new d2 data.\n\nstan_data &lt;- d2 |&gt; \n  select(-m) |&gt; \n  compose_data()\n\n# What?\nstr(stan_data)\n\nList of 5\n $ h0       : num [1:1000(1d)] 9.14 9.11 9.04 10.83 9.16 ...\n $ treatment: int [1:1000(1d)] 0 0 0 0 0 0 0 0 0 0 ...\n $ fungus   : int [1:1000(1d)] 0 0 1 1 1 0 1 1 0 1 ...\n $ h1       : num [1:1000(1d)] 14.8 15.3 16.4 19.1 17.2 ...\n $ n        : int 1000\n\n\nUse sampling() to refit m6.7 and m6.8 to the new data.\n\nm6.7b &lt;- sampling(\n  data = stan_data,\n  object = m6.7@stanmodel,\n  cores = 4, seed = 6)\n\nm6.8b &lt;- sampling(\n  data = stan_data,\n  object = m6.8@stanmodel,\n  cores = 4, seed = 6)\n\nCheck the model summaries.\n\nprint(m6.7b, probs = c(0.055, 0.945))\n\nInference for Stan model: anon_model.\n4 chains, each with iter=2000; warmup=1000; thin=1; \npost-warmup draws per chain=1000, total post-warmup draws=4000.\n\n          mean se_mean   sd     5.5%    94.5% n_eff Rhat\nb0        1.52    0.00 0.01     1.50     1.54  1638    1\nb1        0.05    0.00 0.01     0.03     0.07  1873    1\nb2        0.14    0.00 0.01     0.12     0.16  2166    1\nsigma     2.11    0.00 0.05     2.03     2.18  2648    1\nlp__  -1251.22    0.04 1.43 -1253.87 -1249.56  1595    1\n\nSamples were drawn using NUTS(diag_e) at Wed Jul 31 19:08:27 2024.\nFor each parameter, n_eff is a crude measure of effective sample size,\nand Rhat is the potential scale reduction factor on split chains (at \nconvergence, Rhat=1).\n\nprint(m6.8b, probs = c(0.055, 0.945))\n\nInference for Stan model: anon_model.\n4 chains, each with iter=2000; warmup=1000; thin=1; \npost-warmup draws per chain=1000, total post-warmup draws=4000.\n\n          mean se_mean   sd     5.5%    94.5% n_eff Rhat\nb0        1.62    0.00 0.01     1.61     1.64  2231    1\nb1       -0.01    0.00 0.01    -0.03     0.01  2145    1\nsigma     2.21    0.00 0.05     2.13     2.29  2838    1\nlp__  -1299.15    0.03 1.25 -1301.55 -1297.82  1768    1\n\nSamples were drawn using NUTS(diag_e) at Wed Jul 31 19:08:32 2024.\nFor each parameter, n_eff is a crude measure of effective sample size,\nand Rhat is the potential scale reduction factor on split chains (at \nconvergence, Rhat=1).\n\n\n“Including fungus again confounds inference about the treatment, this time by making it seem like it helped the plants, even though it had no effect” (p. 175).\n\n6.2.3.1 Rethinking: Model selection doesn’t help."
  },
  {
    "objectID": "06.html#collider-bias",
    "href": "06.html#collider-bias",
    "title": "6  The Haunted DAG & The Causal Terror",
    "section": "6.3 Collider bias",
    "text": "6.3 Collider bias\nMake the collider bias DAG of the trustworthiness/newsworthiness example.\n\ndag_coords &lt;- tibble(\n  name = c(\"T\", \"S\", \"N\"),\n  x    = 1:3,\n  y    = 1)\n\ndagify(S ~ T + N,\n       coords = dag_coords) |&gt;\n  gg_simple_dag()\n\n\n\n\n\n6.3.1 Collider of false sorrow.\nAll it takes is a single mutate() line in the dagify() function to amend our previous DAG.\n\ndagify(M ~ H + A,\n       coords = dag_coords |&gt;\n         mutate(name = c(\"H\", \"M\", \"A\"))) |&gt;\n  gg_simple_dag()\n\n\n\n\nMcElreath simulated the data for this section using his custom rethinking::sim_happiness() function. If you’d like to see the guts of the function, execute rethinking::sim_happiness. Our approach will be to simulate the data from the ground up. The workflow to follow is based on help from the great Randall Pruim; I was initially stumped and he lent a helping hand. The first step is to make a simple new_borns() function, which returns a tibble with n unmarried one-year-old’s who have different levels of happiness. We’ll set the default for n at 20.\n\nnew_borns &lt;- function(n = 20) {\n  tibble(a = 1,                                       # 1 year old\n         m = 0,                                       # not married\n         h = seq(from = -2, to = 2, length.out = n))  # range of happiness scores\n}\n\nHere’s how it works.\n\nnew_borns() |&gt; \n  glimpse()\n\nRows: 20\nColumns: 3\n$ a &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1\n$ m &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n$ h &lt;dbl&gt; -2.0000000, -1.7894737, -1.5789474, -1.3684211, -1.1578947, -0.94736…\n\n\nThe second step is to make another custom function, update_population(), which takes the input from new_borns(). This function will age up the simulated one-year-old’s from new_borns(), add another cohort of new_borns(), and append the cohorts. As you iterate, the initial cohort of new_borns() will eventually hit the age of 18, which is also the age they’re first eligible to marry (aom = 18).\n\nupdate_population &lt;- function(pop, n_births = 20, aom = 18, max_age = 65) {\n  \n  pop |&gt;\n    mutate(a = a + 1,  # Everyone gets one year older\n           # Some people get married\n           m = ifelse(m &gt;= 1, 1, (a &gt;= aom) * rbinom(n = n(), size = 1, prob = plogis(h - 4)))) |&gt;\n    filter(a &lt;= max_age) |&gt;         # Old people die\n    bind_rows(new_borns(n_births))  # New people are born\n  \n}\n\nHere’s what it looks like if we start with an initial new_borns() and pump them into update_population().\n\nnew_borns() |&gt; \n  update_population() |&gt; \n  glimpse()\n\nRows: 40\nColumns: 3\n$ a &lt;dbl&gt; 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1,…\n$ m &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ h &lt;dbl&gt; -2.0000000, -1.7894737, -1.5789474, -1.3684211, -1.1578947, -0.94736…\n\n\nFor our final step, we run the population simulation for 1,000 years. On my M2 MacBook Pro, this took just a few seconds. YMMV.\n\n# This was McElreath's seed\nset.seed(1977)\n\n# Year 1\nd &lt;- new_borns(n = 20)\n\n# Years 2 through 1000\nfor(i in 2:1000) {\n  d &lt;- update_population(d, n_births = 20, aom = 18, max_age = 65)\n}\n\n# Now rename()\nd &lt;- d |&gt; \n  rename(age = a, married = m, happiness = h)\n\n# Take a look\nglimpse(d)\n\nRows: 1,300\nColumns: 3\n$ age       &lt;dbl&gt; 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, …\n$ married   &lt;dbl&gt; 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, …\n$ happiness &lt;dbl&gt; -2.0000000, -1.7894737, -1.5789474, -1.3684211, -1.1578947, …\n\n\nSummarize the variables.\n\nd |&gt; \n  pivot_longer(everything()) |&gt; \n  group_by(name) |&gt; \n  mean_qi(value) |&gt; \n  mutate_if(is.double, round, digits = 2)\n\n# A tibble: 3 × 7\n  name      value .lower .upper .width .point .interval\n  &lt;chr&gt;     &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;    \n1 age        33        2     64   0.95 mean   qi       \n2 happiness   0       -2      2   0.95 mean   qi       \n3 married     0.3      0      1   0.95 mean   qi       \n\n\nHere’s our version of Figure 6.4.\n\nd |&gt; \n  mutate(married = factor(married, labels = c(\"unmarried\", \"married\"))) |&gt; \n  \n  ggplot(aes(x = age, y = happiness, color = married)) +\n  geom_point(size = 1.75) +\n  scale_color_manual(NULL, values = c(\"grey85\", \"red3\")) +\n  scale_x_continuous(expand = c(.015, .015))\n\n\n\n\nHere’s the likelihood for the simple Gaussian multivariable model predicting happiness:\n\\[\n\\begin{align*}\n\\text{happiness}_i & \\sim \\operatorname{Normal}(\\mu_i, \\sigma) \\\\\n\\mu_i              & = \\alpha_{\\text{married} [i]} + \\beta_1 \\text{age}_i ,\\\\\n\\end{align*}\n\\]\nwhere \\(\\text{married}[i]\\) is the marriage status of individual \\(i\\). Here we make d2, the subset of d containing only those 18 and up. We then make a new age variable, a, which is scaled such that \\(18 = 0\\), \\(65 = 1\\), and so on.\n\nd2 &lt;- d |&gt; \n  filter(age &gt; 17) |&gt; \n  mutate(a = (age - 18) / (65 - 18))\n\nhead(d2)\n\n# A tibble: 6 × 4\n    age married happiness     a\n  &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt;\n1    65       0    -2         1\n2    65       0    -1.79      1\n3    65       0    -1.58      1\n4    65       1    -1.37      1\n5    65       1    -1.16      1\n6    65       0    -0.947     1\n\n\nWith respect to priors,\n\nhappiness is on an arbitrary scale, in these data, from \\(-2\\) to \\(+2\\). So our imaginary strongest relationship, taking happiness from maximum to minimum, has a slope with rise over run of \\((2 - (-2))/1 = 4\\). Remember that 95% of the mass of a normal distribution is contained within 2 standard deviations. So if we set the standard deviation of the prior to half of 4, we are saying that we expect 95% of plausible slopes to be less than maximally strong. That isn’t a very strong prior, but again, it at least helps bound inference to realistic ranges. Now for the intercepts. Each \\(\\alpha\\) is the value of \\(\\mu_i\\) when \\(A_i = 0\\). In this case, that means at age 18. So we need to allow \\(\\alpha\\) to cover the full range of happiness scores. \\(\\operatorname{Normal}(0, 1)\\) will put 95% of the mass in the \\(-2\\) to \\(+2\\) interval. (p. 178)\n\nHere we’ll take one last step before fitting our model with stan(). Saving the mid index variable as a factor will make it easier to interpret the model results.\n\nd2 &lt;- d2 |&gt; \n  mutate(mid = factor(married + 1, labels = c(\"single\", \"married\")))\n\nhead(d2)\n\n# A tibble: 6 × 5\n    age married happiness     a mid    \n  &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt;  \n1    65       0    -2         1 single \n2    65       0    -1.79      1 single \n3    65       0    -1.58      1 single \n4    65       1    -1.37      1 married\n5    65       1    -1.16      1 married\n6    65       0    -0.947     1 single \n\n\nNow make the stan_data.\n\nstan_data &lt;- d2 |&gt; \n  compose_data()\n\n# What?\nstr(stan_data)\n\nList of 7\n $ age      : num [1:960(1d)] 65 65 65 65 65 65 65 65 65 65 ...\n $ married  : num [1:960(1d)] 0 0 0 1 1 0 0 0 1 1 ...\n $ happiness: num [1:960(1d)] -2 -1.79 -1.58 -1.37 -1.16 ...\n $ a        : num [1:960(1d)] 1 1 1 1 1 1 1 1 1 1 ...\n $ mid      : num [1:960(1d)] 1 1 1 2 2 1 1 1 2 2 ...\n $ n_mid    : int 2\n $ n        : int 960\n\n\nDefine the two model_code objects. For model_code_6.9, note how since we’re using mid as an index variable, we have saved it as an integer in an array. We haven’t done this in a while, but we covered it in some detail in Section 5.3.1 if you need a refresher.\n\nmodel_code_6.9 &lt;- '\ndata {\n  int&lt;lower=1&gt; n;\n  vector[n] happiness;\n  vector[n] a;\n  array[n] int mid;\n}\nparameters {\n  vector[2] b0;\n  real b1;\n  real&lt;lower=0&gt; sigma;\n}\nmodel {\n  happiness ~ normal(b0[mid] + b1 * a, sigma);\n  \n  b0 ~ normal(0, 1);\n  b1 ~ normal(0, 2);\n  sigma ~ exponential(1);\n}\n'\n\nmodel_code_6.10 &lt;- '\ndata {\n  int&lt;lower=1&gt; n;\n  vector[n] happiness;\n  vector[n] a;\n}\nparameters {\n  real b0;\n  real b1;\n  real&lt;lower=0&gt; sigma;\n}\nmodel {\n  happiness ~ normal(b0 + b1 * a, sigma);\n  \n  b0 ~ normal(0, 1);\n  b1 ~ normal(0, 2);\n  sigma ~ exponential(1);\n}\n'\n\nFit the models with stan().\n\nm6.9 &lt;- stan(\n  data = stan_data,\n  model_code = model_code_6.9,\n  cores = 4, seed = 6)\n\nm6.10 &lt;- stan(\n  data = stan_data,\n  model_code = model_code_6.10,\n  cores = 4, seed = 6)\n\nCheck the summaries.\n\nprint(m6.9, probs = c(0.055, 0.945))\n\nInference for Stan model: anon_model.\n4 chains, each with iter=2000; warmup=1000; thin=1; \npost-warmup draws per chain=1000, total post-warmup draws=4000.\n\n         mean se_mean   sd    5.5%   94.5% n_eff Rhat\nb0[1]   -0.19    0.00 0.06   -0.29   -0.09  1705    1\nb0[2]    1.27    0.00 0.09    1.13    1.41  1696    1\nb1      -0.80    0.00 0.11   -0.98   -0.62  1605    1\nsigma    1.01    0.00 0.02    0.97    1.05  2810    1\nlp__  -490.28    0.03 1.39 -492.85 -488.69  1785    1\n\nSamples were drawn using NUTS(diag_e) at Wed Aug 14 10:08:02 2024.\nFor each parameter, n_eff is a crude measure of effective sample size,\nand Rhat is the potential scale reduction factor on split chains (at \nconvergence, Rhat=1).\n\nprint(m6.10, probs = c(0.055, 0.945))\n\nInference for Stan model: anon_model.\n4 chains, each with iter=2000; warmup=1000; thin=1; \npost-warmup draws per chain=1000, total post-warmup draws=4000.\n\n         mean se_mean   sd    5.5%   94.5% n_eff Rhat\nb0       0.00    0.00 0.08   -0.12    0.12  1271    1\nb1       0.00    0.00 0.13   -0.21    0.20  1273    1\nsigma    1.22    0.00 0.03    1.17    1.26  2361    1\nlp__  -668.61    0.03 1.18 -670.82 -667.33  1595    1\n\nSamples were drawn using NUTS(diag_e) at Wed Jul 31 19:14:37 2024.\nFor each parameter, n_eff is a crude measure of effective sample size,\nand Rhat is the potential scale reduction factor on split chains (at \nconvergence, Rhat=1).\n\n\nWow. So when we take out mid, the coefficient for a (\\(\\beta_1\\)) drops to zero.\n\n\n6.3.2 The haunted DAG.\nIt gets worse. “Unmeasured causes can still induce collider bias. So I’m sorry to say that we also have to consider the possibility that our DAG may be haunted” (p. 180).\nHere’s the unhaunted DAG.\n\ndag_coords &lt;- tibble(\n  name = c(\"G\", \"P\", \"C\"),\n  x    = c(1, 2, 2),\n  y    = c(2, 2, 1))\n\ndagify(P ~ G,\n       C ~ P + G,\n       coords = dag_coords) |&gt;\n  gg_simple_dag()\n\n\n\n\nNow we add the haunting variable, U.\n\ndag_coords &lt;- tibble(\n  name = c(\"G\", \"P\", \"C\", \"U\"),\n  x    = c(1, 2, 2, 2.5),\n  y    = c(2, 2, 1, 1.5))\n\ndagify(P ~ G + U,\n       C ~ P + G + U,\n       coords = dag_coords) |&gt;\n  gg_fancy_dag(x = 2.5, y = 1.5, circle = \"U\")\n\n\n\n\nThis is a mess. Let’s simulate some data.\n\n# How many grandparent-parent-child triads would you like?\nn    &lt;- 200 \n\nb_gp &lt;- 1  # Direct effect of G on P\nb_gc &lt;- 0  # Direct effect of G on C\nb_pc &lt;- 1  # Direct effect of P on C\nb_u  &lt;- 2  # Direct effect of U on P and C\n\n# Simulate triads\nset.seed(1)\nd &lt;- tibble(u = 2 * rbinom(n = n, size = 1, prob = 0.5) - 1,\n            g = rnorm(n = n, mean = 0, sd = 1)) |&gt; \n  mutate(p = rnorm(n = n, mean = b_gp * g + b_u * u, sd = 1)) |&gt; \n  mutate(c = rnorm(n = n, mean = b_pc * p + b_gc * g + b_u * u, sd = 1))\n\n# What?\nhead(d)\n\n# A tibble: 6 × 4\n      u       g     p     c\n  &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1    -1 -0.620  -1.73 -3.65\n2    -1  0.0421 -3.01 -5.30\n3     1 -0.911   3.06  3.88\n4     1  0.158   1.77  3.79\n5    -1 -0.655  -1.00 -2.01\n6     1  1.77    5.28  8.87\n\n\nUpdate the stan_data.\n\nstan_data &lt;- d |&gt; \n  compose_data()\n\n# What?\nstr(stan_data)\n\nList of 5\n $ u: num [1:200(1d)] -1 -1 1 1 -1 1 1 1 1 -1 ...\n $ g: num [1:200(1d)] -0.6204 0.0421 -0.9109 0.158 -0.6546 ...\n $ p: num [1:200(1d)] -1.73 -3.01 3.06 1.77 -1 ...\n $ c: num [1:200(1d)] -3.65 -5.3 3.88 3.79 -2.01 ...\n $ n: int 200\n\n\nMake model_code_6.11 and model_code_6.12.\n\nmodel_code_6.11 &lt;- '\ndata {\n  int&lt;lower=1&gt; n;\n  vector[n] c;\n  vector[n] p;\n  vector[n] g;\n}\nparameters {\n  real b0;\n  real b1;\n  real b2;\n  real&lt;lower=0&gt; sigma;\n}\nmodel {\n  c ~ normal(b0 + b1 * p + b2 * g, sigma);\n  \n  [b0, b1, b2] ~ normal(0, 1);\n  sigma ~ exponential(1);\n}\n'\n\nmodel_code_6.12 &lt;- '\ndata {\n  int&lt;lower=1&gt; n;\n  vector[n] c;\n  vector[n] p;\n  vector[n] g;\n  vector[n] u;\n}\nparameters {\n  real b0;\n  real b1;\n  real b2;\n  real b3;\n  real&lt;lower=0&gt; sigma;\n}\nmodel {\n  c ~ normal(b0 + b1 * p + b2 * g + b3 * u, sigma);\n  \n  [b0, b1, b2, b3] ~ normal(0, 1);\n  sigma ~ exponential(1);\n}\n'\n\nFit the models with stan().\n\nm6.11 &lt;- stan(\n  data = stan_data,\n  model_code = model_code_6.11,\n  cores = 4, seed = 6)\n\nm6.12 &lt;- stan(\n  data = stan_data,\n  model_code = model_code_6.12,\n  cores = 4, seed = 6)\n\nCheck the summaries.\n\nprint(m6.11, probs = c(0.055, 0.945))\n\nInference for Stan model: anon_model.\n4 chains, each with iter=2000; warmup=1000; thin=1; \npost-warmup draws per chain=1000, total post-warmup draws=4000.\n\n         mean se_mean   sd    5.5%   94.5% n_eff Rhat\nb0      -0.12    0.00 0.10   -0.28    0.05  4367    1\nb1       1.79    0.00 0.05    1.71    1.86  4098    1\nb2      -0.84    0.00 0.11   -1.01   -0.67  3668    1\nsigma    1.43    0.00 0.07    1.32    1.55  3876    1\nlp__  -174.41    0.03 1.44 -177.00 -172.79  2239    1\n\nSamples were drawn using NUTS(diag_e) at Wed Jul 31 19:18:35 2024.\nFor each parameter, n_eff is a crude measure of effective sample size,\nand Rhat is the potential scale reduction factor on split chains (at \nconvergence, Rhat=1).\n\nprint(m6.12, probs = c(0.055, 0.945))\n\nInference for Stan model: anon_model.\n4 chains, each with iter=2000; warmup=1000; thin=1; \npost-warmup draws per chain=1000, total post-warmup draws=4000.\n\n         mean se_mean   sd    5.5%   94.5% n_eff Rhat\nb0      -0.12    0.00 0.07   -0.24   -0.01  3407    1\nb1       1.01    0.00 0.07    0.90    1.11  1709    1\nb2      -0.04    0.00 0.10   -0.20    0.12  2087    1\nb3       2.00    0.00 0.15    1.76    2.24  1849    1\nsigma    1.04    0.00 0.05    0.95    1.12  2851    1\nlp__  -110.42    0.04 1.63 -113.42 -108.49  1541    1\n\nSamples were drawn using NUTS(diag_e) at Wed Jul 31 19:19:02 2024.\nFor each parameter, n_eff is a crude measure of effective sample size,\nand Rhat is the potential scale reduction factor on split chains (at \nconvergence, Rhat=1).\n\n\nNow the posterior for \\(\\beta_2\\) is hovering around 0, where it belongs.\n\nb_gc\n\n[1] 0\n\n\nHere’s our version of Figure 6.5.\n\nd &lt;- d |&gt; \n  mutate(centile = ifelse(p &gt;= quantile(p, prob = .45) & p &lt;= quantile(p, prob = .60), \"a\", \"b\"))\n\nd |&gt;\n  ggplot(aes(x = g, y = c)) +\n  geom_point(aes(shape = centile, color = factor(u)),\n             size = 2.5, stroke = 1/4) +\n  stat_smooth(data = d |&gt; \n                filter(centile == \"a\"),\n              method = \"lm\", color = \"black\", fullrange = TRUE, linewidth = 1/2, se = FALSE) +\n  scale_shape_manual(values = c(19, 1), breaks = NULL) +\n  scale_color_manual(values = c(\"black\", \"blue\"), breaks = NULL)\n\n\n\n\n\n6.3.2.1 Bonus: A second method.\nThe last two models were largely the same in they were both multivariable models with several predictors; the second just had one more predictor than the other. This is a good opportunity to show another way to fit them both, but using a more general kind of model_code syntax.\nDo you recall back in Section 5.1.3.1 where we briefly introduced compact model notation and the design matrix? The method we are about to explore will require we adjust how we are defining the stan_data, and that adjustment involves the notion of a design matrix. We can define a model matrix via the model.matrix() function. We’ll save the object as mm_6.11.\n\n# Define a model matrix\nmm_6.11 &lt;- model.matrix(data = d, object = ~p + g)\n\n# What?\nstr(mm_6.11)\n\n num [1:200, 1:3] 1 1 1 1 1 1 1 1 1 1 ...\n - attr(*, \"dimnames\")=List of 2\n  ..$ : chr [1:200] \"1\" \"2\" \"3\" \"4\" ...\n  ..$ : chr [1:3] \"(Intercept)\" \"p\" \"g\"\n - attr(*, \"assign\")= int [1:3] 0 1 2\n\nhead(mm_6.11)\n\n  (Intercept)         p           g\n1           1 -1.726693 -0.62036668\n2           1 -3.005182  0.04211587\n3           1  3.060416 -0.91092165\n4           1  1.774397  0.15802877\n5           1 -1.000439 -0.65458464\n6           1  5.279500  1.76728727\n\n\nThe mm_6.11 object has 3 columns: The first column is a constant 1 for the intercept, and the other two columns are for the predictors p and g. These are based on the design matrix way of presenting a regression model. We can use this mm_6.11 object to define two new elements within compose_data(). The first will be X to stand for the entire model matrix mm_6.11. The second will be k, the number of columns (i.e., “predictors”) in the design matrix.\nHere’s how we define the new version of the data list. We’ll call it stan_data_6.11.\n\nstan_data_6.11 &lt;- d |&gt;\n  select(c, p, g) |&gt; \n  # Define `X` and `k` right in the `compose_data()` function\n  compose_data(X = mm_6.11,\n               k = ncol(mm_6.11))\n\n# What?\nstr(stan_data_6.11)\n\nList of 6\n $ c: num [1:200(1d)] -3.65 -5.3 3.88 3.79 -2.01 ...\n $ p: num [1:200(1d)] -1.73 -3.01 3.06 1.77 -1 ...\n $ g: num [1:200(1d)] -0.6204 0.0421 -0.9109 0.158 -0.6546 ...\n $ n: int 200\n $ X: num [1:200, 1:3] 1 1 1 1 1 1 1 1 1 1 ...\n  ..- attr(*, \"dimnames\")=List of 2\n  .. ..$ : chr [1:200] \"1\" \"2\" \"3\" \"4\" ...\n  .. ..$ : chr [1:3] \"(Intercept)\" \"p\" \"g\"\n  ..- attr(*, \"assign\")= int [1:3] 0 1 2\n $ k: int 3\n\n\nFor the second model, we add the u predictor. Here we’ll define a new model.matrix() object based on the addition of that predictor, and then follow the same steps to make a stan_data_6.12 object.\n\nmm_6.12 &lt;- model.matrix(data = d, object = ~p + g + u)\n\nstan_data_6.12 &lt;- d |&gt;\n  select(c, p, g, u) |&gt; \n  compose_data(X = mm_6.12,\n               k = ncol(mm_6.12))\n\n# What?\nstr(stan_data_6.12)\n\nList of 7\n $ c: num [1:200(1d)] -3.65 -5.3 3.88 3.79 -2.01 ...\n $ p: num [1:200(1d)] -1.73 -3.01 3.06 1.77 -1 ...\n $ g: num [1:200(1d)] -0.6204 0.0421 -0.9109 0.158 -0.6546 ...\n $ u: num [1:200(1d)] -1 -1 1 1 -1 1 1 1 1 -1 ...\n $ n: int 200\n $ X: num [1:200, 1:4] 1 1 1 1 1 1 1 1 1 1 ...\n  ..- attr(*, \"dimnames\")=List of 2\n  .. ..$ : chr [1:200] \"1\" \"2\" \"3\" \"4\" ...\n  .. ..$ : chr [1:4] \"(Intercept)\" \"p\" \"g\" \"u\"\n  ..- attr(*, \"assign\")= int [1:4] 0 1 2 3\n $ k: int 4\n\n\nNow we’ll write one general model_code object with which we’ll fit both models. Note how the syntax we’re using in the model block resembles the \\(\\mathbf{Xb}\\) notation we briefly discussed back in Section 5.1.3.1.\n\nmodel_code_6.11and12&lt;- '\ndata {\n  int&lt;lower=1&gt; n;\n  int&lt;lower=1&gt; k;  // Number of coefficients (including intercept)\n  vector[n] c;     // The criterion\n  matrix[n, k] X;  // Regressors from the model matrix (including intercept)\n}\nparameters {\n  vector[k] b;          // The beta coefficients are now defined by a vector\n  real&lt;lower=0&gt; sigma;  \n}\nmodel {\n  c ~ normal(X * b, sigma);  // Linear model defined in matrix algebra notation Xb\n  \n  b ~ normal(0, 1);\n  sigma ~ exponential(1);\n}\n'\n\nCompile the model_code_6.11and12 object with the stan_model() function, and save the results as an object called stan_dso.\n\nstan_dso &lt;- stan_model(model_code = model_code_6.11and12)\n\nFinally, we sample from the stan_dso object with the sampling() function, once for each of the new stan_data_6.1x lists.\n\nm6.11b &lt;- sampling(\n  data = stan_data_6.11,\n  object = stan_dso,\n  cores = 4, seed = 6)\n\nm6.12b &lt;- sampling(\n  data = stan_data_6.12,\n  object = stan_dso,\n  cores = 4, seed = 6)\n\nCheck the model summaries.\n\nprint(m6.11b, probs = c(0.055, 0.945))\n\nInference for Stan model: anon_model.\n4 chains, each with iter=2000; warmup=1000; thin=1; \npost-warmup draws per chain=1000, total post-warmup draws=4000.\n\n         mean se_mean   sd    5.5%   94.5% n_eff Rhat\nb[1]    -0.12    0.00 0.10   -0.28    0.05  3758    1\nb[2]     1.79    0.00 0.05    1.72    1.86  3719    1\nb[3]    -0.84    0.00 0.11   -1.01   -0.67  3534    1\nsigma    1.43    0.00 0.07    1.32    1.55  3181    1\nlp__  -174.39    0.03 1.41 -177.11 -172.78  1933    1\n\nSamples were drawn using NUTS(diag_e) at Wed Jul 31 19:24:54 2024.\nFor each parameter, n_eff is a crude measure of effective sample size,\nand Rhat is the potential scale reduction factor on split chains (at \nconvergence, Rhat=1).\n\nprint(m6.12b, probs = c(0.055, 0.945))\n\nInference for Stan model: anon_model.\n4 chains, each with iter=2000; warmup=1000; thin=1; \npost-warmup draws per chain=1000, total post-warmup draws=4000.\n\n         mean se_mean   sd    5.5%   94.5% n_eff Rhat\nb[1]    -0.12    0.00 0.07   -0.23   -0.01  3001    1\nb[2]     1.01    0.00 0.07    0.91    1.12  1576    1\nb[3]    -0.04    0.00 0.10   -0.20    0.12  2098    1\nb[4]     2.00    0.00 0.15    1.75    2.23  1605    1\nsigma    1.04    0.00 0.05    0.96    1.12  2905    1\nlp__  -110.41    0.04 1.59 -113.36 -108.48  1836    1\n\nSamples were drawn using NUTS(diag_e) at Wed Jul 31 19:26:25 2024.\nFor each parameter, n_eff is a crude measure of effective sample size,\nand Rhat is the potential scale reduction factor on split chains (at \nconvergence, Rhat=1).\n\n\nWith this approach, all \\(\\beta\\) coefficients in the model now take generic labels b[k], ranging from \\(1, \\dots, K\\). Otherwise, the parameter summaries themselves are basically the same as with the other method we’ve been using. If you’re fitting one or a few simple models, this approach might seem unnecessary. However, it’s a nice trick to have if you need to scale up.\nTo further get a sense of the difference between the model.matrix() approach and the one we’ve been primarily using, we might take a look at the structure of the rstan::extract() output. We’ll focus on m6.11 and m6.11b.\n\n# Simple approach\nextract(m6.11) |&gt; \n  str(max.level = 1)\n\nList of 5\n $ b0   : num [1:4000(1d)] -0.0904 -0.0834 -0.0218 -0.0959 -0.2803 ...\n  ..- attr(*, \"dimnames\")=List of 1\n $ b1   : num [1:4000(1d)] 1.86 1.83 1.79 1.74 1.75 ...\n  ..- attr(*, \"dimnames\")=List of 1\n $ b2   : num [1:4000(1d)] -0.987 -0.838 -0.864 -0.769 -0.708 ...\n  ..- attr(*, \"dimnames\")=List of 1\n $ sigma: num [1:4000(1d)] 1.35 1.53 1.55 1.39 1.33 ...\n  ..- attr(*, \"dimnames\")=List of 1\n $ lp__ : num [1:4000(1d)] -175 -174 -174 -173 -176 ...\n  ..- attr(*, \"dimnames\")=List of 1\n\n# `model.matrix()` approach\nextract(m6.11b) |&gt; \n  str(max.level = 1)\n\nList of 3\n $ b    : num [1:4000, 1:3] -0.2285 -0.1263 -0.1282 -0.0969 -0.13 ...\n  ..- attr(*, \"dimnames\")=List of 2\n $ sigma: num [1:4000(1d)] 1.42 1.38 1.37 1.4 1.32 ...\n  ..- attr(*, \"dimnames\")=List of 1\n $ lp__ : num [1:4000(1d)] -173 -173 -173 -172 -174 ...\n  ..- attr(*, \"dimnames\")=List of 1\n\n\nThe extract() returns the draws from a fitted stan() models parameters in a list format. When we use the simple formula approach as in m6.11, we get a list of one-dimensional arrays, one for each parameter–b0 through sigma–, as well as the lp__. But when we use extract() on m6.11b, which is the model fit with the model.matrix() approach, we get a list of fewer elements, but the first element b is an array with 3 columns, one for each of the columns from the model.matrix() output we used to define the predictors. The other two elements in the list from extract(m6.11b) are for sigma and the lp__.\nThese arrangements have implications for how you might use the gather_draws() and spread_draws() functions from the tidybayes package. These functions are useful for extracting draws from one or more parameters from a fitted Bayesian model, such as those with stan(), and formatting the results in a tidy data format. The spread_draws() function returns the output in a wide format with respect to the parameters, and the gather_draws() function returns the output in a long format w/r/t the parameters. Here are first 10 rows of the gather_draws() and spread_draws() output for m6.11.\n\n# `gather_draws()`\nm6.11 |&gt;\n  gather_draws(b0, b1, b2) |&gt; \n  arrange(.draw) |&gt; \n  head(n = 10)\n\n# A tibble: 10 × 5\n# Groups:   .variable [3]\n   .chain .iteration .draw .variable  .value\n    &lt;int&gt;      &lt;int&gt; &lt;int&gt; &lt;chr&gt;       &lt;dbl&gt;\n 1      1          1     1 b0        -0.154 \n 2      1          1     1 b1         1.79  \n 3      1          1     1 b2        -0.828 \n 4      1          2     2 b0        -0.164 \n 5      1          2     2 b1         1.68  \n 6      1          2     2 b2        -0.823 \n 7      1          3     3 b0        -0.143 \n 8      1          3     3 b1         1.89  \n 9      1          3     3 b2        -0.763 \n10      1          4     4 b0        -0.0669\n\n# `spread_draws()`\nm6.11 |&gt; \n  spread_draws(b0, b1, b2) |&gt; \n  head(n = 10)\n\n# A tibble: 10 × 6\n   .chain .iteration .draw       b0    b1     b2\n    &lt;int&gt;      &lt;int&gt; &lt;int&gt;    &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;\n 1      1          1     1 -0.154    1.79 -0.828\n 2      1          2     2 -0.164    1.68 -0.823\n 3      1          3     3 -0.143    1.89 -0.763\n 4      1          4     4 -0.0669   1.85 -1.02 \n 5      1          5     5 -0.167    1.74 -0.721\n 6      1          6     6 -0.259    1.75 -0.740\n 7      1          7     7  0.0162   1.83 -0.961\n 8      1          8     8  0.0213   1.78 -0.980\n 9      1          9     9 -0.0983   1.82 -0.870\n10      1         10    10 -0.00547  1.72 -0.765\n\n\nThe output for both are long w/r/t the .chain, .iteration, and .draw columns. But whereas the gather_draws() output are also long w/r/t the b parameters, as indicated in the .variable column, each of the b parameters gets its own column in the spread_draws().\nAlso note that the long-formatted output for gather_draws() is automatically grouped by the three levels of .variable, but the wide-formatted output for spread_draws() is not so grouped.\nNow consider the format for m6.11b, the model fit using the model.matrix() approach for the \\(\\beta\\) coefficients. Note how we use the [] notation to indicate the b parameters are in a multidimensional array format, and we further indicated we wanted to index those dimensions with a column called k. We could have chosen another name, such as index.\n\n# `gather_draws()`\nm6.11b |&gt;\n  gather_draws(b[k]) |&gt;  # Notice our `[]` syntax\n  arrange(.draw) |&gt; \n  head(n = 10)\n\n# A tibble: 10 × 6\n# Groups:   k, .variable [3]\n       k .chain .iteration .draw .variable  .value\n   &lt;int&gt;  &lt;int&gt;      &lt;int&gt; &lt;int&gt; &lt;chr&gt;       &lt;dbl&gt;\n 1     1      1          1     1 b         -0.145 \n 2     2      1          1     1 b          1.80  \n 3     3      1          1     1 b         -0.801 \n 4     1      1          2     2 b         -0.0535\n 5     2      1          2     2 b          1.77  \n 6     3      1          2     2 b         -0.958 \n 7     1      1          3     3 b         -0.153 \n 8     2      1          3     3 b          1.76  \n 9     3      1          3     3 b         -0.800 \n10     1      1          4     4 b         -0.152 \n\n# Look at this output with an alternative name for the `b` dimensions\n# m6.11b |&gt;\n#   gather_draws(b[index]) |&gt; \n#   arrange(.draw) |&gt; \n#   head(n = 10)\n\n# `spread_draws()`\nm6.11b |&gt; \n  spread_draws(b[k]) |&gt;  # Notice our `[]` syntax\n  arrange(.draw) |&gt; \n  head(n = 10)\n\n# A tibble: 10 × 5\n# Groups:   k [3]\n       k       b .chain .iteration .draw\n   &lt;int&gt;   &lt;dbl&gt;  &lt;int&gt;      &lt;int&gt; &lt;int&gt;\n 1     1 -0.145       1          1     1\n 2     2  1.80        1          1     1\n 3     3 -0.801       1          1     1\n 4     1 -0.0535      1          2     2\n 5     2  1.77        1          2     2\n 6     3 -0.958       1          2     2\n 7     1 -0.153       1          3     3\n 8     2  1.76        1          3     3\n 9     3 -0.800       1          3     3\n10     1 -0.152       1          4     4\n\n\nThough maybe obscured by our use of head(n = 10), the output for both is long w/r/t the \\(\\beta\\) parameters. The output for each of the \\(\\beta\\) parameters is indexed by the k column in both, and whereas the output for gather_draws() now has a .variable column with a constant value b and a .value column for the actual values of the draws, the output for spread_draws() simply collapsed those two into a single column b which contains the values from each parameter’s draw.\nAlso note the output from both functions is grouped. But whereas the output from gather_draws() is grouped by k and .variable, the output from spread_draws() is grouped only for k.\nThe gather_draws() approach can be nice for plotting parameter posteriors for models using the model.matrix() approach.\n\nm6.11b |&gt;\n  gather_draws(b[k]) |&gt; \n  mutate(beta = str_c(\"beta[\", k, \"]\")) |&gt; \n  \n  ggplot(aes(x = .value, y = beta)) +\n  stat_halfeye(.width = 0.89) + \n  scale_y_discrete(NULL, expand = expansion(mult = 0.05), labels = ggplot2:::parse_safe) +\n  labs(title = \"m6.11b\",\n       subtitle = \"Default numbering in k\")\n\n\n\nm6.11b |&gt;\n  gather_draws(b[k]) |&gt; \n  # Note the change `k - 1`\n  mutate(beta = str_c(\"beta[\", k - 1, \"]\")) |&gt; \n  \n  ggplot(aes(x = .value, y = beta)) +\n  stat_halfeye(.width = 0.89) + \n  scale_y_discrete(NULL, expand = expansion(mult = 0.05), labels = ggplot2:::parse_safe) +\n  labs(title = \"m6.11b\",\n       subtitle = \"Adjusted numbering in k to match convention\")\n\n\n\n\nThe same plot requires the more sophisticated regular-expression syntax within str_extract() to define the beta labels for the y axis for a model like m6.11.\n\nm6.11 |&gt;\n  gather_draws(b0, b1, b2) |&gt; \n  mutate(beta = str_c(\"beta[\", str_extract(.variable, \"\\\\d+\"), \"]\")) |&gt; \n  \n  ggplot(aes(x = .value, y = beta)) +\n  stat_halfeye(.width = 0.89) + \n  scale_y_discrete(NULL, expand = expansion(mult = 0.05), labels = ggplot2:::parse_safe) +\n  labs(title = \"m6.11\",\n       subtitle = \"Default numbering in k\")"
  },
  {
    "objectID": "06.html#confronting-confounding",
    "href": "06.html#confronting-confounding",
    "title": "6  The Haunted DAG & The Causal Terror",
    "section": "6.4 Confronting confounding",
    "text": "6.4 Confronting confounding\n\n6.4.1 Shutting the backdoor.\n\n\n6.4.2 Two roads.\n\n\n6.4.3 Backdoor waffles.\n\n6.4.3.1 Rethinking: DAGs are not enough.\n\n\n6.4.3.2 Overthinking: A smooth operator."
  },
  {
    "objectID": "06.html#summary",
    "href": "06.html#summary",
    "title": "6  The Haunted DAG & The Causal Terror",
    "section": "6.5 Summary",
    "text": "6.5 Summary"
  },
  {
    "objectID": "06.html#session-info",
    "href": "06.html#session-info",
    "title": "6  The Haunted DAG & The Causal Terror",
    "section": "Session info",
    "text": "Session info\n\nsessionInfo()\n\nR version 4.4.0 (2024-04-24)\nPlatform: aarch64-apple-darwin20\nRunning under: macOS Ventura 13.4\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: America/Chicago\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n [1] dagitty_0.3-4      ggdag_0.2.12       posterior_1.6.0    patchwork_1.2.0   \n [5] rstan_2.32.6       StanHeaders_2.32.7 tidybayes_3.0.6    lubridate_1.9.3   \n [9] forcats_1.0.0      stringr_1.5.1      dplyr_1.1.4        purrr_1.0.2       \n[13] readr_2.1.5        tidyr_1.3.1        tibble_3.2.1       ggplot2_3.5.1     \n[17] tidyverse_2.0.0   \n\nloaded via a namespace (and not attached):\n [1] svUnit_1.0.6         tidyselect_1.2.1     viridisLite_0.4.2   \n [4] farver_2.1.1         viridis_0.6.5        loo_2.8.0           \n [7] ggraph_2.2.1         fastmap_1.1.1        tensorA_0.36.2.1    \n[10] tweenr_2.0.3         digest_0.6.35        timechange_0.3.0    \n[13] lifecycle_1.0.4      processx_3.8.4       magrittr_2.0.3      \n[16] compiler_4.4.0       rlang_1.1.4          tools_4.4.0         \n[19] igraph_2.0.3         utf8_1.2.4           yaml_2.3.8          \n[22] knitr_1.46           graphlayouts_1.1.1   labeling_0.4.3      \n[25] htmlwidgets_1.6.4    pkgbuild_1.4.4       curl_5.2.1          \n[28] cmdstanr_0.8.1       abind_1.4-5          withr_3.0.0         \n[31] polyclip_1.10-6      grid_4.4.0           stats4_4.4.0        \n[34] fansi_1.0.6          colorspace_2.1-0     inline_0.3.19       \n[37] scales_1.3.0         rethinking_2.40      MASS_7.3-60.2       \n[40] cli_3.6.3            mvtnorm_1.2-5        rmarkdown_2.26      \n[43] generics_0.1.3       RcppParallel_5.1.7   rstudioapi_0.16.0   \n[46] tzdb_0.4.0           cachem_1.0.8         ggforce_0.4.2       \n[49] splines_4.4.0        parallel_4.4.0       matrixStats_1.3.0   \n[52] vctrs_0.6.5          V8_4.4.2             boot_1.3-30         \n[55] Matrix_1.7-0         jsonlite_1.8.8       hms_1.1.3           \n[58] arrayhelpers_1.1-0   ggrepel_0.9.5        ggdist_3.3.2        \n[61] glue_1.7.0           codetools_0.2-20     ps_1.7.6            \n[64] distributional_0.4.0 stringi_1.8.4        gtable_0.3.5        \n[67] shape_1.4.6.1        QuickJSR_1.1.3       munsell_0.5.1       \n[70] pillar_1.9.0         htmltools_0.5.8.1    R6_2.5.1            \n[73] tidygraph_1.3.1      evaluate_0.23        lattice_0.22-6      \n[76] backports_1.5.0      memoise_2.0.1        Rcpp_1.0.12         \n[79] nlme_3.1-164         coda_0.19-4.1        gridExtra_2.3       \n[82] checkmate_2.3.1      mgcv_1.9-1           xfun_0.43           \n[85] pkgconfig_2.0.3"
  },
  {
    "objectID": "06.html#comments",
    "href": "06.html#comments",
    "title": "6  The Haunted DAG & The Causal Terror",
    "section": "Comments",
    "text": "Comments"
  },
  {
    "objectID": "07.html#the-problem-with-parameters",
    "href": "07.html#the-problem-with-parameters",
    "title": "7  Ulysses’ Compass",
    "section": "7.1 The problem with parameters",
    "text": "7.1 The problem with parameters\n\n7.1.1 More parameters (almost) always improve fit.\nWe’ll start off by making the data with brain size and body size for seven species.\n\nd &lt;- tibble(\n  species = c(\"afarensis\", \"africanus\", \"habilis\", \"boisei\", \"rudolfensis\", \"ergaster\", \"sapiens\"), \n  brain   = c(438, 452, 612, 521, 752, 871, 1350), \n  mass    = c(37.0, 35.5, 34.5, 41.5, 55.5, 61.0, 53.5))\n\n# What?\nprint(d)\n\n# A tibble: 7 × 3\n  species     brain  mass\n  &lt;chr&gt;       &lt;dbl&gt; &lt;dbl&gt;\n1 afarensis     438  37  \n2 africanus     452  35.5\n3 habilis       612  34.5\n4 boisei        521  41.5\n5 rudolfensis   752  55.5\n6 ergaster      871  61  \n7 sapiens      1350  53.5\n\n\nHere’s Figure 7.2.\n\nd |&gt;\n  ggplot(aes(x =  mass, y = brain, label = species)) +\n  geom_point() +\n  geom_text(hjust = -0.2, size = 2.2, vjust = 0) +\n  labs(x = \"body mass (kg)\",\n       y = \"brain volume (cc)\",\n       subtitle = \"Average brain volume by body mass for\\nsix hominin species\") +\n  xlim(30, 65)\n\n\n\n\nBefore fitting our models, rescale a couple of the variables.\n\nd &lt;- d |&gt; \n  mutate(mass_std  = (mass - mean(mass)) / sd(mass),\n         brain_std = brain / max(brain))\n\nOur first statistical model will follow the form\n\\[\n\\begin{align*}\n\\text{brain-std}_i & \\sim \\operatorname{Normal}(\\mu_i, \\sigma) \\\\\n\\mu_i              & = \\alpha + \\beta \\text{mass-std}_i \\\\\n\\alpha             & \\sim \\operatorname{Normal}(0.5, 1) \\\\\n\\beta              & \\sim \\operatorname{Normal}(0, 10) \\\\\n\\sigma             & \\sim \\operatorname{Log-Normal}(0, 1).\n\\end{align*}\n\\]\nA careful study of McElreath’s R code 7.3 will show he is modeling log_sigma, rather than \\(\\sigma\\). We’ll consider the implications for that in the code shortly.\nPart of the challenge for this section is we’ll be fitting several closely-related models. We could do that one model at a time, but that would require a lot of redundant and inefficient code. Instead, we’ll take the opportunity to show an approach that streamlines the process. But since this requires we adopt several steps we haven’t often used, we’ll spend a lot of time up front describing them one at a time. Then after the exposition, we’ll show the code for the fully developed streamlined approach.\nTo start this all off, define the stan_data with the compose_data() function.\n\nstan_data &lt;- d |&gt;\n  select(brain_std, mass_std) |&gt; \n  compose_data()\n\n# What?\nstr(stan_data)\n\nList of 3\n $ brain_std: num [1:7(1d)] 0.324 0.335 0.453 0.386 0.557 ...\n $ mass_std : num [1:7(1d)] -0.779 -0.917 -1.009 -0.367 0.917 ...\n $ n        : int 7\n\n\nDefine the initial model_code_7.1.\n\nmodel_code_7.1 &lt;- '\ndata {\n  int&lt;lower=1&gt; n;\n  vector[n] brain_std;\n  vector[n] mass_std;\n}\nparameters {\n  real b0;\n  real b1;\n  real log_sigma;\n}\nmodel {\n  brain_std ~ normal(b0 + b1 * mass_std, exp(log_sigma));\n  \n  b0 ~ normal(0.5, 1);\n  b1 ~ normal(0, 10);\n  log_sigma ~ normal(0, 1);\n}\n'\n\nNote that whereas we usually define our \\(\\sigma\\) parameters as real&lt;lower=0&gt;, we have defined log_sigma as simply real. Also note that we have exp(log_sigma) in the likelihood line, which is how you put the posterior of log_sigma back on the natural zero-bounded \\(\\sigma\\) metric.\nCompile and fit this initial model with stan().\n\nm7.1 &lt;- stan(\n  data = stan_data,\n  model_code = model_code_7.1,\n  cores = 4, seed = 7)\n\nCheck the summary.\n\nprint(m7.1, probs = c(0.055, 0.945))\n\nInference for Stan model: anon_model.\n4 chains, each with iter=2000; warmup=1000; thin=1; \npost-warmup draws per chain=1000, total post-warmup draws=4000.\n\n           mean se_mean   sd  5.5% 94.5% n_eff Rhat\nb0         0.52    0.00 0.11  0.35  0.69  2032 1.00\nb1         0.17    0.00 0.12 -0.02  0.35  1812 1.00\nlog_sigma -1.40    0.01 0.38 -1.93 -0.75  1134 1.00\nlp__       5.89    0.06 1.62  2.82  7.59   834 1.01\n\nSamples were drawn using NUTS(diag_e) at Thu Aug  1 11:13:37 2024.\nFor each parameter, n_eff is a crude measure of effective sample size,\nand Rhat is the potential scale reduction factor on split chains (at \nconvergence, Rhat=1).\n\n\nHere we use as_draws_df() to plot the posterior of the log_sigma, after exponentiation. For comparison, we’ll add the sample standard deviation as the red diamond.\n\nas_draws_df(m7.1) |&gt; \n  ggplot(aes(x = exp(log_sigma))) +\n  stat_halfeye(point_interval = median_qi, .width = 0.89, adjust = 1/4) +\n  annotate(geom = \"point\",\n           x = sd(d$brain_std), y = -0.05,\n           color = \"red\", shape = 18, size = 4) +\n  scale_y_continuous(NULL, breaks = NULL) +\n  coord_cartesian(xlim = c(0, 2))\n\n\n\n\nNow granted, exp(log_sigma) is the residual standard deviation, not the unconditional sample standard deviation. But the two are nevertheless somewhat comparable, and hopefully this helps clarify the log_sigma parameter.\nHere’s the point estimate for the \\(R^2\\).\n\nas_draws_df(m7.1) |&gt; \n  expand_grid(d |&gt;\n                select(species, brain_std, mass_std)) |&gt; \n  mutate(mu = b0 + b1 * mass_std) |&gt; \n  mutate(residual = brain_std - mu) |&gt; \n  group_by(species) |&gt; \n  summarise(residual = mean(residual),\n            brain_std = mean(brain_std)) |&gt; \n  summarise(residual_var = var(residual),\n            outcome_var = var(brain_std)) |&gt; \n  mutate(r2 = 1 - residual_var / outcome_var)\n\n# A tibble: 1 × 3\n  residual_var outcome_var    r2\n         &lt;dbl&gt;       &lt;dbl&gt; &lt;dbl&gt;\n1       0.0291      0.0570 0.490\n\n\nThis matches up closely with the book’s value of 0.477 (p. 197).\nSince rstan models do not work for functions like fitted() or predict(), I’m not sure about making a general-purpose R2_is_bad() function for our models. However, we do want a method that will scale to computing \\(\\widehat{R^2}\\) from a variety of models, and the current approach won’t work well for that since it will require different equations for mu for each model.\nOne way to solve this is to include a generated quantities block in the model_code, like we did for m5.4 in Section 5.1.5.1. We’ll call this version model_code_7.1gq.\n\nmodel_code_7.1gq &lt;- '\ndata {\n  int&lt;lower=1&gt; n;\n  vector[n] brain_std;\n  vector[n] mass_std;\n}\nparameters {\n  real b0;\n  real b1;\n  real log_sigma;\n}\nmodel {\n  brain_std ~ normal(b0 + b1 * mass_std, exp(log_sigma));\n  \n  b0 ~ normal(0.5, 1);\n  b1 ~ normal(0, 10);\n  log_sigma ~ normal(0, 1);\n}\ngenerated quantities {\n  vector[n] mu;\n  mu = b0 + b1 * mass_std;  // Expected values for each case\n}\n'\n\nCompile and fit the second version of the model with stan().\n\nm7.1gq &lt;- stan(\n  data = stan_data,\n  model_code = model_code_7.1gq,\n  cores = 4, seed = 7)\n\nCheck the summary.\n\nprint(m7.1gq, probs = c(0.055, 0.945))\n\nInference for Stan model: anon_model.\n4 chains, each with iter=2000; warmup=1000; thin=1; \npost-warmup draws per chain=1000, total post-warmup draws=4000.\n\n           mean se_mean   sd  5.5% 94.5% n_eff Rhat\nb0         0.52    0.00 0.11  0.35  0.69  2032 1.00\nb1         0.17    0.00 0.12 -0.02  0.35  1812 1.00\nlog_sigma -1.40    0.01 0.38 -1.93 -0.75  1134 1.00\nmu[1]      0.40    0.00 0.14  0.16  0.61  1990 1.00\nmu[2]      0.37    0.00 0.16  0.13  0.60  1900 1.00\nmu[3]      0.36    0.00 0.16  0.10  0.60  1852 1.00\nmu[4]      0.46    0.00 0.12  0.29  0.64  2036 1.00\nmu[5]      0.68    0.00 0.16  0.45  0.91  1928 1.00\nmu[6]      0.76    0.00 0.21  0.45  1.06  1888 1.00\nmu[7]      0.65    0.00 0.14  0.44  0.85  1943 1.00\nlp__       5.89    0.06 1.62  2.82  7.59   834 1.01\n\nSamples were drawn using NUTS(diag_e) at Thu Aug  1 11:13:42 2024.\nFor each parameter, n_eff is a crude measure of effective sample size,\nand Rhat is the potential scale reduction factor on split chains (at \nconvergence, Rhat=1).\n\n\nNow we have a series of mu[i] posteriors in addition to the usual model parameters. These are our expected or fitted values, one for each of the 7 cases in the data set. Just to check, we can confirm these are indeed the same as the fitted values we might compute by working pushing the observed predictor values for mass_std through the posterior distributions for b0 and b1.\n\n# Extract the posterior draws, and make the `mu[i]` columns long\nas_draws_df(m7.1gq) |&gt; \n  pivot_longer(starts_with(\"mu\"), values_to = \"mu\", names_to = \"i\") |&gt; \n  mutate(i = str_extract(i, \"\\\\d\") |&gt; \n           as.integer()) |&gt; \n  # Add in the observed values\n  left_join(d |&gt; \n              mutate(i = 1:n()),\n            by = join_by(i)) |&gt; \n  # Compute the expected values by hand\n  mutate(fitted = b0 + b1 * mass_std) |&gt; \n  # Compare the `mu[i]` values with their hand-made `fitted` counterparts\n  summarise(all_equal = all.equal(mu, fitted))\n\n# A tibble: 1 × 1\n  all_equal\n  &lt;lgl&gt;    \n1 TRUE     \n\n\nRecall we can also extract the draws for the mu[i] expectations in a handy long format with spread_draws().\n\nm7.1gq |&gt; \n  spread_draws(mu[i]) |&gt; \n  glimpse()\n\nRows: 28,000\nColumns: 5\nGroups: i [7]\n$ i          &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n$ mu         &lt;dbl&gt; 0.6116193, 0.3411885, 0.4582914, 0.3471304, 0.5020851, 0.46…\n$ .chain     &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n$ .iteration &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, …\n$ .draw      &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, …\n\n\nThus we can use a slightly more compact spread_draws(mu[i])-based workflow to compute the point estimate for the \\(R^2\\) from the m7.1gq model.\n\nm7.1gq |&gt; \n  spread_draws(mu[i]) |&gt; \n  left_join(d |&gt; \n              mutate(i = 1:n()),\n            by = join_by(i)) |&gt; \n  mutate(residual = brain_std - mu) |&gt; \n  group_by(species) |&gt; \n  summarise(residual = mean(residual),\n            brain_std = mean(brain_std)) |&gt; \n  summarise(residual_var = var(residual),\n            outcome_var = var(brain_std)) |&gt; \n  mutate(r2 = 1 - residual_var / outcome_var)\n\n# A tibble: 1 × 3\n  residual_var outcome_var    r2\n         &lt;dbl&gt;       &lt;dbl&gt; &lt;dbl&gt;\n1       0.0291      0.0570 0.490\n\n\nTo make the fitted line-ribbons displayed in Figure 7.3, we’ll also want a streamlined way to compute those values for several model types. As a first step toward that aim, we will adopt the model.matrix() approach we introduced in Section 6.3.2.1. Here we make a model.matrix() object for the first model called mm_7.1\n\n# Define a model matrix\nmm_7.1 &lt;- model.matrix(data = d, object = ~mass_std)\n\n# What?\nstr(mm_7.1)\n\n num [1:7, 1:2] 1 1 1 1 1 ...\n - attr(*, \"dimnames\")=List of 2\n  ..$ : chr [1:7] \"1\" \"2\" \"3\" \"4\" ...\n  ..$ : chr [1:2] \"(Intercept)\" \"mass_std\"\n - attr(*, \"assign\")= int [1:2] 0 1\n\nhead(mm_7.1)\n\n  (Intercept)   mass_std\n1           1 -0.7794667\n2           1 -0.9170196\n3           1 -1.0087216\n4           1 -0.3668079\n5           1  0.9170196\n6           1  1.4213804\n\n\nWe can use this mm_7.1 object to define two new elements within compose_data(). The first will be X, the entire model matrix mm_7.1. The second will be k, the number of columns (i.e., “predictors”) in the design matrix.\n\nstan_data &lt;- d |&gt;\n  select(brain_std, mass_std) |&gt; \n  # Define `X` and `k` right in the `compose_data()` function\n  compose_data(X = mm_7.1,\n               k = ncol(mm_7.1))\n\n# What?\nstr(stan_data)\n\nList of 5\n $ brain_std: num [1:7(1d)] 0.324 0.335 0.453 0.386 0.557 ...\n $ mass_std : num [1:7(1d)] -0.779 -0.917 -1.009 -0.367 0.917 ...\n $ n        : int 7\n $ X        : num [1:7, 1:2] 1 1 1 1 1 ...\n  ..- attr(*, \"dimnames\")=List of 2\n  .. ..$ : chr [1:7] \"1\" \"2\" \"3\" \"4\" ...\n  .. ..$ : chr [1:2] \"(Intercept)\" \"mass_std\"\n  ..- attr(*, \"assign\")= int [1:2] 0 1\n $ k        : int 2\n\n\nNow update the model_code to use the model.matrix() approach in the various blocks. This time we’ll call the thing model_code_7.1mm.\n\nmodel_code_7.1mm &lt;- '\ndata {\n  int&lt;lower=1&gt; n;\n  int&lt;lower=1&gt; k;       // Number of coefficients (including intercept)\n  vector[n] brain_std;  \n  matrix[n, k] X;       // Regressors from the model matrix (including intercept)\n}\nparameters {\n  vector[k] b;     // The beta coefficients are now defined by a vector\n  real log_sigma;  \n}\nmodel {\n  brain_std ~ normal(X * b, exp(log_sigma));  // Linear model defined in matrix algebra notation Xb\n  b[1] ~ normal(0.5, 1);                      // Priors for the `b` coefficients now use `[]` indices\n  b[2] ~ normal(0, 10);\n  log_sigma ~ normal(0, 1);\n}\ngenerated quantities {\n  vector[n] mu;\n  mu = X * b;  // Expected values computed with matrix algebra notation Xb\n}\n'\n\nCompile and fit the third version of the model with stan().\n\nm7.1mm &lt;- stan(\n  data = stan_data,\n  model_code = model_code_7.1mm,\n  cores = 4, seed = 7)\n\nCheck the summary.\n\nprint(m7.1mm, probs = c(0.055, 0.945))\n\nInference for Stan model: anon_model.\n4 chains, each with iter=2000; warmup=1000; thin=1; \npost-warmup draws per chain=1000, total post-warmup draws=4000.\n\n           mean se_mean   sd  5.5% 94.5% n_eff Rhat\nb[1]       0.53    0.00 0.11  0.36  0.69  2028    1\nb[2]       0.17    0.00 0.12 -0.01  0.35  1914    1\nlog_sigma -1.40    0.01 0.39 -1.95 -0.72  1259    1\nmu[1]      0.40    0.00 0.14  0.18  0.61  1859    1\nmu[2]      0.38    0.00 0.15  0.14  0.60  1850    1\nmu[3]      0.36    0.00 0.16  0.11  0.60  1846    1\nmu[4]      0.47    0.00 0.12  0.29  0.64  1925    1\nmu[5]      0.68    0.00 0.17  0.45  0.92  2075    1\nmu[6]      0.77    0.00 0.21  0.46  1.07  2041    1\nmu[7]      0.65    0.00 0.15  0.44  0.87  2085    1\nlp__       5.87    0.05 1.64  2.85  7.59   949    1\n\nSamples were drawn using NUTS(diag_e) at Thu Aug  1 11:13:47 2024.\nFor each parameter, n_eff is a crude measure of effective sample size,\nand Rhat is the potential scale reduction factor on split chains (at \nconvergence, Rhat=1).\n\n\nThe results are within HMC simulation variance to the ones from the previous version of the model, m7.1gq. But now the input elements in the various blocks of the model_code are general enough they will scale to models with different predictors.\nAs a last step, we’ll add another model.matrix() element to the stan_data to support the fitted lines for the six models displayed in Figure 7.3. To make a smooth line and 89%-CI ribbon for each model, we’ll need a way to feed in a tight sequence of body-mass values into each of the models. We here define those values in a data frame called d_pred.\n\nd_pred &lt;- data.frame(mass_std = seq(from = -2, to = 2, length.out = 100))\n\n# What?\nglimpse(d_pred)\n\nRows: 100\nColumns: 1\n$ mass_std &lt;dbl&gt; -2.000000, -1.959596, -1.919192, -1.878788, -1.838384, -1.797…\n\n\nNow we have our sequence of predictor values in d_pred, we can add them to the stan_data via the model.matrix() function. Within the stan_data, we’ll call this new matrix Xpred. Here’s what that looks like.\n\nstan_data &lt;- d |&gt;\n  select(brain_std, mass_std) |&gt; \n  compose_data(X = mm_7.1,\n               # This line is new\n               Xpred = model.matrix(data = d_pred, object = ~mass_std),\n               k = ncol(mm_7.1))\n\n# What?\nstr(stan_data)\n\nList of 6\n $ brain_std: num [1:7(1d)] 0.324 0.335 0.453 0.386 0.557 ...\n $ mass_std : num [1:7(1d)] -0.779 -0.917 -1.009 -0.367 0.917 ...\n $ n        : int 7\n $ X        : num [1:7, 1:2] 1 1 1 1 1 ...\n  ..- attr(*, \"dimnames\")=List of 2\n  .. ..$ : chr [1:7] \"1\" \"2\" \"3\" \"4\" ...\n  .. ..$ : chr [1:2] \"(Intercept)\" \"mass_std\"\n  ..- attr(*, \"assign\")= int [1:2] 0 1\n $ Xpred    : num [1:100, 1:2] 1 1 1 1 1 1 1 1 1 1 ...\n  ..- attr(*, \"dimnames\")=List of 2\n  .. ..$ : chr [1:100] \"1\" \"2\" \"3\" \"4\" ...\n  .. ..$ : chr [1:2] \"(Intercept)\" \"mass_std\"\n  ..- attr(*, \"assign\")= int [1:2] 0 1\n $ k        : int 2\n\n\nNow update the model_code to include 2 sections in the generated quantities block.\n\nmodel_code_7.1gq2 &lt;- '\ndata {\n  int&lt;lower=1&gt; n;\n  int&lt;lower=1&gt; k;\n  vector[n] brain_std;  \n  matrix[n, k] X;\n  matrix[100, k] Xpred;  // New data for fitted lines\n}\nparameters {\n  vector[k] b;\n  real log_sigma;  \n}\nmodel {\n  brain_std ~ normal(X * b, exp(log_sigma));\n  b[1] ~ normal(0.5, 1);\n  b[2] ~ normal(0, 10);\n  log_sigma ~ normal(0, 1);\n}\ngenerated quantities {\n  vector[n] mu;\n  mu = X * b;\n  \n  vector[100] fitted;  // A second section for the fitted lines\n  fitted = Xpred * b;\n}\n'\n\nCompile and fit the final version of the model with stan().\n\nm7.1gq2 &lt;- stan(\n  data = stan_data,\n  model_code = model_code_7.1gq2,\n  cores = 4, seed = 7)\n\nCheck the summary.\n\nprint(m7.1gq2, probs = c(0.055, 0.945))\n\nI’m suppressing the print() output for the sake of space. Now it contains an additional 100 rows for the new fitted[b] values. But if you’re following along with code on your computer, do give that output a look.\nHere’s how to showcase those fitted[b] values in a plot.\n\n# Compute R2 and save as a data frame\nd_r2 &lt;- m7.1gq2 |&gt; \n  spread_draws(mu[i]) |&gt; \n  left_join(d |&gt; \n              mutate(i = 1:n()),\n            by = join_by(i)) |&gt; \n  mutate(residual = brain_std - mu) |&gt; \n  group_by(species) |&gt; \n  summarise(residual = mean(residual),\n            brain_std = mean(brain_std)) |&gt; \n  summarise(residual_var = var(residual),\n            outcome_var = var(brain_std)) |&gt; \n  transmute(r2 = str_c(\"widehat(italic(R)^2)==\", round(1 - residual_var / outcome_var, digits = 2)),\n            mass = min(d$mass),\n            brain = max(d$brain))\n\n# Start wrangling the `fitted[]` draws for the plot\nm7.1gq2 |&gt; \n  spread_draws(fitted[row]) |&gt; \n  # Convert the fitted values back to the `brain` metric\n  mutate(brain = fitted * max(d$brain)) |&gt; \n  # Join the `d_pred` data\n  left_join(d_pred |&gt; \n              mutate(row = 1:n()),\n            by = join_by(row)) |&gt; \n  # Convert the `mass_std` values back to the `mass` metric\n  mutate(mass = mass_std * sd(d$mass) + mean(d$mass)) |&gt; \n  \n  # Plot!\n  ggplot(aes(x = mass, y = brain)) +\n  stat_lineribbon(point_interval = mean_qi, .width = c(0.67, 0.89), \n                  color = \"lightblue4\", linewidth = 2/3) +\n  geom_point(data = d) +\n  # Add in the R2 estimate\n  geom_text(data = d_r2,\n            aes(label = r2),\n            hjust = 0, parse = TRUE) +\n  scale_x_continuous(\"body mass (kg)\", breaks = c(35, 47, 60)) +\n  scale_y_continuous(\"brain volume (cc)\", breaks = c(450, 900, 1300)) +\n  scale_fill_manual(values = c(\"lightblue1\", \"lightblue2\")) +\n  coord_cartesian(xlim = c(32, 63),\n                  ylim = c(400, 1400))\n\n\n\n\nConsistent with my brms translation, the models fit with stan() consistently show wider 89% intervals than the ones McElreath showed fit with quap() in this part of the text. However, the stan()-based 67% intervals are pretty close to the intervals displayed in Figure 7.3 in the text, so we’ll show both for the plots to come.\nNow we have a workflow that supports fitting, summarizing, and plotting the first linear model and its curvier variants, we’re ready to work in bulk.\nFirst, we update both the d and d_pred data frames to include mass_std1 through mass_std6.\n\nd &lt;- d |&gt; \n  mutate(mass_std1 = mass_std,\n         mass_std2 = mass_std^2,\n         mass_std3 = mass_std^3,\n         mass_std4 = mass_std^4,\n         mass_std5 = mass_std^5,\n         mass_std6 = mass_std^6)\n\nd_pred &lt;- data.frame(mass_std1 = seq(from = -2, to = 2, length.out = 100)) |&gt; \n  mutate(mass_std2 = mass_std1^2,\n         mass_std3 = mass_std1^3,\n         mass_std4 = mass_std1^4,\n         mass_std5 = mass_std1^5,\n         mass_std6 = mass_std1^6)\n\n# What?\nglimpse(d)\n\nRows: 7\nColumns: 11\n$ species   &lt;chr&gt; \"afarensis\", \"africanus\", \"habilis\", \"boisei\", \"rudolfensis\"…\n$ brain     &lt;dbl&gt; 438, 452, 612, 521, 752, 871, 1350\n$ mass      &lt;dbl&gt; 37.0, 35.5, 34.5, 41.5, 55.5, 61.0, 53.5\n$ mass_std  &lt;dbl&gt; -0.7794667, -0.9170196, -1.0087216, -0.3668079, 0.9170196, 1…\n$ brain_std &lt;dbl&gt; 0.3244444, 0.3348148, 0.4533333, 0.3859259, 0.5570370, 0.645…\n$ mass_std1 &lt;dbl&gt; -0.7794667, -0.9170196, -1.0087216, -0.3668079, 0.9170196, 1…\n$ mass_std2 &lt;dbl&gt; 0.6075683, 0.8409250, 1.0175193, 0.1345480, 0.8409250, 2.020…\n$ mass_std3 &lt;dbl&gt; -0.47357927, -0.77114476, -1.02639367, -0.04935326, 0.771144…\n$ mass_std4 &lt;dbl&gt; 0.36913927, 0.70715489, 1.03534547, 0.01810317, 0.70715489, …\n$ mass_std5 &lt;dbl&gt; -0.287731766, -0.648474917, -1.044375339, -0.006640383, 0.64…\n$ mass_std6 &lt;dbl&gt; 0.224277328, 0.594664234, 1.053483965, 0.002435745, 0.594664…\n\nglimpse(d_pred)\n\nRows: 100\nColumns: 6\n$ mass_std1 &lt;dbl&gt; -2.000000, -1.959596, -1.919192, -1.878788, -1.838384, -1.79…\n$ mass_std2 &lt;dbl&gt; 4.000000, 3.840016, 3.683298, 3.529844, 3.379655, 3.232731, …\n$ mass_std3 &lt;dbl&gt; -8.000000, -7.524880, -7.068955, -6.631828, -6.213103, -5.81…\n$ mass_std4 &lt;dbl&gt; 16.000000, 14.745725, 13.566681, 12.459798, 11.422069, 10.45…\n$ mass_std5 &lt;dbl&gt; -32.000000, -28.895664, -26.037065, -23.409317, -20.998147, …\n$ mass_std6 &lt;dbl&gt; 64.0000000, 56.6238262, 49.9701253, 43.9811416, 38.6026537, …\n\n\nWe are going to fit and store the models and their output within a nested data frame. As a first step, we’ll define the six models by their names in the model column, the number of predictors (excluding the intercept) in the predictors column, and the formulas for their model matrices in a formula column.\n\nd_fits &lt;- tibble(model = str_c(\"m7.\", 1:6)) |&gt; \n  mutate(predictors = str_remove(model, \"m7.\") |&gt; \n           as.integer(),\n         formula = c(\n           ~ mass_std1,\n           ~ mass_std1 + mass_std2,\n           ~ mass_std1 + mass_std2 + mass_std3,\n           ~ mass_std1 + mass_std2 + mass_std3 + mass_std4,\n           ~ mass_std1 + mass_std2 + mass_std3 + mass_std4 + mass_std5,\n           ~ mass_std1 + mass_std2 + mass_std3 + mass_std4 + mass_std5 + mass_std6)) \n\n# What?\nprint(d_fits)\n\n# A tibble: 6 × 3\n  model predictors formula  \n  &lt;chr&gt;      &lt;int&gt; &lt;list&gt;   \n1 m7.1           1 &lt;formula&gt;\n2 m7.2           2 &lt;formula&gt;\n3 m7.3           3 &lt;formula&gt;\n4 m7.4           4 &lt;formula&gt;\n5 m7.5           5 &lt;formula&gt;\n6 m7.6           6 &lt;formula&gt;\n\n\nNow compute the model.matrix() output for each using the formula column as input to the object argument, via the map() function, and save the contents as a nested column named mm. Then compute the d_pred data frames for each model using the numbers in the predictors column as input for subsetting the necessary columns from the external object d_pred, via map(). We save the results of that operation as a nested column named d_pred.\n\nd_fits &lt;- d_fits |&gt; \n  mutate(mm = map(.x = formula, .f =~ model.matrix(data = d, object = .x)),\n         d_pred = map(.x = predictors, .f =~ d_pred |&gt; \n                         select(mass_std1:str_c(\"mass_std\", .x))))\n\n# What?\nprint(d_fits)\n\n# A tibble: 6 × 5\n  model predictors formula   mm            d_pred        \n  &lt;chr&gt;      &lt;int&gt; &lt;list&gt;    &lt;list&gt;        &lt;list&gt;        \n1 m7.1           1 &lt;formula&gt; &lt;dbl [7 × 2]&gt; &lt;df [100 × 1]&gt;\n2 m7.2           2 &lt;formula&gt; &lt;dbl [7 × 3]&gt; &lt;df [100 × 2]&gt;\n3 m7.3           3 &lt;formula&gt; &lt;dbl [7 × 4]&gt; &lt;df [100 × 3]&gt;\n4 m7.4           4 &lt;formula&gt; &lt;dbl [7 × 5]&gt; &lt;df [100 × 4]&gt;\n5 m7.5           5 &lt;formula&gt; &lt;dbl [7 × 6]&gt; &lt;df [100 × 5]&gt;\n6 m7.6           6 &lt;formula&gt; &lt;dbl [7 × 7]&gt; &lt;df [100 × 6]&gt;\n\n\nNext we compute the stan_data using the mm, d_pred, and formula columns as input for the compose_data() and model.matrix() functions, all via the pmap() function. We save the results in a nested column named stan_data.\n\nd_fits &lt;- d_fits |&gt; \n  mutate(stan_data = pmap(.l = list(mm, d_pred, formula), \n                          .f =~ d |&gt; \n                            select(brain_std:mass_std6) |&gt; \n                            compose_data(X = ..1,\n                                         Xpred = model.matrix(data = ..2, object = ..3),\n                                         k = ncol(..1))))\n\n# What?\nprint(d_fits)\n\n# A tibble: 6 × 6\n  model predictors formula   mm            d_pred         stan_data        \n  &lt;chr&gt;      &lt;int&gt; &lt;list&gt;    &lt;list&gt;        &lt;list&gt;         &lt;list&gt;           \n1 m7.1           1 &lt;formula&gt; &lt;dbl [7 × 2]&gt; &lt;df [100 × 1]&gt; &lt;named list [11]&gt;\n2 m7.2           2 &lt;formula&gt; &lt;dbl [7 × 3]&gt; &lt;df [100 × 2]&gt; &lt;named list [11]&gt;\n3 m7.3           3 &lt;formula&gt; &lt;dbl [7 × 4]&gt; &lt;df [100 × 3]&gt; &lt;named list [11]&gt;\n4 m7.4           4 &lt;formula&gt; &lt;dbl [7 × 5]&gt; &lt;df [100 × 4]&gt; &lt;named list [11]&gt;\n5 m7.5           5 &lt;formula&gt; &lt;dbl [7 × 6]&gt; &lt;df [100 × 5]&gt; &lt;named list [11]&gt;\n6 m7.6           6 &lt;formula&gt; &lt;dbl [7 × 7]&gt; &lt;df [100 × 6]&gt; &lt;named list [11]&gt;\n\n\nDefine a generic model_code for all 6 models. This is the same as the previous one with one last addition: Now we have used the syntax of b[2:k] to refer to all non-intercept \\(\\beta\\) parameters within the model block. Save this glorious monstrosity as model_code_7.1to6.\n\nmodel_code_7.1to6 &lt;- '\ndata {\n  int&lt;lower=1&gt; n;\n  int&lt;lower=1&gt; k;\n  vector[n] brain_std;  \n  matrix[n, k] X;\n  matrix[100, k] Xpred;\n}\nparameters {\n  vector[k] b;\n  real log_sigma; \n}\nmodel {\n  brain_std ~ normal(X * b, exp(log_sigma));\n  b[1] ~ normal(0.5, 1);\n  // New general-purpose notation for the non-intercept `beta[k]` priors\n  b[2:k] ~ normal(0, 10);\n  log_sigma ~ normal(0, 1);\n}\ngenerated quantities {\n  vector[n] mu;\n  vector[100] fitted;\n  mu = X * b;\n  fitted = Xpred * b;\n}\n'\n\nCompile with stan_model() and save the DSO as stan_dso.\n\nstan_dso &lt;- stan_model(model_code = model_code_7.1to6)\n\nNow draw from the posterior distributions of all 6 models by using the sampling() function within map(), saving the results in a nested column called sampling within the d_fits data frame.\n\nd_fits &lt;- d_fits |&gt; \n  mutate(sampling = map(.x = stan_data, \n                        .f =~ sampling(\n                          object = stan_dso, \n                          data = .x,\n                          seed = 7)))\n\nExtract the as_draws_df() output from each model with map(), saving the results in a column named as_draws_df.\n\nd_fits &lt;- d_fits |&gt; \n  mutate(as_draws_df = map(.x = sampling, .f = as_draws_df))\n\n# What?\nd_fits |&gt; \n  select(model, sampling, as_draws_df)\n\n# A tibble: 6 × 3\n  model sampling          as_draws_df             \n  &lt;chr&gt; &lt;list&gt;            &lt;list&gt;                  \n1 m7.1  &lt;stanfit[,4,111]&gt; &lt;draws_df [4,000 × 114]&gt;\n2 m7.2  &lt;stanfit[,4,112]&gt; &lt;draws_df [4,000 × 115]&gt;\n3 m7.3  &lt;stanfit[,4,113]&gt; &lt;draws_df [4,000 × 116]&gt;\n4 m7.4  &lt;stanfit[,4,114]&gt; &lt;draws_df [4,000 × 117]&gt;\n5 m7.5  &lt;stanfit[,4,115]&gt; &lt;draws_df [4,000 × 118]&gt;\n6 m7.6  &lt;stanfit[,4,116]&gt; &lt;draws_df [4,000 × 119]&gt;\n\n\nUpdate the d_r2 for all models.\n\nd_r2 &lt;- d_fits |&gt; \n  unnest(as_draws_df) |&gt; \n  select(model, .draw, starts_with(\"mu\")) |&gt; \n  pivot_longer(starts_with(\"mu\"), names_to = \"i\", values_to = \"mu\") |&gt; \n  mutate(i = str_extract(i, \"\\\\d\") |&gt; \n           as.integer()) |&gt; \n  left_join(d |&gt; \n              mutate(i = 1:n()),\n            by = join_by(i)) |&gt; \n  mutate(residual = brain_std - mu) |&gt; \n  group_by(model, species) |&gt; \n  summarise(residual = mean(residual),\n            brain_std = mean(brain_std)) |&gt; \n  summarise(residual_var = var(residual),\n            outcome_var = var(brain_std)) |&gt; \n  transmute(model = model, \n            r2 = str_c(\"widehat(italic(R)^2)==\", round(1 - residual_var / outcome_var, digits = 2)),\n            mass = min(d$mass),\n            brain = max(d$brain))\n\n# What?\nprint(d_r2)\n\n# A tibble: 6 × 4\n  model r2                          mass brain\n  &lt;chr&gt; &lt;chr&gt;                      &lt;dbl&gt; &lt;dbl&gt;\n1 m7.1  widehat(italic(R)^2)==0.49  34.5  1350\n2 m7.2  widehat(italic(R)^2)==0.54  34.5  1350\n3 m7.3  widehat(italic(R)^2)==0.68  34.5  1350\n4 m7.4  widehat(italic(R)^2)==0.8   34.5  1350\n5 m7.5  widehat(italic(R)^2)==0.94  34.5  1350\n6 m7.6  widehat(italic(R)^2)==0.93  34.5  1350\n\n\nMake the full version of Figure 7.3.\n\nd_fits |&gt; \n  select(model, as_draws_df) |&gt; \n  unnest(as_draws_df) |&gt; \n  select(model, .draw, starts_with(\"fitted\")) |&gt; \n  pivot_longer(starts_with(\"fitted\"), names_to = \"row\") |&gt; \n  mutate(row = str_extract(row, \"\\\\d+\") |&gt; as.integer()) |&gt; \n  mutate(brain = value * max(d$brain)) |&gt; \n  left_join(d_pred |&gt; \n              mutate(row = 1:n()),\n            by = join_by(row)) |&gt; \n  mutate(mass = mass_std1 * sd(d$mass) + mean(d$mass)) |&gt; \n  \n  ggplot(aes(x = mass, y = brain)) +\n  stat_lineribbon(point_interval = mean_qi, .width = c(0.67, 0.89), \n                  color = \"lightblue4\", linewidth = 2/3) +\n  geom_point(data = d) +\n  geom_text(data = d_r2,\n            aes(label = r2),\n            hjust = 0, parse = TRUE) +\n  scale_x_continuous(\"body mass (kg)\", breaks = c(35, 47, 60)) +\n  scale_y_continuous(\"brain volume (cc)\", breaks = c(450, 900, 1300)) +\n  scale_fill_manual(values = c(\"lightblue1\", \"lightblue2\")) +\n  coord_cartesian(xlim = c(32, 63),\n                  ylim = c(400, 1400)) +\n  facet_wrap(~ model)\n\n\n\n\nThough the fitted lines for all our models are much less certain than the quap()-based ones McElreath displayed in the text, they’re most notably so for the last model m7.6. This phenomena is connected at least in part to the increasing uncertainty in the exp(log_sigma) posterior for the models. Here they are in a plot.\n\nd_fits |&gt; \n  select(model, as_draws_df) |&gt; \n  unnest(as_draws_df) |&gt; \n  \n  ggplot(aes(x = exp(log_sigma), y = model)) +\n  stat_halfeye(.width = 0.89) +\n  scale_y_discrete(NULL, expand = expansion(mult = 0.05)) +\n  coord_cartesian(xlim = c(0, 3))\n\n\n\n\nBut McElreath wrote:\n\nThat last model, m7.6, has one trick in it. The standard deviation is replaced with a constant value 0.001. (p. 198)\n\nWe can do that with stan(), too. But here we’ll abandon our bulk data frame workflow and fit this version of the model separate. First, define model_code_7.6b with \\(\\sigma\\) fixed to a constant 0.001.\n\nmodel_code_7.6b &lt;- '\ndata {\n  int&lt;lower=1&gt; n;\n  int&lt;lower=1&gt; k;\n  vector[n] brain_std;  \n  matrix[n, k] X;\n  matrix[100, k] Xpred;\n}\nparameters {\n  vector[k] b;\n}\nmodel {\n  brain_std ~ normal(X * b, 0.001);  // Set sigma to a constant\n  b[1] ~ normal(0.5, 1);\n  b[2:k] ~ normal(0, 10);\n  // Note how `sigma`, or `log_sigma` for that matter, no longer has a prior\n}\ngenerated quantities {\n  vector[n] mu;\n  mu = X * b;\n  vector[100] fitted;\n  fitted = Xpred * b;\n}\n'\n\nCompile and fit the special version of the model with stan().\n\nm7.6b &lt;- stan(\n  # Note how we're reusing the `stan_data` from `d_fits`\n  data = d_fits |&gt; \n    slice(6) |&gt; \n    unnest(stan_data) |&gt; \n    pull(stan_data),\n  model_code = model_code_7.6b,\n  cores = 4, seed = 7)\n\nHere we’ll restrict the model summary by using the pars argument within print().\n\nprint(m7.6b, pars = \"b\", probs = c(0.05, 0.945))\n\nInference for Stan model: anon_model.\n4 chains, each with iter=2000; warmup=1000; thin=1; \npost-warmup draws per chain=1000, total post-warmup draws=4000.\n\n      mean se_mean   sd    5% 94.5% n_eff Rhat\nb[1]  0.51       0 0.01  0.49  0.52   200 1.01\nb[2]  0.88       0 0.01  0.86  0.90   201 1.01\nb[3]  1.70       0 0.04  1.64  1.76   199 1.01\nb[4] -0.61       0 0.04 -0.67 -0.56   197 1.01\nb[5] -3.47       0 0.06 -3.57 -3.38   198 1.01\nb[6] -0.35       0 0.02 -0.38 -0.31   196 1.01\nb[7]  1.63       0 0.03  1.58  1.67   197 1.01\n\nSamples were drawn using NUTS(diag_e) at Thu Aug  1 11:14:20 2024.\nFor each parameter, n_eff is a crude measure of effective sample size,\nand Rhat is the potential scale reduction factor on split chains (at \nconvergence, Rhat=1).\n\n\nBecause we used the 0.001 constant in the likelihood, we nave no sigma or log_sigma parameter. It’s a constant. Anyway, here’s the plot.\n\n# Compute R2 and save as a data frame\nd_r2 &lt;- m7.6b |&gt; \n  spread_draws(mu[i]) |&gt; \n  left_join(d |&gt; \n              mutate(i = 1:n()),\n            by = join_by(i)) |&gt; \n  mutate(residual = brain_std - mu) |&gt; \n  group_by(species) |&gt; \n  summarise(residual = mean(residual),\n            brain_std = mean(brain_std)) |&gt; \n  summarise(residual_var = var(residual),\n            outcome_var = var(brain_std)) |&gt; \n  transmute(r2 = str_c(\"widehat(italic(R)^2)==\", round(1 - residual_var / outcome_var, digits = 2)),\n            mass = min(d$mass),\n            brain = 1900)\n\n# Start wrangling the `fitted[]` draws for the plot\nm7.6b |&gt; \n  spread_draws(fitted[row]) |&gt; \n  # Convert the fitted values back to the `brain` metric\n  mutate(brain = fitted * max(d$brain)) |&gt; \n  # Join the `d_pred` data\n  left_join(d_pred |&gt; \n              mutate(row = 1:n()),\n            by = join_by(row)) |&gt; \n  # Convert the `mass_std` values back to the `mass` metric\n  mutate(mass = mass_std1 * sd(d$mass) + mean(d$mass)) |&gt; \n  \n  # Plot!\n  ggplot(aes(x = mass, y = brain)) +\n  geom_hline(yintercept = 0, color = \"white\") +\n  stat_lineribbon(point_interval = mean_qi, .width = c(0.67, 0.89), \n                  color = \"lightblue4\", linewidth = 2/3) +\n  geom_point(data = d) +\n  # Add in the R2 estimate\n  geom_text(data = d_r2,\n            aes(label = r2),\n            hjust = 0, parse = TRUE) +\n  scale_x_continuous(\"body mass (kg)\", breaks = c(35, 47, 60)) +\n  scale_y_continuous(\"brain volume (cc)\", breaks = c(0, 450, 1300)) +\n  scale_fill_manual(values = c(\"lightblue1\", \"lightblue2\")) +\n  coord_cartesian(xlim = c(32, 63),\n                  ylim = c(-400, 2000)) +\n  facet_wrap(~ \"m7.6b\")\n\n\n\n\nNow the results are very close to those McElreath displayed in the text.\n\n7.1.1.1 Rethinking: Model fitting as compression.\n\n\n\n7.1.2 Too few parameters hurts, too.\nTo explore the distinctions between overfitting and underfitting, we’ll need to refit m7.1 and m7.4 several times after serially dropping one of the rows in the data. You can filter() by row_number() to drop rows. For example, we can drop the second row of d like this.\n\nd |&gt;\n  mutate(row = 1:n()) |&gt; \n  filter(row_number() != 2)\n\n# A tibble: 6 × 12\n  species brain  mass mass_std brain_std mass_std1 mass_std2 mass_std3 mass_std4\n  &lt;chr&gt;   &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n1 afaren…   438  37     -0.779     0.324    -0.779     0.608   -0.474     0.369 \n2 habilis   612  34.5   -1.01      0.453    -1.01      1.02    -1.03      1.04  \n3 boisei    521  41.5   -0.367     0.386    -0.367     0.135   -0.0494    0.0181\n4 rudolf…   752  55.5    0.917     0.557     0.917     0.841    0.771     0.707 \n5 ergast…   871  61      1.42      0.645     1.42      2.02     2.87      4.08  \n6 sapiens  1350  53.5    0.734     1         0.734     0.538    0.395     0.290 \n# ℹ 3 more variables: mass_std5 &lt;dbl&gt;, mass_std6 &lt;dbl&gt;, row &lt;int&gt;\n\n\nIn his Overthinking: Dropping rows box (p. 202), McElreath encouraged us to take a look at the brain_loo_plot() function to get a sense of how he made his Figure 7.4. You can do so by executing rethinking::brain_loo_plot in your console. Our approach will be different. We’ll begin by defining a d_fits_subset data frame starting with model, predictors, and formula columns like before. This time we add a new column called row, which we’ll use to reference which row we’d like to drop for a given iteration.\n\nd_fits_subset &lt;- tibble(model = str_c(\"m7.\", c(1, 4))) |&gt; \n  mutate(predictors = str_remove(model, \"m7.\") |&gt; \n           as.integer(),\n         formula = c(\n           ~ mass_std1,\n           ~ mass_std1 + mass_std2 + mass_std3 + mass_std4)) |&gt; \n  expand_grid(row = 1:7)\n\n# What?\nglimpse(d_fits_subset)\n\nRows: 14\nColumns: 4\n$ model      &lt;chr&gt; \"m7.1\", \"m7.1\", \"m7.1\", \"m7.1\", \"m7.1\", \"m7.1\", \"m7.1\", \"m7…\n$ predictors &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 4, 4, 4, 4, 4, 4, 4\n$ formula    &lt;list&gt; &lt;~mass_std1&gt;, &lt;~mass_std1&gt;, &lt;~mass_std1&gt;, &lt;~mass_std1&gt;, &lt;~m…\n$ row        &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7\n\n\nAdd a mm column based on model.matrix() output.\n\nd_fits_subset &lt;- d_fits_subset |&gt; \n  mutate(mm = map2(.x = row,\n                   .y = formula,\n                   .f =~ model.matrix(data = d |&gt; \n                                        filter(row_number() != .x),\n                                      object = .y)))\n\n# What?\nprint(d_fits_subset)\n\n# A tibble: 14 × 5\n   model predictors formula     row mm           \n   &lt;chr&gt;      &lt;int&gt; &lt;list&gt;    &lt;int&gt; &lt;list&gt;       \n 1 m7.1           1 &lt;formula&gt;     1 &lt;dbl [6 × 2]&gt;\n 2 m7.1           1 &lt;formula&gt;     2 &lt;dbl [6 × 2]&gt;\n 3 m7.1           1 &lt;formula&gt;     3 &lt;dbl [6 × 2]&gt;\n 4 m7.1           1 &lt;formula&gt;     4 &lt;dbl [6 × 2]&gt;\n 5 m7.1           1 &lt;formula&gt;     5 &lt;dbl [6 × 2]&gt;\n 6 m7.1           1 &lt;formula&gt;     6 &lt;dbl [6 × 2]&gt;\n 7 m7.1           1 &lt;formula&gt;     7 &lt;dbl [6 × 2]&gt;\n 8 m7.4           4 &lt;formula&gt;     1 &lt;dbl [6 × 5]&gt;\n 9 m7.4           4 &lt;formula&gt;     2 &lt;dbl [6 × 5]&gt;\n10 m7.4           4 &lt;formula&gt;     3 &lt;dbl [6 × 5]&gt;\n11 m7.4           4 &lt;formula&gt;     4 &lt;dbl [6 × 5]&gt;\n12 m7.4           4 &lt;formula&gt;     5 &lt;dbl [6 × 5]&gt;\n13 m7.4           4 &lt;formula&gt;     6 &lt;dbl [6 × 5]&gt;\n14 m7.4           4 &lt;formula&gt;     7 &lt;dbl [6 × 5]&gt;\n\n\nNext we add the d_pred column like before. When we define the stan_data this time, we also include the row column as one of the inputs in pmap(), which will allow us to subset the d data we input to compose_data().\n\nd_fits_subset &lt;- d_fits_subset |&gt; \n  mutate(d_pred = map(.x = predictors, .f =~ d_pred |&gt; \n                         select(mass_std1:str_c(\"mass_std\", .x)))) |&gt; \n  mutate(stan_data = pmap(.l = list(row, mm, d_pred, formula), \n                          .f =~ d |&gt; \n                            filter(row_number() != ..1) |&gt; \n                            select(brain_std:mass_std6) |&gt; \n                            compose_data(X = ..2,\n                                         Xpred = model.matrix(data = ..3, object = ..4),\n                                         k = ncol(..2))))\n\n# What?\nprint(d_fits_subset)\n\n# A tibble: 14 × 7\n   model predictors formula     row mm            d_pred         stan_data   \n   &lt;chr&gt;      &lt;int&gt; &lt;list&gt;    &lt;int&gt; &lt;list&gt;        &lt;list&gt;         &lt;list&gt;      \n 1 m7.1           1 &lt;formula&gt;     1 &lt;dbl [6 × 2]&gt; &lt;df [100 × 1]&gt; &lt;named list&gt;\n 2 m7.1           1 &lt;formula&gt;     2 &lt;dbl [6 × 2]&gt; &lt;df [100 × 1]&gt; &lt;named list&gt;\n 3 m7.1           1 &lt;formula&gt;     3 &lt;dbl [6 × 2]&gt; &lt;df [100 × 1]&gt; &lt;named list&gt;\n 4 m7.1           1 &lt;formula&gt;     4 &lt;dbl [6 × 2]&gt; &lt;df [100 × 1]&gt; &lt;named list&gt;\n 5 m7.1           1 &lt;formula&gt;     5 &lt;dbl [6 × 2]&gt; &lt;df [100 × 1]&gt; &lt;named list&gt;\n 6 m7.1           1 &lt;formula&gt;     6 &lt;dbl [6 × 2]&gt; &lt;df [100 × 1]&gt; &lt;named list&gt;\n 7 m7.1           1 &lt;formula&gt;     7 &lt;dbl [6 × 2]&gt; &lt;df [100 × 1]&gt; &lt;named list&gt;\n 8 m7.4           4 &lt;formula&gt;     1 &lt;dbl [6 × 5]&gt; &lt;df [100 × 4]&gt; &lt;named list&gt;\n 9 m7.4           4 &lt;formula&gt;     2 &lt;dbl [6 × 5]&gt; &lt;df [100 × 4]&gt; &lt;named list&gt;\n10 m7.4           4 &lt;formula&gt;     3 &lt;dbl [6 × 5]&gt; &lt;df [100 × 4]&gt; &lt;named list&gt;\n11 m7.4           4 &lt;formula&gt;     4 &lt;dbl [6 × 5]&gt; &lt;df [100 × 4]&gt; &lt;named list&gt;\n12 m7.4           4 &lt;formula&gt;     5 &lt;dbl [6 × 5]&gt; &lt;df [100 × 4]&gt; &lt;named list&gt;\n13 m7.4           4 &lt;formula&gt;     6 &lt;dbl [6 × 5]&gt; &lt;df [100 × 4]&gt; &lt;named list&gt;\n14 m7.4           4 &lt;formula&gt;     7 &lt;dbl [6 × 5]&gt; &lt;df [100 × 4]&gt; &lt;named list&gt;\n\n\nNow fit the models with sampling() within map().\n\nd_fits_subset &lt;- d_fits_subset |&gt; \n  mutate(sampling = map(.x = stan_data, \n                        .f =~ sampling(\n                          object = stan_dso, \n                          data = .x,\n                          seed = 7)))\n\nExtract the as_draws_df() output from each model.\n\nd_fits_subset &lt;- d_fits_subset |&gt; \n  mutate(as_draws_df = map(.x = sampling, .f = as_draws_df))\n\n# What?\nd_fits_subset |&gt; \n  select(model, sampling, as_draws_df)\n\n# A tibble: 14 × 3\n   model sampling          as_draws_df             \n   &lt;chr&gt; &lt;list&gt;            &lt;list&gt;                  \n 1 m7.1  &lt;stanfit[,4,110]&gt; &lt;draws_df [4,000 × 113]&gt;\n 2 m7.1  &lt;stanfit[,4,110]&gt; &lt;draws_df [4,000 × 113]&gt;\n 3 m7.1  &lt;stanfit[,4,110]&gt; &lt;draws_df [4,000 × 113]&gt;\n 4 m7.1  &lt;stanfit[,4,110]&gt; &lt;draws_df [4,000 × 113]&gt;\n 5 m7.1  &lt;stanfit[,4,110]&gt; &lt;draws_df [4,000 × 113]&gt;\n 6 m7.1  &lt;stanfit[,4,110]&gt; &lt;draws_df [4,000 × 113]&gt;\n 7 m7.1  &lt;stanfit[,4,110]&gt; &lt;draws_df [4,000 × 113]&gt;\n 8 m7.4  &lt;stanfit[,4,113]&gt; &lt;draws_df [4,000 × 116]&gt;\n 9 m7.4  &lt;stanfit[,4,113]&gt; &lt;draws_df [4,000 × 116]&gt;\n10 m7.4  &lt;stanfit[,4,113]&gt; &lt;draws_df [4,000 × 116]&gt;\n11 m7.4  &lt;stanfit[,4,113]&gt; &lt;draws_df [4,000 × 116]&gt;\n12 m7.4  &lt;stanfit[,4,113]&gt; &lt;draws_df [4,000 × 116]&gt;\n13 m7.4  &lt;stanfit[,4,113]&gt; &lt;draws_df [4,000 × 116]&gt;\n14 m7.4  &lt;stanfit[,4,113]&gt; &lt;draws_df [4,000 × 116]&gt;\n\n\nAfter all that, here’s our version of Figure 7.4.\n\nd_fits_subset |&gt; \n  select(model, row, as_draws_df) |&gt; \n  unnest(as_draws_df) |&gt; \n  pivot_longer(starts_with(\"fitted\"), names_to = \"m\") |&gt; \n  mutate(m = str_extract(m, \"\\\\d+\") |&gt; as.integer()) |&gt; \n  mutate(brain = value * max(d$brain)) |&gt; \n  left_join(d_pred |&gt; \n              mutate(m = 1:n()),\n            by = join_by(m)) |&gt; \n  mutate(mass = mass_std1 * sd(d$mass) + mean(d$mass)) |&gt; \n  \n  ggplot(aes(x = mass, y = brain)) +\n  stat_lineribbon(aes(group = row),\n                  point_interval = mean_qi, .width = 0, \n                  alpha = 3/4, color = \"lightblue4\", linewidth = 1/3) +\n  geom_point(data = d) +\n  scale_x_continuous(\"body mass (kg)\", breaks = c(35, 47, 60)) +\n  scale_y_continuous(\"brain volume (cc)\", breaks = c(0, 450, 900, 1300, 2000)) +\n  scale_fill_brewer(breaks = NULL) +\n  coord_cartesian(xlim = c(34, 61),\n                  ylim = c(0, 2000)) +\n  facet_wrap(~ model)\n\n\n\n\n\n7.1.2.1 Rethinking: Bias and variance."
  },
  {
    "objectID": "07.html#entropy-and-accuracy",
    "href": "07.html#entropy-and-accuracy",
    "title": "7  Ulysses’ Compass",
    "section": "7.2 Entropy and accuracy",
    "text": "7.2 Entropy and accuracy\n\n7.2.1 Firing the weatherperson.\n\n7.2.1.1 Costs and benefits.\n\n\n7.2.1.2 Measuring accuracy.\n\n\n7.2.1.3 Rethinking: Calibration is overrated.\n\n\n\n7.2.2 Information and uncertainty.\nThe formula for information entropy is:\n\\[H(p) = - \\text E \\log (p_i) = - \\sum_{i = 1}^n p_i \\log (p_i).\\]\nMcElreath put it in words as: “The uncertainty contained in a probability distribution is the average log-probability of an event.” (p. 206).\n\n7.2.2.1 Overthinking: More on entropy.\n\n\n7.2.2.2 Rethinking: The benefits of maximizing uncertainty.\n\n\n\n7.2.3 From entropy to accuracy.\n\n7.2.3.1 Overthinking: Cross entropy and divergence.\n\n\n7.2.3.2 Rethinking: Divergence depends upon direction.\nHere we see \\(H(p, q) \\neq H(q, p)\\). That is, direction matters.\n\n\n\n7.2.4 Estimating divergence.\nWe define deviance as\n\\[D(q) = -2 \\sum_i \\log (q_i),\\]\nwhere \\(i\\) indexes each case and \\(q_i\\) is the likelihood for each case. Here’s the deviance from the OLS version of model m7.1.\n\nlm(data = d, brain_std ~ mass_std) |&gt; \n  logLik() * -2\n\n'log Lik.' -5.985049 (df=3)\n\n\nIn our \\(D(q)\\) formula, did you notice how we ended up multiplying \\(\\sum_i \\log (p_i)\\) by \\(-2\\)? Frequentists and Bayesians alike make use of information theory, KL divergence, and deviance. It turns out that the differences between two \\(D(q)\\) values follows a \\(\\chi^2\\) distribution (Wilks, 1938), which frequentists like to reference for the purpose of null-hypothesis significance testing. Some Bayesians, however, are not into all that significance-testing stuff and they aren’t as inclined to multiply \\(\\sum_i \\log (p_i)\\) by \\(-2\\) for the simple purpose of scaling the associated difference distribution to follow the \\(\\chi^2\\). If we leave that part out of the equation, we end up with\n\\[S(q) = \\sum_i \\log (q_i),\\]\nwhich we can think of as a log-probability score which is “the gold standard way to compare the predictive accuracy of different models. It is an estimate of \\(\\text E \\log (q_i)\\), just without the final step of dividing by the number of observations” (p. 210).\nWhen Bayesians compute \\(S(q)\\), they do so over the entire posterior distribution. The rstan package does not have a convenience function for computing the log likelihood, and the log likelihood is not computed automatically for stan() models. From the loo.stanfit section of the current version (2.32.6) of the rstan reference manual (Guo et al., 2024), we read:\n\nStan does not automatically compute and store the log-likelihood. It is up to the user to incorporate it into the Stan program if it is to be extracted after fitting the model. In a Stan program, the pointwise log likelihood can be coded as a vector in the transformed parameters block (and then summed up in the model block) or it can be coded entirely in the generated quantities block. We recommend using the generated quantities block so that the computations are carried out only once per iteration rather than once per HMC leapfrog step.\nFor example, the following is the generated quantities block for computing and saving the loglikelihood for a linear regression model with N data points, outcome y, predictor matrix X (including column of 1s for intercept), coefficients beta, and standard deviation sigma:\nvector[N] log_lik; for (n in 1:N) log_lik[n] = normal_lpdf(y[n] | X[n, ] * beta, sigma);\n\nHere’s how to update the model_code for model m7.1 to include log_lik within the generated quantities block.\n\nmodel_code_7.1ll &lt;- '\ndata {\n  int&lt;lower=1&gt; n;\n  int&lt;lower=1&gt; k;\n  vector[n] brain_std;  \n  matrix[n, k] X;\n  matrix[100, k] Xpred;  // New data for fitted lines\n}\nparameters {\n  vector[k] b;\n  real log_sigma;  \n}\nmodel {\n  brain_std ~ normal(X * b, exp(log_sigma));\n  b[1] ~ normal(0.5, 1);\n  b[2] ~ normal(0, 10);\n  log_sigma ~ normal(0, 1);\n}\ngenerated quantities {\n  vector[n] log_lik;\n  for (i in 1:n) log_lik[i] = normal_lpdf(brain_std[i] | X[i, ] * b, exp(log_sigma));\n}\n'\n\nCompile and fit this version the model with stan().\n\nm7.1ll &lt;- stan(\n  data = stan_data,\n  model_code = model_code_7.1ll,\n  cores = 4, seed = 7)\n\nNotice the seven log_lik[i] rows in the print() output, one for each case in the sample data.\n\nprint(m7.1ll, probs = c(0.055, 0.945))\n\nInference for Stan model: anon_model.\n4 chains, each with iter=2000; warmup=1000; thin=1; \npost-warmup draws per chain=1000, total post-warmup draws=4000.\n\n            mean se_mean   sd  5.5% 94.5% n_eff Rhat\nb[1]        0.53    0.00 0.11  0.36  0.69  2028    1\nb[2]        0.17    0.00 0.12 -0.01  0.35  1914    1\nlog_sigma  -1.40    0.01 0.39 -1.95 -0.72  1259    1\nlog_lik[1]  0.30    0.01 0.42 -0.43  0.91  1165    1\nlog_lik[2]  0.32    0.01 0.43 -0.43  0.94  1086    1\nlog_lik[3]  0.24    0.01 0.45 -0.56  0.86  1245    1\nlog_lik[4]  0.32    0.01 0.39 -0.37  0.89  1177    1\nlog_lik[5]  0.16    0.01 0.47 -0.68  0.81  1513    1\nlog_lik[6]  0.07    0.01 0.60 -1.01  0.82  1580    1\nlog_lik[7] -0.92    0.02 0.97 -2.87  0.15  2512    1\nlp__        5.87    0.05 1.64  2.85  7.59   949    1\n\nSamples were drawn using NUTS(diag_e) at Thu Aug  1 12:53:23 2024.\nFor each parameter, n_eff is a crude measure of effective sample size,\nand Rhat is the potential scale reduction factor on split chains (at \nconvergence, Rhat=1).\n\n\nWe can convert these log_lik[i] values into log probability scores like so.\n\nm7.1ll |&gt; \n  spread_draws(log_lik[i]) |&gt; \n  mutate(prob = exp(log_lik)) |&gt; \n  group_by(i) |&gt; \n  summarise(log_probability_score = mean(prob) |&gt; log())\n\n# A tibble: 7 × 2\n      i log_probability_score\n  &lt;int&gt;                 &lt;dbl&gt;\n1     1                 0.381\n2     2                 0.407\n3     3                 0.329\n4     4                 0.394\n5     5                 0.259\n6     6                 0.216\n7     7                -0.603\n\n\n“If you sum these values, you’ll have the total log-probability score for the model and data” (p. 210). Here we sum those \\(\\log (q_i)\\) values up to compute \\(S(q)\\).\n\nm7.1ll |&gt; \n  spread_draws(log_lik[i]) |&gt; \n  mutate(prob = exp(log_lik)) |&gt; \n  group_by(i) |&gt; \n  summarise(log_probability_score = mean(prob) |&gt; log()) |&gt; \n  # This is the only new step from the last code block\n  summarise(total_log_probability_score = sum(log_probability_score))\n\n# A tibble: 1 × 1\n  total_log_probability_score\n                        &lt;dbl&gt;\n1                        1.38\n\n\n\n7.2.4.1 Overthinking: Computing the lppd.\nThe Bayesian version of the log-probability score, what we’ve been calling the lppd, has to account for the data and the posterior distribution. It follows the form\n\\[\\text{lppd}(y, \\Theta) = \\sum_i \\log \\frac{1}{S} \\sum_s p (y_i | \\Theta_s),\\]\n\nwhere \\(S\\) is the number of samples and \\(\\Theta_s\\) is the \\(s\\)-th set of sampled parameter values in the posterior distribution. While in principle this is easy–you just need to compute the probability (density) of each observation \\(i\\) for each sample \\(s\\), take the average, and then the logarithm–in practice it is not so easy. The reason is that doing arithmetic in a computer often requires some tricks to retain precision. (p. 210)\n\nThough we computed these values above with the log_lik[i] values defined in the generated quantities block of the model_code, we can also do it by hand with the posterior distribution and the sample data. When we pull the posterior draws with as_draws_df(), the HMC draws, what McElreath called \\(s\\), are indexed in the .draw column. To play along, we’ll rename that .draw column s. The term \\(p (y_i | \\Theta_s)\\) is the probability of the brain_std values for each of the rows of the data, which we’ve indexed by the i column, given the samples from the posterior distribution \\(\\Theta_s\\). Those \\(\\Theta_s\\) values are our b[1], b[2] and log_sigma columns, seen through the lens of the Gaussian likelihood. Thus we compute \\(p (y_i | \\Theta_s)\\) within the dnorm() function, which we save as density[i][s].\n\nlog_prob_df &lt;- as_draws_df(m7.1ll) |&gt; \n  # Index the samples using McElreath's notation\n  mutate(s = .draw) |&gt; \n  # Add the sample data\n  expand_grid(d |&gt; \n                mutate(i = 1:n()) |&gt; \n                select(i, species:brain_std)) |&gt; \n  # Not needed, but simplifies the output\n  select(s, i, species, brain_std, mass_std, `b[1]`, `b[2]`, log_sigma) |&gt; \n  # Define p(y[i] | Theta[s])\n  mutate(`density[i][s]` = dnorm(x = brain_std, \n                                 mean = `b[1]` + `b[2]` * mass_std,\n                                 sd = exp(log_sigma)))\n\n# What?\nglimpse(log_prob_df)\n\nRows: 28,000\nColumns: 9\n$ s               &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, …\n$ i               &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, …\n$ species         &lt;chr&gt; \"afarensis\", \"africanus\", \"habilis\", \"boisei\", \"rudolf…\n$ brain_std       &lt;dbl&gt; 0.3244444, 0.3348148, 0.4533333, 0.3859259, 0.5570370,…\n$ mass_std        &lt;dbl&gt; -0.7794667, -0.9170196, -1.0087216, -0.3668079, 0.9170…\n$ `b[1]`          &lt;dbl&gt; 0.5111734, 0.5111734, 0.5111734, 0.5111734, 0.5111734,…\n$ `b[2]`          &lt;dbl&gt; 0.6746181, 0.6746181, 0.6746181, 0.6746181, 0.6746181,…\n$ log_sigma       &lt;dbl&gt; -0.4891425, -0.4891425, -0.4891425, -0.4891425, -0.489…\n$ `density[i][s]` &lt;dbl&gt; 0.5583681, 0.5016021, 0.3885140, 0.6378460, 0.4205836,…\n\n\nBy \\(\\frac{1}{S} \\sum_s p (y_i | \\Theta_s)\\), we are computing the average density value separately for each row in the sample data, i.\n\nlog_prob_df |&gt; \n  group_by(i) |&gt; \n  summarise(`mean_density[i]` = mean(`density[i][s]`))\n\n# A tibble: 7 × 2\n      i `mean_density[i]`\n  &lt;int&gt;             &lt;dbl&gt;\n1     1             1.46 \n2     2             1.50 \n3     3             1.39 \n4     4             1.48 \n5     5             1.30 \n6     6             1.24 \n7     7             0.547\n\n\nThen by the rightmost terms in the equation, \\(\\sum_i \\log \\cdot\\), we take the log of those values and sum them up.\n\nlog_prob_df |&gt; \n  group_by(i) |&gt; \n  summarise(`mean_density[i]` = mean(`density[i][s]`)) |&gt; \n  summarise(total_log_probability_score = log(`mean_density[i]`) |&gt; sum())\n\n# A tibble: 1 × 1\n  total_log_probability_score\n                        &lt;dbl&gt;\n1                        1.38\n\n\nThat is the log-pointwise-predictive-density, \\(\\text{lppd}(y, \\Theta)\\), computed by hand.\n\n\n\n7.2.5 Scoring the right data.\nSince our stan() models from above do not have log-likelihood values saved from each, we have to options to make an alternative to McElreath’s R code 7.15:\n\nwe can compute each by hand, like in the last section, but with a custom-defined linear function within dnorm(), or\nwe can refit the models after adding log_lik[i] definitions in the generated quantities block of the model program.\n\nI’m opting for the latter. To that end, define the model_code_7.1to6ll object with a generated quantities block.\n\nmodel_code_7.1to6ll &lt;- '\ndata {\n  int&lt;lower=1&gt; n;\n  int&lt;lower=1&gt; k;\n  vector[n] brain_std;  \n  matrix[n, k] X;\n  matrix[100, k] Xpred;\n}\nparameters {\n  vector[k] b;\n  real log_sigma;\n}\nmodel {\n  brain_std ~ normal(X * b, exp(log_sigma));\n  \n  b[1] ~ normal(0.5, 1);\n  b[2:k] ~ normal(0, 10);\n  log_sigma ~ normal(0, 1);\n}\ngenerated quantities {\n  // Define and compute the log likelihood\n  vector[n] log_lik;\n  for (i in 1:n) log_lik[i] = normal_lpdf(brain_std[i] | X[i, ] * b, exp(log_sigma));\n}\n'\n\nCompile and save the stan_dso_ll.\n\nstan_dso_ll &lt;- stan_model(model_code = model_code_7.1to6ll)\n\nNow draw from the posterior distributions of all 6 models by using the sampling() function within map(), and then extract the log_lik estimates from each model with spread_draws() within map().\n\nd_fits_ll &lt;- d_fits |&gt; \n  # Subset the data frame\n  select(model, stan_data) |&gt; \n  # Sample from each model\n  mutate(sampling = map(.x = stan_data, \n                        .f =~ sampling(\n                          object = stan_dso_ll, \n                          data = .x,\n                          seed = 7))) |&gt; \n  # Extract the posterior draws for the `log_lik` estimates \n  mutate(spread_draws = map(.x = sampling, \n                            .f =~ spread_draws(\n                              model = .x,\n                              log_lik[i])))\n\nCompute the total_log_probability_score for each model.\n\nd_fits_ll |&gt; \n  select(model, spread_draws) |&gt; \n  unnest(spread_draws) |&gt; \n  rename(s = .draw) |&gt; \n  mutate(`density[i][s]` = exp(log_lik)) |&gt; \n  group_by(model, i) |&gt; \n  summarise(`mean_density[i]` = mean(`density[i][s]`)) |&gt; \n  group_by(model) |&gt; \n  summarise(total_log_probability_score = log(`mean_density[i]`) |&gt; sum())\n\n`summarise()` has grouped output by 'model'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 6 × 2\n  model total_log_probability_score\n  &lt;chr&gt;                       &lt;dbl&gt;\n1 m7.1                       1.38  \n2 m7.2                       0.712 \n3 m7.3                       0.640 \n4 m7.4                       0.273 \n5 m7.5                       0.0968\n6 m7.6                      -2.16  \n\n\n\n7.2.5.1 Overthinking: Simulated training and testing.\nI’m leaving this out, for now. If you want a sense of how to do this, check out this section in my brms translation (here)."
  },
  {
    "objectID": "07.html#golem-taming-regularization",
    "href": "07.html#golem-taming-regularization",
    "title": "7  Ulysses’ Compass",
    "section": "7.3 Golem taming: regularization",
    "text": "7.3 Golem taming: regularization\nI’ll leave the simulation for Figure 7.8 for another day. If you want a sense of how to do this, check out this section in my brms translation (here).\n\n7.3.0.1 Rethinking: Ridge regression."
  },
  {
    "objectID": "07.html#predicting-predictive-accuracy",
    "href": "07.html#predicting-predictive-accuracy",
    "title": "7  Ulysses’ Compass",
    "section": "7.4 Predicting predictive accuracy",
    "text": "7.4 Predicting predictive accuracy\n\n7.4.1 Cross-validation.\n\n7.4.1.1 Overthinking: Pareto-smoothed cross-validation.\n\n\n\n7.4.2 Information criteria.\nWe define the widely applicable information criterion (WAIC) as\n\\[\\text{WAIC}(y, \\Theta) = -2 \\big ( \\text{lppd} - {\\color{blue}{\\sum_i \\operatorname{var}_\\theta \\log p (y_i \\mid \\theta)}} \\big),\\]\nwhere \\(y\\) is the criterion, \\(\\Theta\\) is the posterior distribution, and the terms in the blue font make up the complexity penalty.\n\n7.4.2.1 Overthinking: The Akaike inspiration criterion.\n\n\n7.4.2.2 Rethinking: Information criteria and consistency.\n\n\n7.4.2.3 Rethinking: What about BIC and Bayes factors?\n\n\n7.4.2.4 Overthinking: WAIC calculations.\nHere is how to fit the pre-WAIC model with brms.\nDefine the stan_data version of the cars data set.\n\nstan_data &lt;- cars |&gt; \n  compose_data()\n\n# What?\nstr(stan_data)\n\nList of 3\n $ speed: num [1:50(1d)] 4 4 7 7 8 9 10 10 10 11 ...\n $ dist : num [1:50(1d)] 2 10 4 22 16 10 18 26 34 17 ...\n $ n    : int 50\n\n\nDefine model_code_7.7.\n\nmodel_code_7.7 &lt;- '\ndata {\n  int&lt;lower=1&gt; n;\n  vector[n] speed;\n  vector[n] dist;\n}\nparameters {\n  real b0;\n  real b1;\n  real&lt;lower=0&gt; sigma;  \n}\nmodel {\n  dist ~ normal(b0 + b1 * speed, sigma);\n  b0 ~ normal(0, 100);\n  b1 ~ normal(0, 10);\n  sigma ~ exponential(1);\n}\ngenerated quantities {\n  // Define and compute the log likelihood\n  vector[n] log_lik;\n  for (i in 1:n) log_lik[i] = normal_lpdf(dist[i] | b0 + b1 * speed[i], sigma);\n}\n'\n\nFit m7.7 with stan().\n\nm7.7 &lt;- stan(\n  data = stan_data,\n  model_code = model_code_7.7,\n  cores = 4, seed = 7)\n\nCheck the model summary.\n\nprint(m7.7, pars = c(\"b0\", \"b1\", \"sigma\"), probs = c(0.055, 0.945))\n\nInference for Stan model: anon_model.\n4 chains, each with iter=2000; warmup=1000; thin=1; \npost-warmup draws per chain=1000, total post-warmup draws=4000.\n\n        mean se_mean   sd   5.5% 94.5% n_eff Rhat\nb0    -17.50    0.17 6.09 -27.29 -7.73  1324    1\nb1      3.93    0.01 0.37   3.33  4.53  1316    1\nsigma  13.82    0.03 1.22  12.03 15.89  1842    1\n\nSamples were drawn using NUTS(diag_e) at Fri Aug  2 13:06:15 2024.\nFor each parameter, n_eff is a crude measure of effective sample size,\nand Rhat is the potential scale reduction factor on split chains (at \nconvergence, Rhat=1).\n\n\nFor the sake of practice, here’s the fitted line plotted against the data.\n\n# range(cars$speed)  # 4 25\n\nas_draws_df(m7.7) |&gt; \n  expand_grid(speed = 4:25) |&gt; \n  mutate(dist = b0 + b1 * speed) |&gt; \n  \n  ggplot(aes(x = speed, y = dist)) +\n  stat_lineribbon(.width = 0.89, fill = \"gray67\", linewidth = 1/2) +\n  geom_point(data = cars,\n             alpha = 3/4, color = \"blue\")\n\n\n\n\nAs the log likelihood and the WAIC, because of our generated quantities block, our m7.7 object has a vector of log_lik values for each case in the data. We’ll make explicit use of those in a moment. But since this is such a simple model, we’ll first practice by hand. Here we extract the posterior draws just for the model parameters b0, b1 and sigma from m7.7, use expand_grid() to add in the cars data, compute the log_lik values with dnorm(log = TRUE), exponentiate those values back to the likelihood metric with exp(), and save the results as a data frame called d_log_lik.\n\nd_log_lik &lt;- m7.7 |&gt; \n  spread_draws(b0, b1, sigma) |&gt; \n  expand_grid(cars |&gt; \n                mutate(i = 1:n()) |&gt; \n                select(i, everything())) |&gt; \n  # In R code 7.20, McElreath called this `logprob`\n  mutate(log_lik = dnorm(x = dist, \n                         mean =  b0 + b1 * speed, \n                         sd = sigma, \n                         log = TRUE)) |&gt; \n  mutate(lik = exp(log_lik))\n\n# What?\nglimpse(d_log_lik)\n\nRows: 200,000\nColumns: 11\n$ .chain     &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n$ .iteration &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n$ .draw      &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n$ b0         &lt;dbl&gt; -11.39182, -11.39182, -11.39182, -11.39182, -11.39182, -11.…\n$ b1         &lt;dbl&gt; 3.672345, 3.672345, 3.672345, 3.672345, 3.672345, 3.672345,…\n$ sigma      &lt;dbl&gt; 14.86227, 14.86227, 14.86227, 14.86227, 14.86227, 14.86227,…\n$ i          &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, …\n$ speed      &lt;dbl&gt; 4, 4, 7, 7, 8, 9, 10, 10, 10, 11, 11, 12, 12, 12, 12, 13, 1…\n$ dist       &lt;dbl&gt; 2, 10, 4, 22, 16, 10, 18, 26, 34, 17, 28, 14, 20, 24, 28, 2…\n$ log_lik    &lt;dbl&gt; -3.621575, -3.719451, -3.858590, -3.751465, -3.626701, -3.9…\n$ lik        &lt;dbl&gt; 0.0267405229, 0.0242472711, 0.0210977186, 0.0234833221, 0.0…\n\n\nRecall the formula for the \\(\\text{lppd}\\) was\n\\[\\text{lppd}(y, \\Theta) = \\sum_i \\log \\frac{1}{S} \\sum_s p (y_i | \\Theta_s),\\]\nwhere \\(p (y_i | \\Theta_s)\\) is the likelihood of case \\(i\\) on posterior draw \\(s\\). For each case \\(i\\) (i.e., \\(\\sum_i\\)), we then take the average likelihood value [i.e., \\(\\frac{1}{S} \\sum_s p (y_i | \\Theta_s)\\)] and transform the result by taking its log [i.e., \\(\\log \\left (\\frac{1}{S} \\sum_s p (y_i | \\Theta_s) \\right )\\)]. When we sum those values up, we have the \\(\\text{lppd}\\), which we’ll save as a scalar named lppd.\n\nlppd &lt;- d_log_lik |&gt; \n  group_by(i) |&gt; \n  summarise(log_mean_likelihood = mean(lik) |&gt; log()) |&gt;  \n  summarise(lppd = sum(log_mean_likelihood)) |&gt; \n  pull(lppd)\n\n# What?\nprint(lppd)\n\n[1] -206.6241\n\n\nIt’s a little easier to compute the effective number of parameters, \\(p_\\text{WAIC}\\). First, let’s use a shorthand notation and define \\(V(y_i)\\) as the variance in log-likelihood for the \\(i^\\text{th}\\) case across all \\(S\\) samples. We define \\(p_\\text{WAIC}\\) as their sum\n\\[p_\\text{WAIC} = \\sum_{i=1}^N V (y_i).\\]\nWe’ll name the pointwise results [i.e., \\(V (y_i)\\)] as var_log_lik, and we’ll save their sum [i.e., \\(\\sum_{i=1}^N V (y_i)\\)] as a scalar named pwaic.\n\npwaic &lt;- d_log_lik |&gt; \n  group_by(i) |&gt; \n  summarise(var_log_lik = var(log_lik)) |&gt; \n  summarise(pwaic = sum(var_log_lik)) |&gt; \n  pull(pwaic)\n\n# What?\nprint(pwaic)\n\n[1] 4.086416\n\n\nNow we can finally plug our hand-made lppd and pwaic values into the formula \\(-2 (\\text{lppd} - p_\\text{WAIC})\\) to compute the WAIC.\n\n# WAIC\n-2 * (lppd - pwaic)\n\n[1] 421.4209\n\n\nWe’re finally ready to use those log_lik vectors from our generated quantities block. The loo package has a extract_log_lik() function that expects a vector named log_lik. This will convert them to a matrix with as many rows as posterior draws, and as many columns as cases in the sample data. In our case, That will make for a \\(4{,}000 \\times 50\\) matrix.\n\nextract_log_lik(m7.7) |&gt; \n  str()\n\n num [1:4000, 1:50] -3.62 -3.49 -3.66 -3.83 -3.65 ...\n\n\nWe can then pump this log-likelihood matrix directly into the loo::waic() function, the results of which we’ll save as w7.7.\n\nw7.7 &lt;- extract_log_lik(m7.7) |&gt; \n  waic()\n\nWe can get a nice summary with print().\n\nprint(w7.7)\n\n\nComputed from 4000 by 50 log-likelihood matrix.\n\n          Estimate   SE\nelpd_waic   -210.7  8.2\np_waic         4.1  1.6\nwaic         421.4 16.4\n\n2 (4.0%) p_waic estimates greater than 0.4. We recommend trying loo instead. \n\n\nLo and behold, the value in the Estimate column of the waic row matches the waic scalar we hand-computed just a few code blocks above.\nBefore we move on, did you notice the elpd_waic row? That value is the lppd minus the pwaic, but without multiplying the result by -2. Here’s how that matches up with our hand-computed scalars.\n\n(lppd - pwaic)\n\n[1] -210.7105\n\n\nRecalling some of the intermediary steps from above, here’s how we might compute the WAIC standard error by hand.\n\nn_cases &lt;- nrow(cars)  # 50\n\nd_log_lik |&gt; \n  group_by(i) |&gt; \n  summarise(log_mean_likelihood = mean(lik) |&gt; log(),\n            var_log_lik = var(log_lik)) |&gt; \n  # Compute the pointwise waic values\n  mutate(pointwise_waic = -2 * (log_mean_likelihood - var_log_lik)) |&gt; \n  summarise(waic_se = sqrt(n_cases * var(pointwise_waic)))\n\n# A tibble: 1 × 1\n  waic_se\n    &lt;dbl&gt;\n1    16.4\n\n\nIf you’d like the pointwise WAIC values from waic() output, just index.\n\nw7.7$pointwise |&gt; \n  head()\n\n     elpd_waic     p_waic     waic\n[1,] -3.648848 0.02209327 7.297696\n[2,] -4.022936 0.09582308 8.045871\n[3,] -3.684862 0.02091625 7.369725\n[4,] -3.994271 0.06003729 7.988543\n[5,] -3.587983 0.01035827 7.175966\n[6,] -3.742794 0.02106961 7.485588\n\n\n\n\n\n7.4.3 Comparing CV, PSIS, and WAIC.\nI’ll leave the simulation for Figure 7.9 for another day.\nHowever, when it comes to the LOO-CV for stan() models, we can use the convenience function loo::loo() in much the same we used the waic(). Here’s what that looks like for m7.7.\n\nextract_log_lik(m7.7) |&gt; \n  loo()\n\n\nComputed from 4000 by 50 log-likelihood matrix.\n\n         Estimate   SE\nelpd_loo   -210.8  8.3\np_loo         4.2  1.6\nlooic       421.6 16.5\n------\nMCSE of elpd_loo is 0.1.\nMCSE and ESS estimates assume independent draws (r_eff=1).\n\nAll Pareto k estimates are good (k &lt; 0.7).\nSee help('pareto-k-diagnostic') for details.\n\n\nAs long as you compute the log_lik values in the generated quantities block for input to stan(), the workflow is smooth. However, if you’re ever in a situation where you haven’t done that, you can do this all by hand. For example, this is how you can get the loo() summary for hand-computed log_lik values.\n\nm7.7 |&gt; \n  spread_draws(b0, b1, sigma) |&gt; \n  expand_grid(cars |&gt; \n                mutate(i = 1:n()) |&gt; \n                select(i, everything())) |&gt; \n  mutate(log_lik = dnorm(x = dist, \n                         mean =  b0 + b1 * speed, \n                         sd = sigma, \n                         log = TRUE)) |&gt; \n  # Everything up to this point is a repeat from earlier\n  select(.draw, i, log_lik) |&gt; \n  pivot_wider(names_from = i, values_from = log_lik) |&gt; \n  select(-.draw) |&gt; \n  as.matrix() |&gt; \n  loo()\n\n\nComputed from 4000 by 50 log-likelihood matrix.\n\n         Estimate   SE\nelpd_loo   -210.8  8.3\np_loo         4.2  1.6\nlooic       421.6 16.5\n------\nMCSE of elpd_loo is 0.1.\nMCSE and ESS estimates assume independent draws (r_eff=1).\n\nAll Pareto k estimates are good (k &lt; 0.7).\nSee help('pareto-k-diagnostic') for details.\n\n\nHopefully you’ll never have to do that, though.\n\n7.4.3.1 Rethinking: Diverse prediction frameworks."
  },
  {
    "objectID": "07.html#model-comparison",
    "href": "07.html#model-comparison",
    "title": "7  Ulysses’ Compass",
    "section": "7.5 Model comparison",
    "text": "7.5 Model comparison\n\n7.5.1 Model mis-selection.\nOnce again we return to the plant-growth models from back in Section 6.2. These were named m6.6, m6.7, and m6.8. If you were following along closely in that part of the ebook, you may have noticed we defined the log_lik values in the generated quantities block for each, but put off their discussion until now. It’s time for the payoff. Here we’ll use our extract_log_lik |&gt; waic() workflow to compute the WAIC summaries for each, and save them as objects named w6.6 through w6.8.\n\nw6.6 &lt;- m6.6 |&gt; \n  extract_log_lik() |&gt; \n  waic()\n\nw6.7 &lt;- m6.7 |&gt; \n  extract_log_lik() |&gt; \n  waic()\n\nw6.8 &lt;- m6.8 |&gt; \n  extract_log_lik() |&gt; \n  waic()\n\nLike in the text (p. 226), here’s the waic() output for m6.7.\n\nprint(w6.7)\n\n\nComputed from 4000 by 100 log-likelihood matrix.\n\n          Estimate   SE\nelpd_waic   -180.6  6.7\np_waic         3.4  0.5\nwaic         361.3 13.4\n\n\nFor our rstan + loo based workflow, we can compare multiple models by their WAIC with the loo_compare() function. The name of the function implies you should be using the LOO-CV, rather than the WAIC. Given the preferences of the package’s authors, that’s no surprise (e.g., see the opening paragraph here). But yes, you can also use loo_compare() function to compare models by their WAIC estimates. Here we save the output as an object called w_difference, and then display a summary of the results.\n\nw_difference &lt;- loo_compare(w6.6, w6.7, w6.8)\n\nw_difference |&gt; \n  print(simplify = FALSE)\n\n       elpd_diff se_diff elpd_waic se_elpd_waic p_waic se_p_waic waic   se_waic\nmodel2    0.0       0.0  -180.6       6.7          3.4    0.5     361.3   13.4 \nmodel3  -20.6       4.9  -201.2       5.4          2.5    0.3     402.5   10.7 \nmodel1  -22.4       5.8  -203.1       5.7          1.6    0.2     406.1   11.4 \n\n\nThough the format is a little different, out output largely matches what McElreath displayed on page 227 of the text. With respect to our loo_compare() output, notice the elpd_diff column and the adjacent se_diff column. Those are our WAIC differences in the elpd metric. The models have been rank ordered from the highest (i.e., m6.7, called model2) to the lowest (i.e., m6.6, called model1). The scores listed are the differences of m6.7 minus the comparison model. Since m6.7 is the comparison model in the top row, the values are naturally 0 (i.e., \\(x - x = 0\\)). But now here’s another critical thing to understand: WAIC and LOO differences are no longer reported in the \\(-2 \\times x\\) metric. Remember how multiplying (lppd - pwaic) by -2 is a historic artifact associated with the frequentist \\(\\chi^2\\) test? We’ll, the makers of the loo package aren’t fans, and they no longer support the conversion.\nSo here’s the deal: The substantive interpretations of the differences presented in an elpd_diff metric will be the same as if presented in a WAIC metric. But if we want to compare our elpd_diff results to those in the text, we will have to multiply them by -2. And also, if we want the associated standard error in the same metric, we’ll need to multiply the se_diff column by 2. You wouldn’t multiply by -2 because that would return a negative standard error, which would be silly. Here’s a quick way to do those conversions.\n\ncbind(waic_diff = w_difference[, 1] * -2,\n      se        = w_difference[, 2] * 2)\n\n       waic_diff        se\nmodel2   0.00000  0.000000\nmodel3  41.21758  9.787452\nmodel1  44.83923 11.568710\n\n\nNow those match up reasonably well with the values in McElreath’s dWAIC and dSE columns.\nAnyway, here’s how to compute the standard error for the WAIC difference for m6.7 and m6.8, by hand, like McElreath did in the top of page 228.\n\ntibble(m6.7 = w6.7$pointwise[, \"waic\"],\n       m6.8 = w6.8$pointwise[, \"waic\"]) |&gt; \n  mutate(diff_m6.7_m6.8 = m6.7 - m6.8) |&gt; \n  summarise(se = sqrt(n() * var(diff_m6.7_m6.8)))\n\n# A tibble: 1 × 1\n     se\n  &lt;dbl&gt;\n1  9.79\n\n\nFor us, the 99% interval for the difference distribution would be about so.\n\n41.2 + c(-1, 1) * 9.8 * 2.6\n\n[1] 15.72 66.68\n\n\nHere’s our version of a WAIC coefficient plot.\n\nbind_rows(w6.6$estimates[\"waic\", ],\n          w6.7$estimates[\"waic\", ],\n          w6.8$estimates[\"waic\", ]) |&gt; \n  mutate(model = str_c(\"m6.\", 6:8) |&gt; \n           fct_reorder(Estimate, .desc = TRUE),\n         lower = Estimate - SE,\n         upper = Estimate + SE) |&gt; \n  \n  ggplot(aes(x = Estimate, xmin = lower, xmax = upper, y = model)) +\n  geom_pointrange(shape = 1) +\n  labs(x = \"WAIC\",\n       y = NULL)\n\n\n\n\nWe don’t get the deviance points with this method, but that’s okay. Our primary focus is on the WAIC and its standard errors. IMO, the deviance points are mainly of pedagogical interest.\nAs far as WAIC weights go, I’m not aware there is a quick and convenient way to compute WAIC weights for an rstan model. But if we look to the vignette here, we can compute them by hand.\n\nw_difference |&gt; \n  data.frame() |&gt; \n  mutate(weight = exp(elpd_waic) / sum(exp(elpd_waic))) |&gt; \n  select(waic, weight) |&gt; \n  # Just to make the output nicer\n  mutate_all(round, digits = 2)\n\n         waic weight\nmodel2 361.28      1\nmodel3 402.50      0\nmodel1 406.12      0\n\n\nBefore we move on, I should point out you can do all of this for the loo(), as well. For example, here’s a quick way to get the loo_compare() summary for the LOO estimates from our three models.\n\nloo_compare(\n  extract_log_lik(m6.6) |&gt; loo(),\n  extract_log_lik(m6.7) |&gt; loo(),\n  extract_log_lik(m6.8) |&gt; loo()\n) |&gt; \n  print(simplify = FALSE)\n\n       elpd_diff se_diff elpd_loo se_elpd_loo p_loo  se_p_loo looic  se_looic\nmodel2    0.0       0.0  -180.7      6.7         3.4    0.5    361.3   13.4  \nmodel3  -20.6       4.9  -201.3      5.4         2.5    0.3    402.5   10.7  \nmodel1  -22.4       5.8  -203.1      5.7         1.7    0.2    406.1   11.4  \n\n\nSpeaking of the LOO, the loo package, does support other kinds of model weights. With the loo_model_weights() function, we can compute stacking weights, or pseudo-Bayesian model averaging (BMA) weights. The loo_model_weights() function takes input in the form of a list of psis_loo objects (i.e., loo() output). Here’s what that can look like for both stackind and pseudo-BMA weights.\n\n# stacking\nloo_model_weights(\n  list(extract_log_lik(m6.6) |&gt; loo(),\n       extract_log_lik(m6.7) |&gt; loo(),\n       extract_log_lik(m6.8) |&gt; loo()),\n  method = \"stacking\"\n)\n\nMethod: stacking\n------\n       weight\nmodel1 0.000 \nmodel2 1.000 \nmodel3 0.000 \n\n# pseudobma\nset.seed(7)\n\nloo_model_weights(\n  list(extract_log_lik(m6.6) |&gt; loo(),\n       extract_log_lik(m6.7) |&gt; loo(),\n       extract_log_lik(m6.8) |&gt; loo()),\n  method = \"pseudobma\"\n)\n\nMethod: pseudo-BMA+ with Bayesian bootstrap\n------\n       weight\nmodel1 0.000 \nmodel2 1.000 \nmodel3 0.000 \n\n\nFor more on these types of weighting methods, see Yao et al. (2018).\n\n7.5.1.1 Rethinking: WAIC metaphors.\n\n\n\n7.5.2 Outliers and other illusions.\nTime to bring back the WaffleDivorce data, and reconsider the models from back in Section 5.1.\n\ndata(WaffleDivorce, package = \"rethinking\")\n\nd &lt;- WaffleDivorce |&gt; \n  mutate(d = rethinking::standardize(Divorce),\n         m = rethinking::standardize(Marriage),\n         a = rethinking::standardize(MedianAgeMarriage))\n\nrm(WaffleDivorce)\n\nFor each of the models m5.1 through m5.3, we computed the log_lik using the generated quantities block method. Here we compute and save their loo() output as objects named l5.1 through l5.3.\n\nl5.1 &lt;- m5.1 |&gt; \n  extract_log_lik() |&gt; \n  loo()\n\nl5.2 &lt;- m5.2 |&gt; \n  extract_log_lik() |&gt; \n  loo()\n\nl5.3 &lt;- m5.3 |&gt; \n  extract_log_lik() |&gt; \n  loo()\n\nNow compare the models by the PSIS-LOO-CV.\n\nloo_compare(l5.1, l5.2, l5.3) |&gt; \n  print(simplify = FALSE)\n\n       elpd_diff se_diff elpd_loo se_elpd_loo p_loo se_p_loo looic se_looic\nmodel1   0.0       0.0   -62.9      6.4         3.7   1.8    125.8  12.8   \nmodel3  -1.0       0.3   -63.9      6.4         4.8   1.9    127.8  12.9   \nmodel2  -6.8       4.6   -69.7      5.0         3.0   1.0    139.4  10.0   \n\n\nLike in the text, our m5.1 has the best LOO estimate, but only by a little bit when compared to m5.3. Unlike McElreath reported in the text, we did not get a warning message from loo_compare(). Let’s investigate more carefully with the loo() function.\n\nloo(m5.3)\n\n\nComputed from 4000 by 50 log-likelihood matrix.\n\n         Estimate   SE\nelpd_loo    -63.9  6.4\np_loo         4.8  1.9\nlooic       127.8 12.9\n------\nMCSE of elpd_loo is 0.1.\nMCSE and ESS estimates assume MCMC draws (r_eff in [0.6, 1.3]).\n\nAll Pareto k estimates are good (k &lt; 0.7).\nSee help('pareto-k-diagnostic') for details.\n\n\nThe critical line in that output was All Pareto k estimates are good (k &lt; 0.7). The loo package bins the Pareto-\\(k\\) values into ranges labeled ok, good, bad, and very bad, and you will get warnings if anything starts to look bad or worse.\nTo dig deeper, we can use the pareto_k_ids() function to identify which observation[s] might have crossed out of the (good) range into the (ok) range.\n\nloo(m5.3) |&gt; \n  pareto_k_ids(threshold = 0.5)\n\n[1] 13\n\n\nThe number 13 refers to the corresponding row in the data used to fit the model. We can access that row directly with the dplyr::slice() function.\n\nd |&gt; \n  slice(13) |&gt; \n  select(Location:Loc)\n\n  Location Loc\n1    Idaho  ID\n\n\nHere we subset the 13th cell in the loo::pareto_k_values() output to see what that \\(k\\) value was.\n\npareto_k_values(l5.3)[13]\n\n[1] 0.6680358\n\n\nAlternatively, we could have extracted that value from our l5.3 object with indexing like so.\n\nl5.3$diagnostics$pareto_k[13]\n\n[1] 0.6680358\n\n\nA \\(k\\) value of 0.67 is a little high, but not high enough to cause loo() to return a warning message. Once a Pareto \\(k\\) value crosses the 0.7 threshold, though, the loo package will bark. Before we make our version of Figure 7.10, we’ll want to compute the WAIC for m5.3, which will give us access to the \\(p_\\text{WAIC}\\).\n\nw5.3 &lt;- m5.3 |&gt; \n  extract_log_lik() |&gt; \n  waic()\n\nWe’re ready to make our version of Figure 7.10.\n\nd_k &lt;- tibble(\n  pareto_k = l5.3$diagnostics$pareto_k,\n  p_waic   = w5.3$pointwise[, \"p_waic\"],\n  Loc      = pull(d, Loc)) \n\nd_k |&gt; \n  ggplot(aes(x = pareto_k, y = p_waic, color = Loc == \"ID\")) +\n  geom_vline(xintercept = c(0.5, 0.7), \n             alpha = 1/2, color = \"black\", linetype = 2) +\n  geom_point(aes(shape = Loc == \"ID\")) +\n  geom_text(data = d_k |&gt; \n              filter(p_waic &gt; 0.5),\n            aes(label = Loc),\n            hjust = 1, nudge_x = -0.03) +\n  scale_x_continuous(expression(PSIS~Pareto~italic(k)), breaks = c(0, 0.5, 0.7)) +\n  scale_color_manual(values = c(\"black\", \"red\")) +\n  scale_shape_manual(values = c(1, 19)) +\n  labs(y = expression(italic(p)[WAIC]),\n       subtitle = \"Gaussian model (m5.3)\") +\n  theme(legend.position = \"none\")\n\n\n\n\nFor both the Pareto \\(k\\) and the \\(p_\\text{WAIC}\\), our values are not as extreme as those McElreath reported in the text. I’m not sure if this is a consequence of us using HMC or due to recent algorithmic changes for the Stan/loo teams. But at least the overall pattern is the same. Idaho is the most extreme/influential case.\nIn the text (p. 232), McElreath reported the effective number of parameters for b5.3 was nearly 6. We can look at this with the waic() output.\n\nprint(w5.3)\n\n\nComputed from 4000 by 50 log-likelihood matrix.\n\n          Estimate   SE\nelpd_waic    -63.8  6.4\np_waic         4.7  1.9\nwaic         127.6 12.7\n\n2 (4.0%) p_waic estimates greater than 0.4. We recommend trying loo instead. \n\n\nOur \\(p_\\text{WAIC}\\) was about 4.7, which is still a little high due to Idaho but not quite as high as in the text. There is some concern that Idaho is putting us at risk of overfitting due to the large influence it has on the posterior.\nWe can fit a Student-\\(t\\) model in ratan() by using the student_t() likelihood in the model block, and we can then use the student_t_lpdf() function in the generated quantities to compute the log_lik values.\n\n# Define the `stan_data`\nstan_data &lt;- d |&gt;\n  select(d, a, m) |&gt; \n  compose_data()\n\n# Define `model_code_5.3t`\nmodel_code_5.3t &lt;- '\ndata {\n  int&lt;lower=1&gt; n;\n  vector[n] d;\n  vector[n] m;\n  vector[n] a;\n}\nparameters {\n  real b0;\n  real b1;\n  real b2;\n  real&lt;lower=0&gt; sigma;\n}\nmodel {\n  vector[n] mu;\n  mu = b0 + b1 * m + b2 * a;\n  d ~ student_t(2, mu, sigma);\n  \n  b0 ~ normal(0, 0.2);\n  b1 ~ normal(0, 0.5);\n  b2 ~ normal(0, 0.5);\n  sigma ~ exponential(1);\n}\ngenerated quantities {\n  vector[n] log_lik;\n  for (i in 1:n) log_lik[i] = student_t_lpdf(d[i] | 2, b0 + b1 * m[i] + b2 * a[i], sigma);\n}\n'\n\nFit the \\(t\\) model with stan().\n\nm5.3t &lt;- stan(\n  data = stan_data,\n  model_code = model_code_5.3t,\n  cores = 4, seed = 5)\n\nCheck the model summary.\n\nprint(m5.3t, pars = c(\"b0\", \"b1\", \"b2\", \"sigma\"), probs = c(0.05, 0.945))\n\nInference for Stan model: anon_model.\n4 chains, each with iter=2000; warmup=1000; thin=1; \npost-warmup draws per chain=1000, total post-warmup draws=4000.\n\n       mean se_mean   sd    5% 94.5% n_eff Rhat\nb0     0.02       0 0.10 -0.14  0.18  3420    1\nb1     0.05       0 0.21 -0.28  0.39  3460    1\nb2    -0.70       0 0.15 -0.94 -0.47  3356    1\nsigma  0.58       0 0.09  0.45  0.73  3681    1\n\nSamples were drawn using NUTS(diag_e) at Fri Aug  2 11:43:54 2024.\nFor each parameter, n_eff is a crude measure of effective sample size,\nand Rhat is the potential scale reduction factor on split chains (at \nconvergence, Rhat=1).\n\n\nHere’s a coefficient plot for \\(\\beta_2\\), by the two likelihoods.\n\nbind_rows(\n  as_draws_df(m5.3),\n  as_draws_df(m5.3t)\n) |&gt; \n  mutate(likelihood = rep(c(\"Gaussian\", \"Student[nu==2]\"), each = n() / 2)) |&gt; \n  \n  ggplot(aes(x = b2, y = likelihood)) +\n  stat_pointinterval(.width = 0.89, linewidth = 1/2, shape = 1) + \n  scale_y_discrete(NULL, expand = expansion(mult = 0.05), labels = ggplot2:::parse_safe)\n\n\n\n\nCompute and save the loo() and waic() output for the new \\(t\\) model.\n\nl5.3t &lt;- m5.3t |&gt; \n  extract_log_lik() |&gt; \n  loo()\n\nw5.3t &lt;- m5.3t |&gt; \n  extract_log_lik() |&gt; \n  waic()\n\nNow we might remake the plot from Figure 7.10, this time based on the \\(t\\) model.\n\nd_k &lt;- tibble(\n  pareto_k = l5.3t$diagnostics$pareto_k,\n  p_waic   = w5.3t$pointwise[, \"p_waic\"],\n  Loc      = pull(d, Loc)) \n\nd_k |&gt; \n  ggplot(aes(x = pareto_k, y = p_waic, color = Loc == \"ID\")) +\n  geom_vline(xintercept = c(0.5, 0.7), \n             alpha = 1/2, color = \"black\", linetype = 2) +\n  geom_point(aes(shape = Loc == \"ID\")) +\n  geom_text(data = d_k |&gt; \n              filter(Loc %in% c(\"ID\", \"ME\")),\n            aes(label = Loc),\n            hjust = 1, nudge_x = -0.03) +\n  scale_x_continuous(expression(PSIS~Pareto~italic(k)), breaks = c(0, 0.5, 0.7)) +\n  scale_color_manual(values = c(\"black\", \"red\")) +\n  scale_shape_manual(values = c(1, 19)) +\n  labs(y = expression(italic(p)[WAIC]),\n       subtitle = \"Student-t model (m5.3t)\") +\n  theme(legend.position = \"none\")\n\n\n\n\nThe high points in both the Pareto \\(k\\) and \\(p_\\text{WAIC}\\) are much smaller, and both ID and ME are now closer to the center of the bivariate distribution. We can formally compare the two versions of the model by the LOO with the loo_compare() function.\n\nloo_compare(l5.3, l5.3t) |&gt; print(simplify = F)\n\n       elpd_diff se_diff elpd_loo se_elpd_loo p_loo se_p_loo looic se_looic\nmodel1   0.0       0.0   -63.9      6.4         4.8   1.9    127.8  12.9   \nmodel2  -2.5       3.0   -66.4      5.8         6.2   1.0    132.9  11.5   \n\n\nThe standard error for the LOO difference was about the same size as the difference itself. This suggests the models were close and hard to distinguish with respect to their fit to the data. This will not always be the case.\n\n7.5.2.1 Rethinking: The Curse of Tippecanoe."
  },
  {
    "objectID": "07.html#summary",
    "href": "07.html#summary",
    "title": "7  Ulysses’ Compass",
    "section": "7.6 Summary",
    "text": "7.6 Summary"
  },
  {
    "objectID": "07.html#session-info",
    "href": "07.html#session-info",
    "title": "7  Ulysses’ Compass",
    "section": "Session info",
    "text": "Session info\n\nsessionInfo()\n\nR version 4.4.0 (2024-04-24)\nPlatform: aarch64-apple-darwin20\nRunning under: macOS Ventura 13.4\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: America/Chicago\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n [1] loo_2.8.0          posterior_1.6.0    patchwork_1.2.0    rstan_2.32.6      \n [5] StanHeaders_2.32.7 tidybayes_3.0.6    lubridate_1.9.3    forcats_1.0.0     \n [9] stringr_1.5.1      dplyr_1.1.4        purrr_1.0.2        readr_2.1.5       \n[13] tidyr_1.3.1        tibble_3.2.1       ggplot2_3.5.1      tidyverse_2.0.0   \n\nloaded via a namespace (and not attached):\n [1] shape_1.4.6.1        gtable_0.3.5         tensorA_0.36.2.1    \n [4] xfun_0.43            QuickJSR_1.1.3       htmlwidgets_1.6.4   \n [7] processx_3.8.4       inline_0.3.19        lattice_0.22-6      \n[10] tzdb_0.4.0           ps_1.7.6             vctrs_0.6.5         \n[13] tools_4.4.0          generics_0.1.3       stats4_4.4.0        \n[16] curl_5.2.1           parallel_4.4.0       fansi_1.0.6         \n[19] cmdstanr_0.8.1       pkgconfig_2.0.3      Matrix_1.7-0        \n[22] checkmate_2.3.1      RColorBrewer_1.1-3   distributional_0.4.0\n[25] RcppParallel_5.1.7   lifecycle_1.0.4      farver_2.1.1        \n[28] compiler_4.4.0       munsell_0.5.1        codetools_0.2-20    \n[31] htmltools_0.5.8.1    yaml_2.3.8           pillar_1.9.0        \n[34] MASS_7.3-60.2        arrayhelpers_1.1-0   rethinking_2.40     \n[37] abind_1.4-5          tidyselect_1.2.1     digest_0.6.35       \n[40] svUnit_1.0.6         mvtnorm_1.2-5        stringi_1.8.4       \n[43] labeling_0.4.3       fastmap_1.1.1        grid_4.4.0          \n[46] colorspace_2.1-0     cli_3.6.3            magrittr_2.0.3      \n[49] pkgbuild_1.4.4       utf8_1.2.4           withr_3.0.0         \n[52] scales_1.3.0         backports_1.5.0      timechange_0.3.0    \n[55] rmarkdown_2.26       matrixStats_1.3.0    gridExtra_2.3       \n[58] hms_1.1.3            coda_0.19-4.1        evaluate_0.23       \n[61] knitr_1.46           V8_4.4.2             ggdist_3.3.2        \n[64] viridisLite_0.4.2    rlang_1.1.4          Rcpp_1.0.12         \n[67] glue_1.7.0           rstudioapi_0.16.0    jsonlite_1.8.8      \n[70] R6_2.5.1"
  },
  {
    "objectID": "07.html#comments",
    "href": "07.html#comments",
    "title": "7  Ulysses’ Compass",
    "section": "Comments",
    "text": "Comments\n\n\n\n\nGuo, J., Gabry, J., Goodrich, B., Johnson, A., Weber, S., & Badr, H. S. (2024). “rstan” reference manual, Version 2.32.6. https://CRAN.R-project.org/package=rstan/rstan.pdf\n\n\nWilks, S. S. (1938). The large-sample distribution of the likelihood ratio for testing composite hypotheses. The Annals of Mathematical Statistics, 9(1), 60–62. https://doi.org/10.1214/aoms/1177732360\n\n\nYao, Y., Vehtari, A., Simpson, D., & Gelman, A. (2018). Using stacking to average Bayesian predictive distributions (with discussion). Bayesian Analysis, 13(3), 917–1007. https://doi.org/10.1214/17-BA1091"
  },
  {
    "objectID": "08.html#building-an-interaction",
    "href": "08.html#building-an-interaction",
    "title": "8  Conditional Manatees",
    "section": "8.1 Building an interaction",
    "text": "8.1 Building an interaction\nLet’s load the rugged data (Nunn & Puga, 2012).\n\ndata(rugged, package = \"rethinking\")\nd &lt;- rugged\nrm(rugged)\n\nMake the first DAG.\n\ndag_coords &lt;- tibble(\n  name = c(\"R\", \"G\", \"C\", \"U\"),\n  x    = c(1, 2, 3, 2),\n  y    = c(2, 2, 2, 1))\n\ndagify(R ~ U,\n       G ~ R + U + C,\n       coords = dag_coords) |&gt;\n  \n  ggplot(aes(x = x, y = y, xend = xend, yend = yend)) +\n  geom_dag_point(aes(color = name == \"U\"),\n                 alpha = 2/3, show.legend = FALSE, size = 6) +\n  geom_point(x = 2, y = 1, \n             shape = 1, size = 6, stroke = 3/4) +\n  geom_dag_text() +\n  geom_dag_edges() +\n  scale_color_viridis_d(option = \"A\", end = 0.6) +\n  theme_dag()\n\n\n\n\n\n8.1.0.1 Overthinking: Not so simple causation.\nHere’s the DAG for a fuller model for the data.\n\ndag_coords &lt;- tibble(\n  name = c(\"G\", \"R\", \"H\", \"C\", \"U\"),\n  x    = c(1, 1.5, 2.5, 3.5, 1),\n  y    = c(3, 2, 2, 2, 1))\n\ndagify(G ~ R + U + H,\n       R ~ U,\n       H ~ R + U + C,\n       coords = dag_coords) |&gt;\n  \n  ggplot(aes(x = x, y = y, xend = xend, yend = yend)) +\n  geom_dag_point(aes(color = name == \"U\"),\n                 alpha = 2/3, size = 6, show.legend = FALSE) +\n  geom_point(x = 1, y = 1, \n             shape = 1, size = 6, stroke = 3/4) +\n  geom_dag_text() +\n  geom_dag_edges() +\n  scale_color_viridis_d(option = \"A\", end = 0.6) +\n  theme_dag()\n\n\n\n\n\n\n8.1.1 Making a rugged model.\nWe’ll continue to use tidyverse-style syntax to wrangle the data.\n\n# Make the log version of criterion\nd &lt;- d |&gt;\n  mutate(log_gdp = log(rgdppc_2000))\n\n# Extract countries with GDP data\ndd &lt;- d |&gt;\n  filter(complete.cases(rgdppc_2000)) |&gt; \n  # Re-scale variables\n  mutate(log_gdp_std = log_gdp / mean(log_gdp), \n         rugged_std  = rugged / max(rugged)) |&gt; \n  # For plotting\n  mutate(nations = ifelse(cont_africa == 0, \"Non-African nations\", \"African nations\"))\n\nBefore we fit our first Bayesian models, let’s back track a bit and make our version of Figure 8.2. In the title, McElreath indicated it was a depiction of two linear regressions separated by whether the nations were African. A fairly simple way to make those plots is to simultaneously fit and plot the two regression models using OLS via the geom_smooth() function using the method = \"lm\" argument.\n\ncountry_vec &lt;- c(\"Lesotho\", \"Seychelles\", \"Switzerland\", \"Tajikistan\")\n\ndd |&gt; \n  ggplot(aes(x = rugged_std, y = log_gdp_std)) +\n  geom_smooth(method = \"lm\", formula = y ~ x) +\n  geom_point() +\n  geom_text(data = dd |&gt; \n              filter(country %in% country_vec),  \n            aes(label = country), \n            hjust = 0.99, size = 3, vjust = -0.6) +\n  labs(x = \"ruggedness (standardized)\",\n       y = \"log GDP (as proportion of mean)\") +\n  facet_wrap(~ nations)\n\n\n\n\nOur first Bayesian model will follow the form\n\\[\n\\begin{align*}\n\\text{log-gdp-std}_i & \\sim \\operatorname{Normal}(\\mu_i, \\sigma) \\\\\n\\mu_i  & = \\alpha + \\beta \\left (\\text{rugged-std}_i - \\overline{\\text{rugged-std}} \\right ) \\\\\n\\alpha & \\sim \\operatorname{Normal}(1, 1) \\\\\n\\beta  & \\sim \\operatorname{Normal}(0, 1) \\\\\n\\sigma & \\sim \\operatorname{Exponential}(1).\n\\end{align*}\n\\]\nHere we compute \\(\\overline{\\text{rugged-std}}\\).\n\nmean(dd$rugged_std)\n\n[1] 0.2149601\n\n\nTo start the model fitting process, define the stan_data with the compose_data() function. Note how we define the xbar value within compose_data().\n\nstan_data &lt;- dd |&gt;\n  select(log_gdp_std, rugged_std) |&gt;  \n  compose_data(xbar = mean(dd$rugged_std))\n\n# What?\nstr(stan_data)\n\nList of 4\n $ log_gdp_std: num [1:170(1d)] 0.88 0.965 1.166 1.104 0.915 ...\n $ rugged_std : num [1:170(1d)] 0.138 0.553 0.124 0.125 0.433 ...\n $ n          : int 170\n $ xbar       : num 0.215\n\n\nDefine what I’m calling model_code_8.1a. Note that for this first version, we’ll be sampling from the prior.\n\nmodel_code_8.1a &lt;- '\ndata {\n  int&lt;lower=1&gt; n;\n  real xbar;\n  vector[n] log_gdp_std;\n  vector[n] rugged_std;\n}\nparameters {\n  real a;\n  real b;\n  real&lt;lower=0&gt; sigma;\n}\nmodel {\n  // vector[n] mu;\n  // mu = a + b * (rugged_std - xbar);\n  // log_gdp_std ~ normal(mu, sigma);\n  a ~ normal(1, 1);\n  b ~ normal(0, 1);\n  sigma ~ exponential(1);\n}\n'\n\nCompile and fit the initial model with stan(). For the sake of bookkeeping, we’ll detract a little from the text and call this m8.1a. You’ll see why in a moment.\n\nm8.1a &lt;- stan(\n  data = stan_data,\n  model_code = model_code_8.1a,\n  cores = 4, seed = 8)\n\nDefine model_code_8.1b. We’re still sampling from the prior, but this time the priors are tighter.\n\nmodel_code_8.1b &lt;- '\ndata {\n  int&lt;lower=1&gt; n;\n  real xbar;\n  vector[n] log_gdp_std;\n  vector[n] rugged_std;\n}\nparameters {\n  real a;\n  real b;\n  real&lt;lower=0&gt; sigma;\n}\nmodel {\n  // vector[n] mu;\n  // mu = a + b * (rugged_std - xbar);\n  // log_gdp_std ~ normal(mu, sigma);\n  a ~ normal(1, 0.1);\n  b ~ normal(0, 0.3);\n  sigma ~ exponential(1);\n}\n'\n\nNow sample from the tighter priors, and call the object m8.1b.\n\nm8.1b &lt;- stan(\n  data = stan_data,\n  model_code = model_code_8.1b,\n  cores = 4, seed = 8)\n\nDisplay the two prior-predictive distributions with Figure 8.3.\n\nfit_labels &lt;- c(\"a ~ dnorm(1, 1)\\nb ~ dnorm(0, 1)\", \"a ~ dnorm(1, 0.1)\\nb ~ dnorm(0, 0.3)\")\n\nbind_rows(as_draws_df(m8.1a), as_draws_df(m8.1b)) |&gt; \n  mutate(fit = rep(c(\"m8.1a\", \"m8.1b\"), each = n() / 2)) |&gt; \n  group_by(fit) |&gt; \n  slice_sample(n = 50) |&gt; \n  expand_grid(rugged_std = c(-1, 2),\n              xbar = mean(dd$rugged_std)) |&gt; \n  mutate(log_gdp_std = a + b * (rugged_std - xbar),\n         fit = factor(fit, labels = fit_labels)) |&gt; \n  \n  ggplot(aes(x = rugged_std, y = log_gdp_std, group = .draw)) +\n  geom_hline(yintercept = range(dd$log_gdp_std), linetype = 2) +\n  geom_line(alpha = 0.4)  +\n  labs(x = \"ruggedness\",\n       y = \"log GDP (prop of mean)\") +\n  coord_cartesian(xlim = c(0, 1),\n                  ylim = c(0.5, 1.5)) +\n  facet_wrap(~fit)\n\n\n\n\nNow define what we’ll just call model_code_8.1, where the likelihood is now included in the model block. Note how we’re also defining the log_lik vector within the generated quantities block so we can compute information criteria for model comparisons.\n\nmodel_code_8.1 &lt;- '\ndata {\n  int&lt;lower=1&gt; n;\n  real xbar;\n  vector[n] log_gdp_std;\n  vector[n] rugged_std;\n}\nparameters {\n  real a;\n  real b;\n  real&lt;lower=0&gt; sigma;\n}\ntransformed parameters {\n  vector[n] mu;\n  mu = a + b * (rugged_std - xbar);\n}\nmodel {\n  log_gdp_std ~ normal(mu, sigma);\n  \n  a ~ normal(1, 0.1);\n  b ~ normal(0, 0.3);\n  sigma ~ exponential(1);\n}\ngenerated quantities {\n  vector[n] log_lik;\n  for (i in 1:n) log_lik[i] = normal_lpdf(log_gdp_std[i] | mu[i], sigma);\n}\n'\n\nThis time we’ll sample from the posterior.\n\nm8.1 &lt;- stan(\n  data = stan_data,\n  model_code = model_code_8.1,\n  cores = 4, seed = 8)\n\nCheck the summary for m8.1.\n\nprint(m8.1, pars = c(\"a\", \"b\", \"sigma\"), probs = c(0.055, 0.945))\n\nInference for Stan model: anon_model.\n4 chains, each with iter=2000; warmup=1000; thin=1; \npost-warmup draws per chain=1000, total post-warmup draws=4000.\n\n      mean se_mean   sd  5.5% 94.5% n_eff Rhat\na     1.00       0 0.01  0.98  1.02  3775    1\nb     0.00       0 0.06 -0.08  0.09  3533    1\nsigma 0.14       0 0.01  0.13  0.15  3726    1\n\nSamples were drawn using NUTS(diag_e) at Mon Aug  5 21:07:01 2024.\nFor each parameter, n_eff is a crude measure of effective sample size,\nand Rhat is the potential scale reduction factor on split chains (at \nconvergence, Rhat=1).\n\n\n\n8.1.1.1 Rethinking: Practicing for when it matters.\n\n\n\n8.1.2 Adding an indicator variable isn’t enough.\nMake the cid index variable.\n\ndd &lt;- dd |&gt; \n  mutate(cid = if_else(cont_africa == 1, \"1\", \"2\"))\n\nUpdate the stan_data to include the cid index. As we have saved cid as a character variable, note how compose_data() automatically computes an n_cid value.\n\nstan_data &lt;- dd |&gt;\n  select(log_gdp_std, rugged_std, cid) |&gt;  \n  compose_data(xbar = mean(dd$rugged_std))\n\n# What?\nstr(stan_data)\n\nList of 6\n $ log_gdp_std: num [1:170(1d)] 0.88 0.965 1.166 1.104 0.915 ...\n $ rugged_std : num [1:170(1d)] 0.138 0.553 0.124 0.125 0.433 ...\n $ cid        : num [1:170(1d)] 1 2 2 2 2 2 2 2 2 1 ...\n $ n_cid      : int 2\n $ n          : int 170\n $ xbar       : num 0.215\n\n\nMake model_code_8.2 for the varying-intercepts model.\n\nmodel_code_8.2 &lt;- '\ndata {\n  int&lt;lower=1&gt; n;\n  int&lt;lower=1&gt; n_cid;\n  real xbar;\n  array[n] int cid;\n  vector[n] rugged_std;\n  vector[n] log_gdp_std;\n}\nparameters {\n  vector[n_cid] a;\n  real b;\n  real&lt;lower=0&gt; sigma;\n}\ntransformed parameters {\n  vector[n] mu;\n  mu = a[cid] + b * (rugged_std - xbar);\n}\nmodel {\n  log_gdp_std ~ normal(mu, sigma);\n  \n  a ~ normal(1, 0.1);\n  b ~ normal(0, 0.3);\n  sigma ~ exponential(1);\n}\ngenerated quantities {\n  vector[n] log_lik;\n  for (i in 1:n) log_lik[i] = normal_lpdf(log_gdp_std[i] | mu[i], sigma);\n}\n'\n\nSample from the posterior.\n\nm8.2 &lt;- stan(\n  data = stan_data,\n  model_code = model_code_8.2,\n  cores = 4, seed = 8)\n\nCheck the summary for m8.2.\n\nprint(m8.2, pars = c(\"a\", \"b\", \"sigma\"), probs = c(0.055, 0.945))\n\nInference for Stan model: anon_model.\n4 chains, each with iter=2000; warmup=1000; thin=1; \npost-warmup draws per chain=1000, total post-warmup draws=4000.\n\n       mean se_mean   sd  5.5% 94.5% n_eff Rhat\na[1]   0.88       0 0.02  0.86  0.91  4035    1\na[2]   1.05       0 0.01  1.03  1.07  4227    1\nb     -0.05       0 0.05 -0.12  0.03  4267    1\nsigma  0.11       0 0.01  0.10  0.13  4134    1\n\nSamples were drawn using NUTS(diag_e) at Wed Aug 14 10:43:50 2024.\nFor each parameter, n_eff is a crude measure of effective sample size,\nand Rhat is the potential scale reduction factor on split chains (at \nconvergence, Rhat=1).\n\n\nUse the extract_log_lik() and waic() functions to compute the WAIC summaries for the models.\n\nw8.1 &lt;- extract_log_lik(m8.1) |&gt; \n  waic()\n\nw8.2 &lt;- extract_log_lik(m8.2) |&gt; \n  waic()\n\nUse the loo_compare() functions to compare the models by their WAIC distributions.\n\nloo_compare(w8.1, w8.2) |&gt; \n  print(simplify = FALSE)\n\n       elpd_diff se_diff elpd_waic se_elpd_waic p_waic se_p_waic waic   se_waic\nmodel2    0.0       0.0   126.2       7.4          4.1    0.8    -252.4   14.8 \nmodel1  -31.8       7.3    94.4       6.5          2.6    0.3    -188.8   13.0 \n\n\nI’m not going to continue to compute the WAIC weights by hand, like in Section 7.5.1, but here are the stacking weights.\n\nloo_model_weights(\n  list(extract_log_lik(m8.1) |&gt; loo(),\n       extract_log_lik(m8.2) |&gt; loo()),\n  method = \"stacking\")\n\nMethod: stacking\n------\n       weight\nmodel1 0.030 \nmodel2 0.970 \n\n\nHere’s the posterior mean and 89% interval for the \\(a_{[1]} - a_{[2]}\\) contrast.\n\nm8.2 |&gt; \n  spread_draws(a[j]) |&gt; \n  # Requires the emmeans package for this `comparison` option\n  compare_levels(a, j, comparison = emmeans_comparison(\"revpairwise\")) |&gt; \n  mean_qi(a, .width = 0.89)\n\n# A tibble: 1 × 7\n  j         a .lower .upper .width .point .interval\n  &lt;chr&gt; &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;    \n1 2 - 1 0.168  0.138  0.199   0.89 mean   qi       \n\n\nHere’s a way to make Figure 8.4.\n\nas_draws_df(m8.2) |&gt; \n  select(.draw, `a[1]`:sigma) |&gt; \n  expand_grid(cid = distinct(dd, cid) |&gt; pull(),\n              rugged_std = seq(from = -0.1, to = 1.1, length.out = 30),\n              xbar = mean(dd$rugged_std)) |&gt; \n  mutate(nations = ifelse(cid == \"1\", \"African nations\", \"Non-African nations\"),\n         mu = case_when(\n    cid == \"1\" ~ `a[1]` + b * (rugged_std - xbar),\n    cid == \"2\" ~ `a[2]` + b * (rugged_std - xbar))) |&gt; \n  \n  ggplot(aes(x = rugged_std, color = nations)) +\n  stat_lineribbon(aes(y = mu, fill = nations),\n                  .width = 0.97, alpha = 1/3) +\n  geom_point(data = dd,\n             aes(y = log_gdp_std))  +\n  scale_color_viridis_d(NULL, option = \"B\", begin = 0.2, end = 0.6) +\n  scale_fill_viridis_d(NULL, option = \"B\", begin = 0.2, end = 0.6) +\n  labs(x = \"ruggedness (standardized)\",\n       y = \"log GDP (prop of mean)\") +\n  coord_cartesian(xlim = 0:1)\n\n\n\n\nNote our use of the case_when() function when defining the linear models for the two levels of cid.\n\n8.1.2.1 Rethinking: Why 97%?\n\n\n\n8.1.3 Adding an interaction does work.\nIn model_code_8.3 we add an interaction to the model via the index-variable approach by setting vector[n_cid] b within the parameters block, and then by setting b[cid] in the mu formula within the transformed parameters block.\n\nmodel_code_8.3 &lt;- '\ndata {\n  int&lt;lower=1&gt; n;\n  int&lt;lower=1&gt; n_cid;\n  real xbar;\n  array[n] int cid;\n  vector[n] rugged_std;\n  vector[n] log_gdp_std;\n}\nparameters {\n  vector[n_cid] a;\n  vector[n_cid] b;\n  real&lt;lower=0&gt; sigma;\n}\ntransformed parameters {\n  vector[n] mu;\n  mu = a[cid] + b[cid] .* (rugged_std - xbar);\n}\nmodel {\n  log_gdp_std ~ normal(mu, sigma);\n  \n  a ~ normal(1, 0.1);\n  b ~ normal(0, 0.3);\n  sigma ~ exponential(1);\n}\ngenerated quantities {\n  vector[n] log_lik;\n  for (i in 1:n) log_lik[i] = normal_lpdf(log_gdp_std[i] | mu[i], sigma);\n}\n'\n\nSample from the posterior.\n\nm8.3 &lt;- stan(\n  data = stan_data,\n  model_code = model_code_8.3,\n  cores = 4, seed = 8)\n\nCheck the summary for m8.2.\n\nprint(m8.3, pars = c(\"a\", \"b\", \"sigma\"), probs = c(0.055, 0.945))\n\nInference for Stan model: anon_model.\n4 chains, each with iter=2000; warmup=1000; thin=1; \npost-warmup draws per chain=1000, total post-warmup draws=4000.\n\n       mean se_mean   sd  5.5% 94.5% n_eff Rhat\na[1]   0.89       0 0.02  0.86  0.91  4523    1\na[2]   1.05       0 0.01  1.04  1.07  4717    1\nb[1]   0.13       0 0.08  0.01  0.26  4369    1\nb[2]  -0.14       0 0.05 -0.23 -0.05  4278    1\nsigma  0.11       0 0.01  0.10  0.12  4404    1\n\nSamples were drawn using NUTS(diag_e) at Wed Aug 14 10:46:03 2024.\nFor each parameter, n_eff is a crude measure of effective sample size,\nand Rhat is the potential scale reduction factor on split chains (at \nconvergence, Rhat=1).\n\n\nCompute and save the waic() summary for m8.3.\n\nw8.3 &lt;- extract_log_lik(m8.3) |&gt; \n  waic()\n\nUse the loo_compare() functions to compare the three models by their WAIC estimates.\n\nloo_compare(w8.1, w8.2, w8.3) |&gt; \n  print(simplify = FALSE)\n\n       elpd_diff se_diff elpd_waic se_elpd_waic p_waic se_p_waic waic   se_waic\nmodel3    0.0       0.0   129.8       7.3          4.8    0.8    -259.5   14.7 \nmodel2   -3.6       3.2   126.2       7.4          4.1    0.8    -252.4   14.8 \nmodel1  -35.4       7.5    94.4       6.5          2.6    0.3    -188.8   13.0 \n\n\nMcElreath mentioned Pareto-\\(k\\) warnings as a reason to switch to the loo().\n\nl8.1 &lt;- extract_log_lik(m8.1) |&gt; \n  loo()\n\nl8.2 &lt;- extract_log_lik(m8.2) |&gt; \n  loo()\n\nl8.3 &lt;- extract_log_lik(m8.3) |&gt; \n  loo()\n\nWe can make a quick plot for the \\(k\\) values by inserting our loo() objects into the plot() function.\n\nplot(l8.3)\n\n\n\n\nMcElreath is using an 0.5 threshold for the \\(k\\) values, but the loo team currently uses 0.7 for warnings. We can get a sense of that with the pareto_k_table() function.\n\npareto_k_table(l8.3)\n\n\nAll Pareto k estimates are good (k &lt; 0.7).\n\n\nHowever, if we wanted to see which cases might be above 0.5, we could use pareto_k_ids() with threshold = 0.5.\n\npareto_k_ids(l8.3, threshold = 0.5)\n\n[1] 93\n\n\nCase number 93 in the data was above 0.5. We can extract their specific \\(k\\) value with the pareto_k_values() function.\n\npareto_k_values(l8.3)[93]\n\n[1] 0.5597555\n\n\nAnyway, here’s the comparison by the loo().\n\nloo_compare(l8.1, l8.2, l8.3) |&gt; \n  print(simplify = FALSE)\n\n       elpd_diff se_diff elpd_loo se_elpd_loo p_loo  se_p_loo looic  se_looic\nmodel3    0.0       0.0   129.7      7.3         4.9    0.9   -259.4   14.7  \nmodel2   -3.5       3.2   126.2      7.4         4.1    0.8   -252.3   14.8  \nmodel1  -35.3       7.5    94.4      6.5         2.6    0.3   -188.8   13.0  \n\n\nHere are the stacking weights.\n\nloo_model_weights(\n  list(l8.1, l8.2, l8.3),\n  method = \"stacking\")\n\nMethod: stacking\n------\n       weight\nmodel1 0.000 \nmodel2 0.123 \nmodel3 0.877 \n\n\nThey don’t match up exactly with the LOO weights McElreath reported in the text (p. 249), but the basic pattern is the same.\n\n\n8.1.4 Plotting the interaction.\nThe code for Figure 8.5 is a minor extension of the code we used for Figure 8.4. The main changes are the mu formulas have changed within case_when(), and we have added a call to facet_wrap().\n\nas_draws_df(m8.3) |&gt; \n  select(.draw, `a[1]`:sigma) |&gt; \n  expand_grid(cid = distinct(dd, cid) |&gt; pull(),\n              rugged_std = seq(from = -0.1, to = 1.1, length.out = 30),\n              xbar = mean(dd$rugged_std)) |&gt; \n  mutate(nations = ifelse(cid == \"1\", \"African nations\", \"Non-African nations\"),\n         mu = case_when(\n    cid == \"1\" ~ `a[1]` + `b[1]` * (rugged_std - xbar),\n    cid == \"2\" ~ `a[2]` + `b[2]` * (rugged_std - xbar))) |&gt; \n  \n  ggplot(aes(x = rugged_std, color = nations)) +\n  stat_lineribbon(aes(y = mu, fill = nations),\n                  .width = 0.97, alpha = 1/3) +\n  geom_point(data = dd,\n             aes(y = log_gdp_std))  +\n  scale_color_viridis_d(option = \"B\", begin = 0.2, end = 0.6, breaks = NULL) +\n  scale_fill_viridis_d(option = \"B\", begin = 0.2, end = 0.6, breaks = NULL) +\n  labs(x = \"ruggedness (standardized)\",\n       y = \"log GDP (prop of mean)\") +\n  coord_cartesian(xlim = 0:1) +\n  facet_wrap(~ nations)\n\n\n\n\n\n8.1.4.1 Rethinking: All Greek to me."
  },
  {
    "objectID": "08.html#symmetry-of-interactions",
    "href": "08.html#symmetry-of-interactions",
    "title": "8  Conditional Manatees",
    "section": "8.2 Symmetry of interactions",
    "text": "8.2 Symmetry of interactions\nAnother way to express the model is\n\\[\n\\begin{align*}\n\\mu_i & = \\underbrace{(2 - \\text{cid}_{i}) \\left (\\alpha_1 + \\beta_1 \\left [\\text{rugged-std}_i - \\overline{\\text{rugged-std}} \\right ] \\right )}_{\\text{cid}[i] = 1} \\\\\n      & \\;\\;\\; + \\underbrace{(\\text{cid}_{i} - 1) \\left (\\alpha_2 + \\beta_2 \\left [\\text{rugged-std}_i - \\overline{\\text{rugged-std}} \\right ] \\right )}_{\\text{cid}[i] = 2},\n\\end{align*}\n\\]\nwhere the first term vanishes when \\(\\text{cid}_i = 2\\) and the second term vanishes when \\(\\text{cid}_i = 1\\). In contrast to the plots above, we can re-express this equation as saying “The association of being in Africa with log GDP depends upon terrain ruggedness” (p. 251, emphasis in the original). Here we follow McElreath’s Figure 8.6 and plot the difference between a nation in Africa and outside Africa, conditional on ruggedness.\n\nas_draws_df(m8.3) |&gt; \n  select(.draw, `a[1]`:sigma) |&gt; \n  expand_grid(cid = distinct(dd, cid) |&gt; pull(),\n              rugged_std = seq(from = -0.1, to = 1.1, length.out = 30),\n              xbar = mean(dd$rugged_std)) |&gt; \n  mutate(nations = ifelse(cid == \"1\", \"African nations\", \"Non-African nations\"),\n         mu = case_when(\n    cid == \"1\" ~ `a[1]` + `b[1]` * (rugged_std - xbar),\n    cid == \"2\" ~ `a[2]` + `b[2]` * (rugged_std - xbar))) |&gt; \n  group_by(rugged_std) |&gt; \n  compare_levels(mu, by = nations, comparison = list(c(\"African nations\", \"Non-African nations\")), draw_indices = \".draw\") |&gt; \n  \n  ggplot(aes(x = rugged_std, y = mu)) +\n  stat_lineribbon(.width = 0.97, alpha = 1/3, fill = \"gray50\") +\n  geom_hline(yintercept = 0, linetype = 2) +\n  annotate(geom = \"text\",\n           x = 0, y = 0,\n           label = \"Africa higher GDP\\nAfrica lower GDP\",\n           hjust = 0) +\n  labs(x = \"ruggedness (standardized)\",\n       y = \"expected difference log GDP\") +\n  coord_cartesian(xlim = c(0, 1),\n                  ylim = c(-0.3, 0.2)) +\n  theme(legend.position = \"none\")"
  },
  {
    "objectID": "08.html#continuous-interactions",
    "href": "08.html#continuous-interactions",
    "title": "8  Conditional Manatees",
    "section": "8.3 Continuous interactions",
    "text": "8.3 Continuous interactions\n\n8.3.1 A winter flower.\nLook at the tulips data, which were adapted from Grafen & Hails (2002).\n\ndata(tulips, package = \"rethinking\")\nd &lt;- tulips\nrm(tulips)\n\nglimpse(d)\n\nRows: 27\nColumns: 4\n$ bed    &lt;fct&gt; a, a, a, a, a, a, a, a, a, b, b, b, b, b, b, b, b, b, c, c, c, …\n$ water  &lt;int&gt; 1, 1, 1, 2, 2, 2, 3, 3, 3, 1, 1, 1, 2, 2, 2, 3, 3, 3, 1, 1, 1, …\n$ shade  &lt;int&gt; 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, …\n$ blooms &lt;dbl&gt; 0.00, 0.00, 111.04, 183.47, 59.16, 76.75, 224.97, 83.77, 134.95…\n\n\n\n\n8.3.2 The models.\nWrangle a little.\n\nd &lt;- d |&gt; \n  mutate(blooms_std = blooms / max(blooms),\n         water_cent = water - mean(water),\n         shade_cent = shade - mean(shade))\n\nIf we let \\(B\\), \\(W\\), and \\(S\\) stand for the scaled/centered versions of the variables, we might express an unconditional (additive) model as\n\\[\n\\begin{align*}\nB_i & \\sim \\operatorname{Normal}(\\mu_i, \\sigma) \\\\\n\\mu_i   & = \\alpha + \\beta_1 W_i + \\beta_2 S_i \\\\\n\\alpha  & \\sim \\operatorname{Normal}(0.5, 1) \\\\\n\\beta_1 & \\sim \\operatorname{Normal}(0, 1) \\\\\n\\beta_2 & \\sim \\operatorname{Normal}(0, 1) \\\\\n\\sigma  & \\sim \\operatorname{Exponential}(1).\n\\end{align*}\n\\]\nEven though “the intercept \\(\\alpha\\) must be greater than zero and less than one,… this prior assigns most of the probability outside that range” (p. 254).\n\nset.seed(8)\n\ntibble(a = rnorm(n = 1e4, mean = 0.5, sd = 1)) |&gt; \n  summarise(proportion_outside_of_the_range = sum(a &lt; 0 | a &gt; 1) / n())\n\n# A tibble: 1 × 1\n  proportion_outside_of_the_range\n                            &lt;dbl&gt;\n1                           0.621\n\n\nTightening up the prior to \\(\\operatorname{Normal}(0, 0.25)\\) helps.\n\nset.seed(8)\n\ntibble(a = rnorm(n = 1e4, mean = 0.5, sd = 0.25)) |&gt; \n  summarise(proportion_outside_of_the_range = sum(a &lt; 0 | a &gt; 1) / n())\n\n# A tibble: 1 × 1\n  proportion_outside_of_the_range\n                            &lt;dbl&gt;\n1                          0.0501\n\n\nHere are the ranges for our two predictors.\n\nrange(d$water_cent)\n\n[1] -1  1\n\nrange(d$shade_cent)\n\n[1] -1  1\n\n\nPutting the same \\(\\operatorname{Normal}(0, 0.25)\\) prior on each would indicate a 0.95 probability each coefficient would be within -0.5 to 0.5. Since the total range for both is \\(1 - (-1) = 2\\), that would imply either could account for the full range of blooms_std because \\(0.5 \\cdot 2 = 1\\), which is the full range of blooms_std. Our first model, then, will be\n\\[\n\\begin{align*}\nB_i & \\sim \\operatorname{Normal}(\\mu_i, \\sigma) \\\\\n\\mu_i   & = \\alpha + \\beta_1 W_i + \\beta_2 S_i \\\\\n\\alpha  & \\sim \\operatorname{Normal}(0.5, 0.25) \\\\\n\\beta_1 & \\sim \\operatorname{Normal}(0, 0.25) \\\\\n\\beta_2 & \\sim \\operatorname{Normal}(0, 0.25) \\\\\n\\sigma  & \\sim \\operatorname{Exponential}(1).\n\\end{align*}\n\\]\nWith our second model we extend to the interaction model,\n\\[\n\\begin{align*}\nB_i & \\sim \\operatorname{Normal}(\\mu_i, \\sigma) \\\\\n\\mu_i   & = \\alpha + \\beta_1 W_i + \\beta_2 S_i + \\beta_3 W_i S_i \\\\\n\\alpha  & \\sim \\operatorname{Normal}(0.5, 0.25) \\\\\n\\beta_1, \\dots, \\beta_3 & \\sim \\operatorname{Normal}(0, 0.25) \\\\\n\\sigma  & \\sim \\operatorname{Exponential}(1),\n\\end{align*}\n\\]\nwhere \\(\\beta_3\\) is the continuous interaction term.\nMake the stan_data.\nThis time when we fit the model, we’ll build in some model-based expected values within the generated quantities block. To prepare, we’ll first make a data frame with our predictor grid.\n\nd_pred &lt;- crossing(\n  w = -1:1,\n  s = -1:1) |&gt; \n  mutate(i = 1:n())\n\n# What?\nprint(d_pred)\n\n# A tibble: 9 × 3\n      w     s     i\n  &lt;int&gt; &lt;int&gt; &lt;int&gt;\n1    -1    -1     1\n2    -1     0     2\n3    -1     1     3\n4     0    -1     4\n5     0     0     5\n6     0     1     6\n7     1    -1     7\n8     1     0     8\n9     1     1     9\n\n\nNow make the stan_data. Note how we’ve defined the w_pred through n_pred values within compose_data(), based on our predictor grid d_pred.\n\nstan_data &lt;- d |&gt; \n  transmute(b = blooms_std,\n            w = water_cent,\n            s = shade_cent) |&gt;  \n  compose_data(w_pred = pull(d_pred, w),\n               s_pred = pull(d_pred, s),\n               n_pred = nrow(d_pred))\n\n# What?\nstr(stan_data)\n\nList of 7\n $ b     : num [1:27(1d)] 0 0 0.307 0.507 0.164 ...\n $ w     : num [1:27(1d)] -1 -1 -1 0 0 0 1 1 1 -1 ...\n $ s     : num [1:27(1d)] -1 0 1 -1 0 1 -1 0 1 -1 ...\n $ n     : int 27\n $ w_pred: int [1:9] -1 -1 -1 0 0 0 1 1 1\n $ s_pred: int [1:9] -1 0 1 -1 0 1 -1 0 1\n $ n_pred: int 9\n\n\nMake model_code_8.4 and model_code_8.5.\n\n# No interaction\nmodel_code_8.4 &lt;- '\ndata {\n  int&lt;lower=1&gt; n;\n  int&lt;lower=1&gt; n_pred;\n  vector[n] b;\n  vector[n] s;\n  vector[n] w;\n  vector[n_pred] s_pred;\n  vector[n_pred] w_pred;\n}\nparameters {\n  real a;\n  real b1;\n  real b2;\n  real&lt;lower=0&gt; sigma;\n}\nmodel {\n  b ~ normal(a + b1 * w + b2 * s, sigma);\n  \n  a ~ normal(0.5, 0.25);\n  b1 ~ normal(0, 0.25);\n  b2 ~ normal(0, 0.25);\n  sigma ~ exponential(1);\n}\ngenerated quantities {\n  vector[n_pred] mu;\n  mu = a + b1 * w_pred + b2 * s_pred;\n}\n'\n\n# Interaction\nmodel_code_8.5 &lt;- '\ndata {\n  int&lt;lower=1&gt; n;\n  int&lt;lower=1&gt; n_pred;\n  vector[n] b;\n  vector[n] s;\n  vector[n] w;\n  vector[n_pred] s_pred;\n  vector[n_pred] w_pred;\n}\nparameters {\n  real a;\n  real b1;\n  real b2;\n  real b3;\n  real&lt;lower=0&gt; sigma;\n}\nmodel {\n  b ~ normal(a + b1 * w + b2 * s + b3 .* w .* s, sigma);\n  \n  a ~ normal(0.5, 0.25);\n  [b1, b2, b3] ~ normal(0, 0.25);\n  sigma ~ exponential(1);\n}\ngenerated quantities {\n  vector[n_pred] mu;\n  mu = a + b1 * w_pred + b2 * s_pred + b3 .* w_pred .* s_pred;\n}\n'\n\nSample from the two posteriors.\n\nm8.4 &lt;- stan(\n  data = stan_data,\n  model_code = model_code_8.4,\n  cores = 4, seed = 8)\n\nm8.5 &lt;- stan(\n  data = stan_data,\n  model_code = model_code_8.5,\n  cores = 4, seed = 8)\n\nCheck the summaries for m8.4 and m8.5.\n\nprint(m8.4, include = FALSE, pars = \"mu\", probs = c(0.055, 0.945))\n\nInference for Stan model: anon_model.\n4 chains, each with iter=2000; warmup=1000; thin=1; \npost-warmup draws per chain=1000, total post-warmup draws=4000.\n\n       mean se_mean   sd  5.5% 94.5% n_eff Rhat\na      0.36    0.00 0.04  0.30  0.42  4370    1\nb1     0.20    0.00 0.04  0.14  0.27  4269    1\nb2    -0.11    0.00 0.04 -0.18 -0.05  4965    1\nsigma  0.18    0.00 0.03  0.14  0.22  3297    1\nlp__  31.41    0.04 1.55 28.49 33.23  1468    1\n\nSamples were drawn using NUTS(diag_e) at Mon Aug  5 21:26:39 2024.\nFor each parameter, n_eff is a crude measure of effective sample size,\nand Rhat is the potential scale reduction factor on split chains (at \nconvergence, Rhat=1).\n\nprint(m8.5, include = FALSE, pars = \"mu\", probs = c(0.055, 0.945))\n\nInference for Stan model: anon_model.\n4 chains, each with iter=2000; warmup=1000; thin=1; \npost-warmup draws per chain=1000, total post-warmup draws=4000.\n\n       mean se_mean   sd  5.5% 94.5% n_eff Rhat\na      0.36    0.00 0.03  0.31  0.40  4937    1\nb1     0.20    0.00 0.03  0.15  0.26  4643    1\nb2    -0.11    0.00 0.03 -0.17 -0.06  5296    1\nb3    -0.14    0.00 0.04 -0.21 -0.08  4498    1\nsigma  0.14    0.00 0.02  0.11  0.18  3684    1\nlp__  36.87    0.04 1.75 33.72 39.01  1728    1\n\nSamples were drawn using NUTS(diag_e) at Mon Aug  5 21:27:06 2024.\nFor each parameter, n_eff is a crude measure of effective sample size,\nand Rhat is the potential scale reduction factor on split chains (at \nconvergence, Rhat=1).\n\n\nHere’s a look at the \\(\\beta_3\\) posterior.\n\nas_draws_df(m8.5) |&gt; \n  ggplot(aes(x = b3)) +\n  stat_halfeye(.width = 0.89) +\n  scale_y_continuous(NULL, breaks = NULL) +\n  xlab(expression(beta[3]~(the~continuous~interaction~term)))\n\n\n\n\n\n8.3.2.1 Overthinking: How is interaction formed?\n\n\n\n8.3.3 Plotting posterior predictions.\nHere’s how we might use spread_draws() to make Figure 8.7.\n\nset.seed(8)\n\nbind_rows(\n  spread_draws(m8.4, mu[i], ndraws = 20),\n  spread_draws(m8.5, mu[i], ndraws = 20)\n) |&gt; \n  mutate(fit = rep(c(\"m8.4\", \"m8.5\"), each = n() / 2)) |&gt; \n  left_join(d_pred, by = join_by(i)) |&gt; \n  mutate(s = str_c(\"shade~(centered)==\", s)) |&gt;\n  \n  ggplot() +\n  geom_line(aes(x = w, y = mu, group = .draw),\n            alpha = 1/3, color = \"blue\", linewidth = 1/3) +\n  geom_point(data = d |&gt; \n               mutate(s = str_c(\"shade~(centered)==\", shade_cent)),\n             aes(x = water_cent, y = blooms_std)) +\n  labs(x = \"water (centered)\",\n       y = \"blooms (scaled)\") +\n  facet_grid(fit ~ s, labeller = label_parsed)\n\n\n\n\n\n\n8.3.4 Plotting prior predictions.\nTo plot the prior-predictive expectations, we’ll need to first sample from the priors. Toward that end, we define what I’ll call model_code_8.4p and model_code_8.5p.\n\n# No interaction\nmodel_code_8.4p &lt;- '\ndata {\n  int&lt;lower=1&gt; n;\n  int&lt;lower=1&gt; n_pred;\n  vector[n] b;\n  vector[n] s;\n  vector[n] w;\n  vector[n_pred] s_pred;\n  vector[n_pred] w_pred;\n}\nparameters {\n  real a;\n  real b1;\n  real b2;\n  real&lt;lower=0&gt; sigma;\n}\nmodel {\n  // Only the priors\n  a ~ normal(0.5, 0.25);\n  b1 ~ normal(0, 0.25);\n  b2 ~ normal(0, 0.25);\n  sigma ~ exponential(1);\n}\ngenerated quantities {\n  vector[n_pred] mu;\n  mu = a + b1 * w_pred + b2 * s_pred;\n}\n'\n\n# Interaction\nmodel_code_8.5p &lt;- '\ndata {\n  int&lt;lower=1&gt; n;\n  int&lt;lower=1&gt; n_pred;\n  vector[n] b;\n  vector[n] s;\n  vector[n] w;\n  vector[n_pred] s_pred;\n  vector[n_pred] w_pred;\n}\nparameters {\n  real a;\n  real b1;\n  real b2;\n  real b3;\n  real&lt;lower=0&gt; sigma;\n}\nmodel {\n  // Only the priors\n  a ~ normal(0.5, 0.25);\n  [b1, b2, b3] ~ normal(0, 0.25);\n  sigma ~ exponential(1);\n}\ngenerated quantities {\n  vector[n_pred] mu;\n  mu = a + b1 * w_pred + b2 * s_pred + b3 .* w_pred .* s_pred;\n}\n'\n\nSample from the two priors with stan().\n\nm8.4p &lt;- stan(\n  data = stan_data,\n  model_code = model_code_8.4p,\n  cores = 4, seed = 8)\n\nm8.5p &lt;- stan(\n  data = stan_data,\n  model_code = model_code_8.5p,\n  cores = 4, seed = 8)\n\nNow make Figure 8.8.\n\nset.seed(8)\n\nbind_rows(\n  spread_draws(m8.4p, mu[i], ndraws = 20),\n  spread_draws(m8.5p, mu[i], ndraws = 20)\n) |&gt; \n  mutate(fit = rep(c(\"m8.4~(prior)\", \"m8.5~(prior)\"), each = n() / 2)) |&gt; \n  left_join(d_pred, by = join_by(i)) |&gt; \n  mutate(s = str_c(\"shade~(centered)==\", s)) |&gt;\n  \n  ggplot(aes(x = w, y = mu)) +\n  geom_hline(yintercept = 0:1, color = \"white\", linetype = 2) +\n  geom_line(aes(group = .draw),\n            alpha = 1/3, color = \"blue\", linewidth = 1/3) +\n  scale_y_continuous(\"blooms (scaled)\", breaks = 0:2 / 2) +\n  xlab(\"water (centered)\") +\n  coord_cartesian(ylim = c(-0.5, 1.5)) +\n  facet_grid(fit ~ s, labeller = label_parsed)"
  },
  {
    "objectID": "08.html#summary",
    "href": "08.html#summary",
    "title": "8  Conditional Manatees",
    "section": "8.4 Summary",
    "text": "8.4 Summary"
  },
  {
    "objectID": "08.html#session-info",
    "href": "08.html#session-info",
    "title": "8  Conditional Manatees",
    "section": "Session info",
    "text": "Session info\n\nsessionInfo()\n\nR version 4.4.0 (2024-04-24)\nPlatform: aarch64-apple-darwin20\nRunning under: macOS Ventura 13.4\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: America/Chicago\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n [1] tidybayes_3.0.6    loo_2.8.0          posterior_1.6.0    rstan_2.32.6      \n [5] StanHeaders_2.32.7 ggdag_0.2.12       lubridate_1.9.3    forcats_1.0.0     \n [9] stringr_1.5.1      dplyr_1.1.4        purrr_1.0.2        readr_2.1.5       \n[13] tidyr_1.3.1        tibble_3.2.1       ggplot2_3.5.1      tidyverse_2.0.0   \n\nloaded via a namespace (and not attached):\n [1] tidyselect_1.2.1     svUnit_1.0.6         viridisLite_0.4.2   \n [4] farver_2.1.1         viridis_0.6.5        ggraph_2.2.1        \n [7] fastmap_1.1.1        tensorA_0.36.2.1     tweenr_2.0.3        \n[10] digest_0.6.35        estimability_1.5.1   timechange_0.3.0    \n[13] lifecycle_1.0.4      magrittr_2.0.3       compiler_4.4.0      \n[16] rlang_1.1.4          tools_4.4.0          igraph_2.0.3        \n[19] utf8_1.2.4           yaml_2.3.8           knitr_1.46          \n[22] labeling_0.4.3       graphlayouts_1.1.1   htmlwidgets_1.6.4   \n[25] pkgbuild_1.4.4       curl_5.2.1           dagitty_0.3-4       \n[28] abind_1.4-5          withr_3.0.0          grid_4.4.0          \n[31] polyclip_1.10-6      stats4_4.4.0         fansi_1.0.6         \n[34] xtable_1.8-4         colorspace_2.1-0     inline_0.3.19       \n[37] emmeans_1.10.3       scales_1.3.0         MASS_7.3-60.2       \n[40] mvtnorm_1.2-5        cli_3.6.3            rmarkdown_2.26      \n[43] generics_0.1.3       RcppParallel_5.1.7   rstudioapi_0.16.0   \n[46] tzdb_0.4.0           cachem_1.0.8         ggforce_0.4.2       \n[49] splines_4.4.0        parallel_4.4.0       matrixStats_1.3.0   \n[52] vctrs_0.6.5          Matrix_1.7-0         V8_4.4.2            \n[55] boot_1.3-30          jsonlite_1.8.8       hms_1.1.3           \n[58] arrayhelpers_1.1-0   ggrepel_0.9.5        ggdist_3.3.2        \n[61] glue_1.7.0           codetools_0.2-20     distributional_0.4.0\n[64] stringi_1.8.4        gtable_0.3.5         QuickJSR_1.1.3      \n[67] munsell_0.5.1        pillar_1.9.0         htmltools_0.5.8.1   \n[70] R6_2.5.1             tidygraph_1.3.1      evaluate_0.23       \n[73] lattice_0.22-6       backports_1.5.0      memoise_2.0.1       \n[76] Rcpp_1.0.12          nlme_3.1-164         coda_0.19-4.1       \n[79] gridExtra_2.3        checkmate_2.3.1      mgcv_1.9-1          \n[82] xfun_0.43            pkgconfig_2.0.3"
  },
  {
    "objectID": "08.html#comments",
    "href": "08.html#comments",
    "title": "8  Conditional Manatees",
    "section": "Comments",
    "text": "Comments\n\n\n\n\nGrafen, A., & Hails, R. (2002). Modern statistics for the life sciences. Oxford University Press. https://global.oup.com/academic/product/modern-statistics-for-the-life-sciences-9780199252312?\n\n\nNunn, N., & Puga, D. (2012). Ruggedness: The blessing of bad geography in Africa. Review of Economics and Statistics, 94(1), 20–36. https://doi.org/10.1162/REST_a_00161"
  },
  {
    "objectID": "09.html#good-king-markov-and-his-island-kingdom",
    "href": "09.html#good-king-markov-and-his-island-kingdom",
    "title": "9  Markov Chain Monte Carlo",
    "section": "9.1 Good King Markov and his island kingdom",
    "text": "9.1 Good King Markov and his island kingdom"
  },
  {
    "objectID": "09.html#metropolis-algorithms",
    "href": "09.html#metropolis-algorithms",
    "title": "9  Markov Chain Monte Carlo",
    "section": "9.2 Metropolis algorithms",
    "text": "9.2 Metropolis algorithms\n\n9.2.1 Gibbs sampling.\n\n\n9.2.2 High-dimensional problems."
  },
  {
    "objectID": "09.html#hamiltonian-monte-carlo",
    "href": "09.html#hamiltonian-monte-carlo",
    "title": "9  Markov Chain Monte Carlo",
    "section": "9.3 Hamiltonian Monte Carlo",
    "text": "9.3 Hamiltonian Monte Carlo\n\n9.3.1 Another parable.\n\n9.3.1.1 Rethinking: Hamiltonians.\n\n\n\n9.3.2 Particles in space.\n\n9.3.2.1 Overthinking: Hamiltonian Monte Carlo in the raw.\n\n\n\n9.3.3 Limitations.\n\n9.3.3.1 Rethinking: The MCMC horizon."
  },
  {
    "objectID": "09.html#easy-hmc-ulam-stan",
    "href": "09.html#easy-hmc-ulam-stan",
    "title": "9  Markov Chain Monte Carlo",
    "section": "9.4 Easy HMC: ulam stan()",
    "text": "9.4 Easy HMC: ulam stan()\nHere we load the rugged data.\n\ndata(rugged, package = \"rethinking\")\nd &lt;- rugged\nrm(rugged)\n\nWrangle the data a bit.\n\nd &lt;- d |&gt;\n  mutate(log_gdp = log(rgdppc_2000))\n\ndd &lt;- d |&gt;\n  drop_na(rgdppc_2000) |&gt; \n  mutate(log_gdp_std = log_gdp / mean(log_gdp),\n         rugged_std  = rugged / max(rugged),\n         cid         = ifelse(cont_africa == 1, \"1\", \"2\")) |&gt; \n  mutate(rugged_std_c = rugged_std - mean(rugged_std))\n\nIn the context of this chapter, it doesn’t make sense to translate McElreath’s m8.3 quap() code to stan() code. Below, we’ll just go directly to the stan() variant of his m9.1.\n\n9.4.1 Preparation.\nWrangle the data into a list with the compose_data() function. McElreath called his data list dat_slim. Here we’ll follow the conventions from earlier chapters and call the object stan_data.\n\nstan_data &lt;- dd |&gt;\n  select(log_gdp_std, rugged_std, cid, rugged_std_c) |&gt;  \n  compose_data()\n\n# What?\nstr(stan_data)\n\nList of 6\n $ log_gdp_std : num [1:170(1d)] 0.88 0.965 1.166 1.104 0.915 ...\n $ rugged_std  : num [1:170(1d)] 0.138 0.553 0.124 0.125 0.433 ...\n $ cid         : num [1:170(1d)] 1 2 2 2 2 2 2 2 2 1 ...\n $ n_cid       : int 2\n $ rugged_std_c: num [1:170(1d)] -0.0766 0.3376 -0.091 -0.09 0.2184 ...\n $ n           : int 170\n\n\n\n\n9.4.2 Sampling from the posterior.\nHere our model_code_9.1 is just a different version of model_code_8.3 from Section 8.1.3. Since we don’t need the log-likelihood for this chapter, we’ve streamlined this version of the program a bit by removing the transformed parameters and generated quantities. We’ve also taken a cue from McElreath’s code by hardcoding the value 0.215 into the model block, rather than importing the xbar scalar from the data list.\n\nmodel_code_9.1 &lt;- '\ndata {\n  int&lt;lower=1&gt; n;\n  int&lt;lower=1&gt; n_cid;\n  array[n] int cid;\n  vector[n] rugged_std;\n  vector[n] log_gdp_std;\n}\nparameters {\n  vector[n_cid] a;\n  vector[n_cid] b;\n  real&lt;lower=0&gt; sigma;\n}\nmodel {\n  vector[n] mu;\n  mu = a[cid] + b[cid] .* (rugged_std - 0.215);\n  log_gdp_std ~ normal(mu, sigma);\n  \n  a ~ normal(1, 0.1);\n  b ~ normal(0, 0.3);\n  sigma ~ exponential(1);\n}\n'\n\nSample with stan(). Note how we’re following McElreath’s lead by setting chains = 1.\n\nm9.1 &lt;- stan(\n  data = stan_data,\n  model_code = model_code_9.1,\n  chains = 1, seed = 9)\n\nHere is a summary of the posterior.\n\nprint(m9.1, probs = c(0.055, 0.945))\n\nInference for Stan model: anon_model.\n1 chains, each with iter=2000; warmup=1000; thin=1; \npost-warmup draws per chain=1000, total post-warmup draws=1000.\n\n        mean se_mean   sd   5.5%  94.5% n_eff Rhat\na[1]    0.89    0.00 0.02   0.86   0.91  1417    1\na[2]    1.05    0.00 0.01   1.03   1.07  1671    1\nb[1]    0.13    0.00 0.07   0.01   0.25  1208    1\nb[2]   -0.14    0.00 0.06  -0.23  -0.06  1522    1\nsigma   0.11    0.00 0.01   0.10   0.12  1395    1\nlp__  285.32    0.07 1.51 282.70 287.10   499    1\n\nSamples were drawn using NUTS(diag_e) at Wed Aug 14 10:54:09 2024.\nFor each parameter, n_eff is a crude measure of effective sample size,\nand Rhat is the potential scale reduction factor on split chains (at \nconvergence, Rhat=1).\n\n\n\n\n9.4.3 Sampling again, in parallel.\nHere we sample from four HMC chains in parallel by adding cores = 4. Though chains = 4 is the default setting in stan(), here we make it explicit. This time we’ll call the object m9.1b.\n\nm9.1b &lt;- stan(\n  data = stan_data,\n  model_code = model_code_9.1,\n  chains = 4, cores = 4, seed = 9)\n\nHere is a summary of the posterior.\n\nprint(m9.1b, probs = c(0.055, 0.945))\n\nInference for Stan model: anon_model.\n4 chains, each with iter=2000; warmup=1000; thin=1; \npost-warmup draws per chain=1000, total post-warmup draws=4000.\n\n        mean se_mean   sd   5.5%  94.5% n_eff Rhat\na[1]    0.89    0.00 0.02   0.86   0.91  4888    1\na[2]    1.05    0.00 0.01   1.03   1.07  5142    1\nb[1]    0.13    0.00 0.07   0.01   0.25  4317    1\nb[2]   -0.14    0.00 0.06  -0.23  -0.05  5013    1\nsigma   0.11    0.00 0.01   0.10   0.12  5015    1\nlp__  285.22    0.03 1.55 282.27 287.06  2024    1\n\nSamples were drawn using NUTS(diag_e) at Sun Aug 11 17:38:51 2024.\nFor each parameter, n_eff is a crude measure of effective sample size,\nand Rhat is the potential scale reduction factor on split chains (at \nconvergence, Rhat=1).\n\n\nThe show() function does not work for rstan models the same way it does with those from rethinking. Rather, show() returns the same information we’d get from print().\n\nshow(m9.1b)\n\nInference for Stan model: anon_model.\n4 chains, each with iter=2000; warmup=1000; thin=1; \npost-warmup draws per chain=1000, total post-warmup draws=4000.\n\n        mean se_mean   sd   2.5%    25%    50%    75%  97.5% n_eff Rhat\na[1]    0.89    0.00 0.02   0.86   0.88   0.89   0.90   0.92  4888    1\na[2]    1.05    0.00 0.01   1.03   1.04   1.05   1.06   1.07  5142    1\nb[1]    0.13    0.00 0.07  -0.01   0.09   0.13   0.18   0.28  4317    1\nb[2]   -0.14    0.00 0.06  -0.25  -0.18  -0.14  -0.10  -0.03  5013    1\nsigma   0.11    0.00 0.01   0.10   0.11   0.11   0.12   0.12  5015    1\nlp__  285.22    0.03 1.55 281.31 284.49 285.55 286.33 287.25  2024    1\n\nSamples were drawn using NUTS(diag_e) at Sun Aug 11 17:38:51 2024.\nFor each parameter, n_eff is a crude measure of effective sample size,\nand Rhat is the potential scale reduction factor on split chains (at \nconvergence, Rhat=1).\n\n\nYou can get a focused look at the formula and prior information from an rstan fit object by subsetting the stanmodel portion of the object.\n\nm9.1b@stanmodel\n\nS4 class stanmodel 'anon_model' coded as follows:\ndata {\n  int&lt;lower=1&gt; n;\n  int&lt;lower=1&gt; n_cid;\n  int cid[n];\n  vector[n] rugged_std;\n  vector[n] log_gdp_std;\n}\nparameters {\n  vector[n_cid] a;\n  vector[n_cid] b;\n  real&lt;lower=0&gt; sigma;\n}\nmodel {\n  vector[n] mu;\n  mu = a[cid] + b[cid] .* (rugged_std - 0.215);\n  log_gdp_std ~ normal(mu, sigma);\n\n  a ~ normal(1, 0.1);\n  b ~ normal(0, 0.3);\n  sigma ~ exponential(1);\n} \n\n\nYou can also extract that information with the get_stanmodel() function.\n\nget_stanmodel(m9.1b)\n\nS4 class stanmodel 'anon_model' coded as follows:\ndata {\n  int&lt;lower=1&gt; n;\n  int&lt;lower=1&gt; n_cid;\n  int cid[n];\n  vector[n] rugged_std;\n  vector[n] log_gdp_std;\n}\nparameters {\n  vector[n_cid] a;\n  vector[n_cid] b;\n  real&lt;lower=0&gt; sigma;\n}\nmodel {\n  vector[n] mu;\n  mu = a[cid] + b[cid] .* (rugged_std - 0.215);\n  log_gdp_std ~ normal(mu, sigma);\n\n  a ~ normal(1, 0.1);\n  b ~ normal(0, 0.3);\n  sigma ~ exponential(1);\n} \n\n\nYou can use the get_elapsed_time() function to extract the duration in seconds each chain took during the warmup and post-warmup sampling phases. I believe McElreath’s third column total is just the sum of the warmup and sample columns.\n\nget_elapsed_time(m9.1b)\n\n        warmup sample\nchain:1  0.037  0.035\nchain:2  0.038  0.038\nchain:3  0.036  0.034\nchain:4  0.041  0.042\n\n\nAs to the diagnostic statistics, you can compute the \\(\\widehat R\\) and effective-sample-size statistics with the posterior::summarise_draws() function, particularly with the nice helper function called default_convergence_measures().\n\nsummarise_draws(m9.1b, default_convergence_measures())\n\n# A tibble: 6 × 4\n  variable  rhat ess_bulk ess_tail\n  &lt;chr&gt;    &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1 a[1]      1.00    4965.    3126.\n2 a[2]      1.00    5156.    2945.\n3 b[1]      1.00    4359.    3110.\n4 b[2]      1.00    5060.    3140.\n5 sigma     1.00    5115.    2962.\n6 lp__      1.00    1968.    2610.\n\n\n\n\n9.4.4 Visualization.\nAs with McElreath’s rethinking, rstan allows users to put the fit object directly into the pairs() function.\n\npairs(m9.1b)\n\n\n\n\nHowever, pairs() also includes the lp__ and energy in the output. These can be suppressed with the pars argument.\n\npairs(m9.1b, pars = c(\"a\", \"b\", \"sigma\"))\n\n\n\n\nOur output is a little different in that we don’t get a lower-triangle of Pearson’s correlation coefficients. If you’d like those values, use cor() after extracting the desired parameter columns with as_draws_df() and select().\n\nas_draws_df(m9.1b) %&gt;% \n  select(`a[1]`:sigma) %&gt;%\n  cor()\n\n             a[1]        a[2]       b[1]         b[2]       sigma\na[1]  1.000000000  0.01261124 0.19425541  0.009139623  0.01997169\na[2]  0.012611240  1.00000000 0.01059454 -0.080636370  0.03328394\nb[1]  0.194255410  0.01059454 1.00000000  0.028562249  0.01808661\nb[2]  0.009139623 -0.08063637 0.02856225  1.000000000 -0.03518082\nsigma 0.019971693  0.03328394 0.01808661 -0.035180821  1.00000000\n\n\nIf you need to customize a pairs()-type plot much further than this, you’re probably best off moving to a GGally::ggpairs()-based workflow, such as we demonstrate later in Section 12.4.\n\n\n9.4.5 Checking the chain.\nHere we apply the traceplot() to m9.1b. The default settings are inc_warmup = FALSE, which means we need to change that to TRUE if we want to see the warmup draws, like in the plots McElreath tends to show in the text.\n\ntraceplot(m9.1b, inc_warmup = TRUE, pars = c(\"a\", \"b\"))\n\n\n\n\nWe can make similar plots with the mcmc_trace() function from the bayesplot package. Note that mcmc_trace() will accept stan() model objects as direct input, but it will also accept input from as_draws_df(), as in below. As mcmc_trace() returns a ggplot object, you can adjust the plot in the usual way with other functions like theme().\n\nas_draws_df(m9.1b) |&gt;  \n  mcmc_trace(pars = vars(`a[1]`:sigma),\n             facet_args = list(ncol = 3, labeller = label_parsed)) +\n  theme(legend.position = c(0.85, 0.25))\n\n\n\n\nNote however that as the as_draws_df() function only returns post-warmup draws, this workflow will not produce traceplots like the ones in the text that show the warmup portion.\nMcElreath pointed out a second way to visualize the chains is by the distribution of the ranked samples, which he called a trank plot (short for trace rank plot). I’m not aware that rstan has a built-in function for that. We can, however, make them with the mcmc_rank_overlay() function from bayesplot.\n\nas_draws_df(m9.1b) |&gt;  \n  mcmc_rank_overlay(pars = vars(`a[1]`:`b[2]`),\n                    facet_args = list(labeller = label_parsed)) +\n  scale_color_viridis_d(option = \"A\", end = 0.8) +\n  coord_cartesian(ylim = c(20, NA))\n\n\n\n\n\n9.4.5.1 Overthinking: Raw Stan model code."
  },
  {
    "objectID": "09.html#care-and-feeding-of-your-markov-chain",
    "href": "09.html#care-and-feeding-of-your-markov-chain",
    "title": "9  Markov Chain Monte Carlo",
    "section": "9.5 Care and feeding of your Markov chain",
    "text": "9.5 Care and feeding of your Markov chain\n\n9.5.1 How many samples do you need?\n\n9.5.1.1 Rethinking: Warmup is not burn-in.\n\n\n\n9.5.2 How many chains do you need?\n\n9.5.2.1 Rethinking: Convergence diagnostics.\n\n\n\n9.5.3 Taming a wild chain.\nDefine the new very-small stan_data.\n\nstan_data &lt;- tibble(y = c(-1, 1)) |&gt;  \n  compose_data()\n\n# What?\nstr(stan_data)\n\nList of 2\n $ y: num [1:2(1d)] -1 1\n $ n: int 2\n\n\nMake model_code_9.2.\n\nmodel_code_9.2 &lt;- '\ndata {\n  int&lt;lower=1&gt; n;\n  vector[n] y;\n}\nparameters {\n  real alpha;\n  real&lt;lower=0&gt; sigma;\n}\nmodel {\n  y ~ normal(alpha, sigma);\n  alpha ~ normal(0, 1000);\n  sigma ~ exponential(0.0001);\n}\n'\n\nCompile and sample with stan().\n\nm9.2 &lt;- stan(\n  data = stan_data,\n  model_code = model_code_9.2,\n  chains = 3, cores = 3, iter = 1000, seed = 9)\n\nLet’s peek at the summary.\n\nprint(m9.2, probs = c(0.055, 0.945))\n\nInference for Stan model: anon_model.\n3 chains, each with iter=1000; warmup=500; thin=1; \npost-warmup draws per chain=500, total post-warmup draws=1500.\n\n        mean se_mean      sd    5.5%   94.5% n_eff Rhat\nalpha  14.06   22.46  318.49 -412.73  434.61   201 1.00\nsigma 641.08  133.85 1895.96    9.48 2481.00   201 1.01\nlp__   -5.51    0.25    1.91   -8.83   -2.70    56 1.06\n\nSamples were drawn using NUTS(diag_e) at Sun Aug 11 17:39:20 2024.\nFor each parameter, n_eff is a crude measure of effective sample size,\nand Rhat is the potential scale reduction factor on split chains (at \nconvergence, Rhat=1).\n\n\nMuch like in the text, this summary is a disaster. If you actually fit the model in your computer, note the warning about divergent transitions. The nuts_params() function from bayesplot allows use to pull a wealth of diagnostic information. The different kinds of diagnostics are listed in the Parameter column.\n\nnuts_params(m9.2) |&gt; \n  distinct(Parameter)\n\n      Parameter\n1 accept_stat__\n2    stepsize__\n3   treedepth__\n4  n_leapfrog__\n5   divergent__\n6      energy__\n\n\nOur interest is for when Parameter == \"divergent__\".\n\nnuts_params(m9.2) |&gt; \n  filter(Parameter == \"divergent__\") |&gt; \n  count(Value)\n\n  Value    n\n1     0 1286\n2     1  214\n\n\nThis indicates that among the 3,000 post-warmup draws, 214 were classified as divergent transitions.\nHere are the trace and rank plots for m9.2, which make the top two rows of our version of Figure 9.9.\n\n# Trace\np1 &lt;- as_draws_df(m9.2) |&gt;  \n  mcmc_trace(pars = vars(alpha:sigma),\n             facet_args = list(labeller = label_parsed))\n\n# Trank\np2 &lt;- as_draws_df(m9.2) |&gt;  \n  mcmc_rank_overlay(pars = vars(alpha:sigma),\n                    facet_args = list(labeller = label_parsed))\n\n# Combine\n(p1 / p2) & \n  theme(legend.position = \"none\")\n\n\n\n\nOkay, that’s enough disaster. Let’s try a model that adds just a little information by way of weakly-regularizing priors:\n\\[\n\\begin{align*}\ny_i & \\sim \\operatorname{Normal}(\\alpha, \\sigma) \\\\\n\\alpha & \\sim \\operatorname{Normal}(1, 10) \\\\\n\\sigma & \\sim \\operatorname{Exponential}(1).\n\\end{align*}\n\\]\nWatch our new priors save the day.\n\nmodel_code_9.3 &lt;- '\ndata {\n  int&lt;lower=1&gt; n;\n  vector[n] y;\n}\nparameters {\n  real alpha;\n  real&lt;lower=0&gt; sigma;\n}\nmodel {\n  y ~ normal(alpha, sigma);\n  alpha ~ normal(1, 10);\n  sigma ~ exponential(1);\n}\n'\n\nm9.3 &lt;- stan(\n  data = stan_data,\n  model_code = model_code_9.3,\n  chains = 3, cores = 3, iter = 1000, seed = 9)\n\nUnlike in the text, we still got one divergent transition.\n\nnuts_params(m9.3) |&gt; \n  filter(Parameter == \"divergent__\") |&gt; \n  count(Value)\n\n  Value    n\n1     0 1499\n2     1    1\n\n\nHowever, the overall parameter summary looks much better.\n\nprint(m9.3, probs = c(0.055, 0.945))\n\nInference for Stan model: anon_model.\n3 chains, each with iter=1000; warmup=500; thin=1; \npost-warmup draws per chain=500, total post-warmup draws=1500.\n\n       mean se_mean   sd  5.5% 94.5% n_eff Rhat\nalpha -0.01    0.09 1.37 -1.92  1.75   258 1.00\nsigma  1.57    0.05 0.90  0.65  3.16   373 1.00\nlp__  -3.24    0.07 1.27 -5.72 -2.08   315 1.01\n\nSamples were drawn using NUTS(diag_e) at Sun Aug 11 17:39:44 2024.\nFor each parameter, n_eff is a crude measure of effective sample size,\nand Rhat is the potential scale reduction factor on split chains (at \nconvergence, Rhat=1).\n\n\nThe trace and trank plots look better, too. Though frankly, they’re still not great. Don’t try to fit models with 2 data points, friends.\n\n# Trace\np1 &lt;- as_draws_df(m9.3) |&gt;  \n  mcmc_trace(pars = vars(alpha:sigma),\n             facet_args = list(labeller = label_parsed))\n\n# Trank\np2 &lt;- as_draws_df(m9.3) |&gt;  \n  mcmc_rank_overlay(pars = vars(alpha:sigma),\n                    facet_args = list(labeller = label_parsed))\n\n# Combine\n(p1 / p2) & \n  theme(legend.position = \"none\")\n\n\n\n\nNow behold our version of Figure 9.10.\n\ndraws &lt;- as_draws_df(m9.3)\n\n# alpha\np1 &lt;- tibble(alpha = seq(from = -17, to = 17, length.out = 501)) |&gt; \n  mutate(density = dnorm(x = alpha, mean = 1, sd = 10)) |&gt; \n  \n  ggplot(aes(x = alpha)) +\n  geom_area(aes(y = density),\n            fill = \"gray60\") +\n  geom_density(data = draws,\n               adjust = 1/2, alpha = 2/3, fill = \"blue\", linewidth = 0) +\n  annotate(geom = \"text\",\n           x = c(9, 2), y = c(0.05, 0.2),\n           label = c(\"prior\", \"posterior\"),\n           color = c(\"black\", \"blue\"), hjust = 0) +\n  coord_cartesian(xlim = c(-15, 15))\n\n# sigma\np2 &lt;- tibble(sigma = seq(from = 0, to = 12, length.out = 501)) |&gt; \n  mutate(density = dexp(x = sigma, rate = 1)) |&gt; \n  \n  ggplot(aes(x = sigma)) +\n  geom_area(aes(y = density),\n            fill = \"gray60\") +\n  geom_density(data = draws,\n               adjust = 1/2, alpha = 2/3, fill = \"blue\", linewidth = 0) +\n  coord_cartesian(xlim = c(0, 10),\n                  ylim = c(0, 0.75))\n\n# Combine\n(p1 | p2) &\n  scale_y_continuous(NULL, breaks = NULL)\n\n\n\n\n\n9.5.3.1 Rethinking: The folk theorem of statistical computing.\n\n\n9.5.3.2 Overthinking: Divergent transitions are your friend.\n\n\n\n9.5.4 Non-identifiable parameters.\nUpdate the stan_data.\n\nset.seed(41)\n\nstan_data &lt;- tibble(y = rnorm(n = 100, mean = 0, sd = 1)) |&gt;  \n  compose_data()\n\n# What?\nstr(stan_data)\n\nList of 2\n $ y: num [1:100(1d)] -0.794 0.197 1.002 1.289 0.906 ...\n $ n: int 100\n\n\nMake model_code_9.4.\n\nmodel_code_9.4 &lt;- '\ndata {\n  int&lt;lower=1&gt; n;\n  vector[n] y;\n}\nparameters {\n  real a1;\n  real a2;\n  real&lt;lower=0&gt; sigma;\n}\nmodel {\n  y ~ normal(a1 + a2, sigma);\n  [a1, a2] ~ normal(0, 1000);\n  sigma ~ exponential(1);\n}\n'\n\nCompile and sample with stan().\n\nm9.4 &lt;- stan(\n  data = stan_data,\n  model_code = model_code_9.4,\n  chains = 3, cores = 3, iter = 1000, seed = 384)\n\nOur model results don’t perfectly mirror McElreath’s, but they’re right with his in spirit.\n\nprint(m9.4, probs = c(0.055, 0.945))\n\nInference for Stan model: anon_model.\n3 chains, each with iter=1000; warmup=500; thin=1; \npost-warmup draws per chain=500, total post-warmup draws=1500.\n\n         mean se_mean     sd    5.5%  94.5% n_eff Rhat\na1    -369.46  125.64 349.79 -826.49 363.39     8 1.77\na2     369.65  125.64 349.78 -363.14 826.63     8 1.77\nsigma    1.04    0.01   0.07    0.93   1.15    20 1.18\nlp__   -54.48    0.11   1.02  -56.36 -53.48    88 1.05\n\nSamples were drawn using NUTS(diag_e) at Sun Aug 11 17:40:09 2024.\nFor each parameter, n_eff is a crude measure of effective sample size,\nand Rhat is the potential scale reduction factor on split chains (at \nconvergence, Rhat=1).\n\n\nIf you’re following along on your computer, note the frightening warning messages. You can also check the HMC diagnostic messages of a stan() model with the check_hmc_diagnostics() function.\n\ncheck_hmc_diagnostics(m9.4)\n\n\nDivergences:\n\n\n0 of 1500 iterations ended with a divergence.\n\n\n\nTree depth:\n\n\n1198 of 1500 iterations saturated the maximum tree depth of 10 (79.8666666666667%).\nTry increasing 'max_treedepth' to avoid saturation.\n\n\n\nEnergy:\n\n\nE-BFMI indicated no pathological behavior.\n\n\nThose iterations flagged for tree depth are also often called “transitions” in the red warning messages you’ll get at the end of a stan() call. You generally want that number to be zero out of the total draws.\nNow we try again with tighter priors for the \\(\\mu\\) model.\n\nmodel_code_9.5 &lt;- '\ndata {\n  int&lt;lower=1&gt; n;\n  vector[n] y;\n}\nparameters {\n  real a1;\n  real a2;\n  real&lt;lower=0&gt; sigma;\n}\nmodel {\n  y ~ normal(a1 + a2, sigma);\n  [a1, a2] ~ normal(0, 10);  // This is the only change\n  sigma ~ exponential(1);\n}\n'\n\nm9.5 &lt;- stan(\n  data = stan_data,\n  model_code = model_code_9.5,\n  chains = 3, cores = 3, iter = 1000, seed = 384)\n\nHow’d we do?\n\nprint(m9.5, probs = c(0.055, 0.945))\n\nInference for Stan model: anon_model.\n3 chains, each with iter=1000; warmup=500; thin=1; \npost-warmup draws per chain=500, total post-warmup draws=1500.\n\n        mean se_mean   sd   5.5%  94.5% n_eff Rhat\na1      0.21    0.40 6.97 -10.14  11.58   298 1.01\na2     -0.02    0.40 6.97 -11.36  10.34   299 1.01\nsigma   1.03    0.00 0.07   0.92   1.16   449 1.01\nlp__  -54.74    0.06 1.18 -57.01 -53.45   341 1.00\n\nSamples were drawn using NUTS(diag_e) at Sun Aug 11 17:40:33 2024.\nFor each parameter, n_eff is a crude measure of effective sample size,\nand Rhat is the potential scale reduction factor on split chains (at \nconvergence, Rhat=1).\n\n\nThis looks better. How about the check_hmc_diagnostics() output.\n\ncheck_hmc_diagnostics(m9.5)\n\n\nDivergences:\n\n\n0 of 1500 iterations ended with a divergence.\n\n\n\nTree depth:\n\n\n0 of 1500 iterations saturated the maximum tree depth of 10.\n\n\n\nEnergy:\n\n\nE-BFMI indicated no pathological behavior.\n\n\nHooray!\nFinish off the chapter with Figure 9.11.\n\n# m9.4, trace\np1 &lt;- as_draws_df(m9.4) |&gt;  \n  mcmc_trace(pars = vars(a1:sigma),\n             facet_args = list(ncol = 1)) +\n  labs(subtitle = \"m9.4 (wimpy priors)\") +\n  theme(legend.position = \"none\",\n        strip.text = element_blank())\n\n# m9.4, trank\np2 &lt;- as_draws_df(m9.4) |&gt;  \n  mcmc_rank_overlay(pars = vars(a1:sigma),\n                    facet_args = list(ncol = 1, strip.position = \"right\")) +\n  theme(legend.position = \"none\")\n\n# m9.5, trace\np3 &lt;- as_draws_df(m9.5) |&gt;  \n  mcmc_trace(pars = vars(a1:sigma),\n             facet_args = list(ncol = 1)) +\n  labs(subtitle = \"m9.5 (weakly informative priors)\") +\n  theme(legend.position = \"none\",\n        strip.text = element_blank())\n\n# m9.5, trank\np4 &lt;- as_draws_df(m9.5) |&gt;  \n  mcmc_rank_overlay(pars = vars(a1:sigma),\n                    facet_args = list(ncol = 1, strip.position = \"right\")) +\n  theme(legend.position = \"none\")\n\n# Combine, adjust, and display\n((p1 | p2) / (p3 | p4)) &\n  scale_x_continuous(NULL, breaks = NULL) &\n  scale_color_viridis_d(option = \"D\", end = 0.8)\n\n\n\n\n\n9.5.4.1 Rethinking: Hamiltonian warnings and Gibbs overconfidence."
  },
  {
    "objectID": "09.html#summary",
    "href": "09.html#summary",
    "title": "9  Markov Chain Monte Carlo",
    "section": "9.6 Summary",
    "text": "9.6 Summary"
  },
  {
    "objectID": "09.html#session-info",
    "href": "09.html#session-info",
    "title": "9  Markov Chain Monte Carlo",
    "section": "Session info",
    "text": "Session info\n\nsessionInfo()\n\nR version 4.4.0 (2024-04-24)\nPlatform: aarch64-apple-darwin20\nRunning under: macOS Ventura 13.4\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: America/Chicago\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n [1] bayesplot_1.11.1   tidybayes_3.0.6    posterior_1.6.0    rstan_2.32.6      \n [5] StanHeaders_2.32.7 patchwork_1.2.0    lubridate_1.9.3    forcats_1.0.0     \n [9] stringr_1.5.1      dplyr_1.1.4        purrr_1.0.2        readr_2.1.5       \n[13] tidyr_1.3.1        tibble_3.2.1       ggplot2_3.5.1      tidyverse_2.0.0   \n\nloaded via a namespace (and not attached):\n [1] gtable_0.3.5         tensorA_0.36.2.1     xfun_0.43           \n [4] QuickJSR_1.1.3       htmlwidgets_1.6.4    inline_0.3.19       \n [7] lattice_0.22-6       tzdb_0.4.0           vctrs_0.6.5         \n[10] tools_4.4.0          generics_0.1.3       stats4_4.4.0        \n[13] curl_5.2.1           parallel_4.4.0       fansi_1.0.6         \n[16] pkgconfig_2.0.3      KernSmooth_2.23-22   Matrix_1.7-0        \n[19] checkmate_2.3.1      distributional_0.4.0 RcppParallel_5.1.7  \n[22] lifecycle_1.0.4      farver_2.1.1         compiler_4.4.0      \n[25] munsell_0.5.1        codetools_0.2-20     htmltools_0.5.8.1   \n[28] yaml_2.3.8           pillar_1.9.0         arrayhelpers_1.1-0  \n[31] abind_1.4-5          tidyselect_1.2.1     digest_0.6.35       \n[34] svUnit_1.0.6         stringi_1.8.4        reshape2_1.4.4      \n[37] labeling_0.4.3       fastmap_1.1.1        grid_4.4.0          \n[40] colorspace_2.1-0     cli_3.6.3            magrittr_2.0.3      \n[43] loo_2.8.0            pkgbuild_1.4.4       utf8_1.2.4          \n[46] withr_3.0.0          scales_1.3.0         backports_1.5.0     \n[49] timechange_0.3.0     rmarkdown_2.26       matrixStats_1.3.0   \n[52] gridExtra_2.3        hms_1.1.3            coda_0.19-4.1       \n[55] evaluate_0.23        knitr_1.46           ggdist_3.3.2        \n[58] V8_4.4.2             viridisLite_0.4.2    rlang_1.1.4         \n[61] Rcpp_1.0.12          glue_1.7.0           rstudioapi_0.16.0   \n[64] jsonlite_1.8.8       plyr_1.8.9           R6_2.5.1"
  },
  {
    "objectID": "09.html#comments",
    "href": "09.html#comments",
    "title": "9  Markov Chain Monte Carlo",
    "section": "Comments",
    "text": "Comments"
  },
  {
    "objectID": "10.html#session-info",
    "href": "10.html#session-info",
    "title": "10  Big Entropy and the Generalized Linear Model",
    "section": "Session info",
    "text": "Session info\n\nsessionInfo()\n\nR version 4.4.0 (2024-04-24)\nPlatform: aarch64-apple-darwin20\nRunning under: macOS Ventura 13.4\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: America/Chicago\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] assertthat_0.2.1  digest_0.6.35     R6_2.5.1          fastmap_1.1.1    \n [5] xfun_0.43         magrittr_2.0.3    glue_1.7.0        stringr_1.5.1    \n [9] knitr_1.46        htmltools_0.5.8.1 rmarkdown_2.26    lifecycle_1.0.4  \n[13] cli_3.6.3         vctrs_0.6.5       compiler_4.4.0    httr_1.4.7       \n[17] vembedr_0.1.5     rstudioapi_0.16.0 tools_4.4.0       curl_5.2.1       \n[21] evaluate_0.23     yaml_2.3.8        rlang_1.1.4       jsonlite_1.8.8   \n[25] htmlwidgets_1.6.4 stringi_1.8.4"
  },
  {
    "objectID": "10.html#comments",
    "href": "10.html#comments",
    "title": "10  Big Entropy and the Generalized Linear Model",
    "section": "Comments",
    "text": "Comments"
  },
  {
    "objectID": "11.html#binomial-regression",
    "href": "11.html#binomial-regression",
    "title": "11  God Spiked the Integers",
    "section": "11.1 Binomial regression",
    "text": "11.1 Binomial regression\n\n11.1.1 Logistic regression: Prosocial chimpanzees.\nLoad the Silk et al. (2005) chimpanzees data.\n\ndata(chimpanzees, package = \"rethinking\")\nd &lt;- chimpanzees\nrm(chimpanzees)\n\nMake the index variable treatment, a variant of which we’ll be saving as a factor with labeled levels named labels.\n\nd &lt;- d |&gt; \n  mutate(treatment = factor(1 + prosoc_left + 2 * condition)) |&gt; \n  # This will come in handy, later\n  mutate(labels = factor(treatment,\n                         levels = 1:4,\n                         labels = c(\"r/n\", \"l/n\", \"r/p\", \"l/p\")))\n\nWe can use the count() function to get a sense of the distribution of the conditions in the data.\n\nd |&gt; \n  count(prosoc_left, condition, treatment, labels)\n\n  prosoc_left condition treatment labels   n\n1           0         0         1    r/n 126\n2           0         1         3    r/p 126\n3           1         0         2    l/n 126\n4           1         1         4    l/p 126\n\n\nWe start with the simple intercept-only logistic regression model, which follows the statistical formula\n\\[\n\\begin{align*}\n\\text{pulled-left}_i & \\sim \\operatorname{Binomial}(1, p_i) \\\\\n\\operatorname{logit}(p_i) & = \\alpha \\\\\n\\alpha & \\sim \\operatorname{Normal}(0, w),\n\\end{align*}\n\\]\nwhere \\(w\\) is the hyperparameter for \\(\\sigma\\) the value for which we have yet to choose.\nMake the stan_data with the compose_data() function.\n\n# Make a data set for predictions\nd_pred &lt;- d |&gt; \n  distinct(actor, prosoc_left, condition, treatment, labels)\n\n# print(d_pred)\n\n# Make the primary data list\nstan_data &lt;- d |&gt; \n  select(actor, treatment, pulled_left) |&gt; \n  compose_data(\n  n_actor = n_distinct(actor),\n  n_treatment = n_distinct(treatment),\n  # For predictions\n  n_pred = nrow(d_pred),\n  pred_actor = d_pred$actor,\n  pred_treatment = d_pred$treatment)\n\n# What?\nstr(stan_data)\n\nList of 10\n $ actor           : int [1:504(1d)] 1 1 1 1 1 1 1 1 1 1 ...\n $ treatment       : num [1:504(1d)] 1 1 2 1 2 2 2 2 1 1 ...\n $ n_treatment     : int 4\n $ pulled_left     : int [1:504(1d)] 0 1 0 0 1 1 0 0 0 0 ...\n $ n               : int 504\n $ n_actor         : int 7\n $ n_pred          : int 28\n $ pred_actor      : int [1:28] 1 1 1 1 2 2 2 2 3 3 ...\n $ pred_treatment  : num [1:28] 1 2 3 4 2 1 3 4 1 2 ...\n $ n_pred_treatment: int 4\n\n\nDefine and sample from the initial program for the prior simulations.\n\nmodel_code_11.1 &lt;- '\ndata {\n  int&lt;lower=1&gt; n;                       \n  array[n] int&lt;lower=0, upper=1&gt; pulled_left;\n}\nparameters {\n  real a;\n}\nmodel {\n  // pulled_left ~ binomial(1, inv_logit(a));\n  a ~ normal(0, 10);\n}\n'\n\nm11.1 &lt;- stan(\n  model_code = model_code_11.1, \n  data = stan_data,\n  cores = 4, seed = 11)\n\nHere’s Figure 11.3.a.\n\nset.seed(11)\n\np1 &lt;- data.frame(a = c(\n  as_draws_df(m11.1) |&gt; pull(a),\n  rnorm(n = 4e3, mean = 0, sd = 1.5))) |&gt; \n  mutate(p = plogis(a),\n         omega = rep(c(10, 1.5), each = n() / 2) |&gt; \n           as.character()) |&gt; \n  \n  ggplot(aes(x = p, color = omega, fill = omega)) +\n  geom_density(adjust = 1/10, alpha = 1/2) +\n  scale_color_discrete(expression(omega)) +\n  scale_fill_discrete(expression(omega)) +\n  labs(x = expression(italic(p)),\n       subtitle = expression(\"a ~ Normal(0, \"*omega*\")\"))\n\n# What?\np1\n\n\n\n\nHere we make the model_code for m11.2, and compile the prior predictive distribution with stan().\n\nmodel_code_11.2 &lt;- '\ndata {\n  int&lt;lower=1&gt; n;                       \n  int&lt;lower=1&gt; n_treatment;\n  vector[n] treatment;\n  array[n] int&lt;lower=0, upper=1&gt; pulled_left;\n}\nparameters {\n  real a;\n  vector[n_treatment] b;\n}\nmodel {\n  // pulled_left ~ binomial(1, inv_logit(a + b[treatment]));\n  a ~ normal(0, 1.5);\n  b ~ normal(0, 10);\n}\n'\n\nm11.2 &lt;- stan(\n  model_code = model_code_11.2, \n  data = stan_data,\n  cores = 4, seed = 11)\n\nNote that this model would typically have identification issues. But since we’re just sampling from the prior, it isn’t an issue for now.\nHere’s m11.3, which is also just for prior-predictive draws, but this time using \\(\\beta_{[1:4]} \\sim \\mathcal N(0, 0.5)\\).\n\nmodel_code_11.3 &lt;- '\ndata {\n  int&lt;lower=1&gt; n;                       \n  int&lt;lower=1&gt; n_treatment;\n  vector[n] treatment;\n  array[n] int&lt;lower=0, upper=1&gt; pulled_left;\n}\nparameters {\n  real a;\n  vector[n_treatment] b;\n}\nmodel {\n  // pulled_left ~ binomial(1, inv_logit(a + b[n_treatment]));\n  a ~ normal(0, 1.5);\n  b ~ normal(0, 0.5);  // This is the only new part\n}\n'\n\nm11.3 &lt;- stan(\n  model_code = model_code_11.3, \n  data = stan_data,\n  cores = 4, seed = 11)\n\nHere we compute the probability difference estimand \\(p_1 - p_2\\) from the prior predictive distribution of m11.2 and m11.3, and save the results as prior_m11.2_df and prior_m11.3_df.\n\nprior_m11.2_df &lt;- m11.2 |&gt; \n  spread_draws(a, b[treatment]) |&gt; \n  filter(treatment &lt; 3) |&gt; \n  mutate(p = plogis(a + b)) |&gt; \n  compare_levels(p, by = treatment)\n\nprior_m11.3_df &lt;- m11.3 |&gt; \n  spread_draws(a, b[treatment]) |&gt; \n  filter(treatment &lt; 3) |&gt; \n  mutate(p = plogis(a + b)) |&gt; \n  compare_levels(p, by = treatment)\n\n# What?\nhead(prior_m11.2_df)\n\n# A tibble: 6 × 5\n# Groups:   treatment [1]\n  .chain .iteration .draw treatment        p\n   &lt;int&gt;      &lt;int&gt; &lt;int&gt; &lt;chr&gt;        &lt;dbl&gt;\n1      1          1     1 2 - 1     -0.0357 \n2      1          2     2 2 - 1     -0.831  \n3      1          3     3 2 - 1     -1.00   \n4      1          4     4 2 - 1     -0.00966\n5      1          5     5 2 - 1     -1.00   \n6      1          6     6 2 - 1     -1.00   \n\nhead(prior_m11.3_df)\n\n# A tibble: 6 × 5\n# Groups:   treatment [1]\n  .chain .iteration .draw treatment       p\n   &lt;int&gt;      &lt;int&gt; &lt;int&gt; &lt;chr&gt;       &lt;dbl&gt;\n1      1          1     1 2 - 1     -0.147 \n2      1          2     2 2 - 1      0.385 \n3      1          3     3 2 - 1     -0.311 \n4      1          4     4 2 - 1     -0.0233\n5      1          5     5 2 - 1     -0.301 \n6      1          6     6 2 - 1      0.0159\n\n\nNow we combine the two to make Figure 11.3.b.\n\np2 &lt;- bind_rows(prior_m11.2_df, prior_m11.3_df) |&gt; \n  mutate(psi = rep(c(10, 0.5), each = n() / 2) |&gt; \n           as.character()) |&gt; \n  \n  ggplot(aes(x = abs(p), color = psi, fill = psi)) +\n  geom_density(adjust = 1/10, alpha = 1/2) +\n  scale_color_discrete(expression(psi)) +\n  scale_fill_discrete(expression(psi)) +\n  labs(x = expression(abs(italic(p)[1]-italic(p)[2])),\n       subtitle = expression(\"b ~ Normal(0, \"*psi*\")\"))\n\n# Combine\np1 | p2\n\n\n\n\nThe average absolute prior difference is about 0.1, very similar to McElreath’s value from R code 11.9.\n\nprior_m11.3_df |&gt; \n  ungroup() |&gt; \n  summarise(mean = abs(p) |&gt; mean())\n\n# A tibble: 1 × 1\n    mean\n   &lt;dbl&gt;\n1 0.0963\n\n\nThe full model follows the form\n\\[\n\\begin{align*}\n\\text{pulled-left}_i      & \\sim \\operatorname{Binomial}(1, p_i) \\\\\n\\operatorname{logit}(p_i) & = \\alpha_{\\text{actor}[i]} + \\beta_{\\text{treatment}[i]} \\\\\n\\alpha_j & \\sim \\operatorname{Normal}(0, 1.5) \\\\\n\\beta_k  & \\sim \\operatorname{Normal}(0, 0.5),\n\\end{align*}\n\\]\nwhere we now have four levels of \\(\\alpha_j\\), and seven levels of \\(\\beta_k\\). We’ll call this model m11.4, and this time we actually sample from the posterior. In the generated quantities block, we’re defining a vector of predicted values p, as well as the log_lik values for information criteria.\n\nmodel_code_11.4 &lt;- '\ndata {\n  int&lt;lower=1&gt; n;                       \n  int&lt;lower=1&gt; n_actor;\n  int&lt;lower=1&gt; n_treatment;\n  int&lt;lower=1&gt; n_pred;\n  array[n] int actor;\n  array[n] int treatment;\n  array[n_pred] int pred_actor;\n  array[n_pred] int pred_treatment;\n  array[n] int&lt;lower=0, upper=1&gt; pulled_left;\n}\nparameters {\n  vector[n_actor] a;\n  vector[n_treatment] b;\n}\nmodel {\n  pulled_left ~ binomial(1, inv_logit(a[actor] + b[treatment]));\n  a ~ normal(0, 1.5);\n  b ~ normal(0, 0.5);\n}\ngenerated quantities {\n  vector[n_pred] p;\n  vector[n] log_lik;\n  \n  p = inv_logit(a[pred_actor] + b[pred_treatment]);\n  for (i in 1:n) log_lik[i] = binomial_lpmf(pulled_left[i] | 1, inv_logit(a[actor[i]] + b[treatment[i]]));\n}\n'\n\nm11.4 &lt;- stan(\n  model_code = model_code_11.4, \n  data = stan_data,\n  cores = 4, seed = 11)\n\nCheck the model summary.\n\nprint(m11.4, pars = c(\"a\", \"b\"), probs = c(0.055, 0.945))\n\nInference for Stan model: anon_model.\n4 chains, each with iter=2000; warmup=1000; thin=1; \npost-warmup draws per chain=1000, total post-warmup draws=4000.\n\n      mean se_mean   sd  5.5% 94.5% n_eff Rhat\na[1] -0.45    0.01 0.32 -0.96  0.07  1195    1\na[2]  3.90    0.01 0.77  2.75  5.20  2919    1\na[3] -0.75    0.01 0.34 -1.29 -0.21  1232    1\na[4] -0.75    0.01 0.34 -1.28 -0.20  1248    1\na[5] -0.45    0.01 0.33 -0.97  0.08  1176    1\na[6]  0.47    0.01 0.33 -0.04  1.02  1115    1\na[7]  1.96    0.01 0.41  1.31  2.64  1412    1\nb[1] -0.04    0.01 0.29 -0.50  0.43   954    1\nb[2]  0.48    0.01 0.29  0.02  0.93  1038    1\nb[3] -0.38    0.01 0.29 -0.85  0.06  1033    1\nb[4]  0.37    0.01 0.29 -0.09  0.82  1100    1\n\nSamples were drawn using NUTS(diag_e) at Thu Aug 15 11:27:49 2024.\nFor each parameter, n_eff is a crude measure of effective sample size,\nand Rhat is the potential scale reduction factor on split chains (at \nconvergence, Rhat=1).\n\n\nHere’s the coefficient plot for the intercepts, transformed onto the probability scale.\n\nm11.4 |&gt; \n  spread_draws(a[j]) |&gt; \n  mutate(j = factor(j, levels = 7:1)) |&gt; \n  \n  ggplot(aes(x = plogis(a), y = j)) +\n  stat_pointinterval(point_interval = mean_qi, .width = 0.89, \n                     linewidth = 1, shape = 1) +\n  xlim(0:1) +\n  ylab(expression(italic(j)))\n\n\n\n\nHere’s the coefficient plot for the treatment parameters, on the log-odds scale.\n\nm11.4 |&gt; \n  spread_draws(b[k]) |&gt; \n  left_join(d |&gt; \n              distinct(treatment, labels) |&gt; \n              mutate(k = as.integer(treatment)),\n            by = join_by(k)) |&gt;\n  mutate(labels = fct_rev(labels)) |&gt; \n  \n  ggplot(aes(x = b, y = labels)) +\n  stat_pointinterval(point_interval = mean_qi, .width = 0.89, \n                     linewidth = 1, shape = 1) +\n  ylab(NULL)\n\n\n\n\nHere are the two contrasts.\n\nm11.4 |&gt; \n  spread_draws(b[k]) |&gt; \n  pivot_wider(names_from = k, values_from = b) |&gt; \n  mutate(db13 = `1` - `3`,\n         db24 = `2` - `4`) |&gt; \n  pivot_longer(starts_with(\"db\")) |&gt; \n  mutate(name = fct_rev(name)) |&gt; \n  \n  ggplot(aes(x = value, y = name)) +\n  stat_pointinterval(point_interval = mean_qi, .width = 0.89, \n                     linewidth = 1, shape = 1) +\n  ylab(NULL)\n\n\n\n\nNext, we prepare for the posterior predictive check. McElreath showed how to compute empirical proportions by the levels of actor and treatment with the by() function. Our approach will be with a combination of group_by() and summarise(). Here’s what that looks like for actor == 1.\n\nd |&gt;\n  group_by(actor, treatment) |&gt;\n  summarise(proportion = mean(pulled_left)) |&gt; \n  filter(actor == 1)\n\n# A tibble: 4 × 3\n# Groups:   actor [1]\n  actor treatment proportion\n  &lt;int&gt; &lt;fct&gt;          &lt;dbl&gt;\n1     1 1              0.333\n2     1 2              0.5  \n3     1 3              0.278\n4     1 4              0.556\n\n\nNow we’ll follow that through to make the top panel of Figure 11.4.\n\n# Wrangle\np1 &lt;- d |&gt;\n  group_by(actor, treatment) |&gt;\n  summarise(p = mean(pulled_left)) |&gt; \n  left_join(d |&gt; distinct(actor, treatment, labels, condition, prosoc_left),\n            by = c(\"actor\", \"treatment\")) |&gt; \n  mutate(actor = str_c(\"actor \", actor),\n         condition = factor(condition)) |&gt; \n  \n  # Plot\n  ggplot(aes(x = labels, y = p)) +\n  geom_hline(yintercept = 0.5, color = \"white\") +\n  geom_line(aes(group = prosoc_left),\n            linewidth = 1/4) +\n  geom_point(aes(color = condition),\n             size = 2.5, show.legend = F) + \n  scale_x_discrete(NULL, breaks = NULL) +\n  facet_grid(\"observed proportions\" ~ actor)\n  \n# Display\np1\n\n\n\n\nMake the bottom panel of Figure 11.4. Note how we’re using our p parameters for this plow, which we defined in the generated quantities block, above.\n\n# Wrangle\np2 &lt;- m11.4 |&gt; \n  spread_draws(p[i]) |&gt; \n  left_join(d_pred |&gt; \n              mutate(i = 1:n()),\n            by = join_by(i)) |&gt; \n  mutate(actor = str_c(\"actor \", actor),\n         condition = factor(condition)) |&gt; \n  group_by(actor, prosoc_left, condition, treatment, labels) |&gt; \n  mean_qi(p, .width = 0.89) |&gt; \n  \n  # Plot\n  ggplot(aes(x = labels, y = p)) +\n  geom_hline(yintercept = .5, color = \"white\") +\n  geom_line(aes(group = prosoc_left),\n            linewidth = 1/4) +\n  geom_pointinterval(aes(ymin = .lower, ymax = .upper, fill = condition),\n                     linewidth = 1, shape = 21) +\n  scale_fill_discrete(breaks = NULL) +\n  facet_grid(\"posterior predictions\" ~ actor) +\n  theme(strip.text.x = element_blank())\n\n# Display\np2\n\n\n\n\nCombine the two panels to make the full Figure 11.4.\n\n(p1 / p2) &\n  scale_y_continuous(\"proportion left lever\", \n                     breaks = 0:2 / 2, limits = 0:1)\n\n\n\n\nLet’s make two more index variables.\n\nd &lt;- d |&gt; \n  mutate(side = prosoc_left + 1,  # right 1, left 2\n         cond = condition + 1)    # no partner 1, partner 2\n\n# What?\nd |&gt; \n  distinct(prosoc_left, condition, side, cond)\n\n  prosoc_left condition side cond\n1           0         0    1    1\n2           1         0    2    1\n3           0         1    1    2\n4           1         1    2    2\n\n\nUpdate the stan_data.\n\nstan_data &lt;- d |&gt; \n  select(actor, side, cond, pulled_left) |&gt; \n  compose_data(\n  n_actor = n_distinct(actor),\n  n_side = n_distinct(side),\n  n_cond = n_distinct(cond))\n\n# What?\nstr(stan_data)\n\nList of 8\n $ actor      : int [1:504(1d)] 1 1 1 1 1 1 1 1 1 1 ...\n $ side       : num [1:504(1d)] 1 1 2 1 2 2 2 2 1 1 ...\n $ cond       : num [1:504(1d)] 1 1 1 1 1 1 1 1 1 1 ...\n $ pulled_left: int [1:504(1d)] 0 1 0 0 1 1 0 0 0 0 ...\n $ n          : int 504\n $ n_actor    : int 7\n $ n_side     : int 2\n $ n_cond     : int 2\n\n\nDefine the new model_code and fit m11.5. Note how this time we’re defining the log likelihood values in the generated quantities block with binomial_lpmf().\n\nmodel_code_11.5 &lt;- '\ndata {\n  int&lt;lower=1&gt; n;                       \n  int&lt;lower=1&gt; n_actor;\n  int&lt;lower=1&gt; n_side;\n  int&lt;lower=1&gt; n_cond;\n  array[n] int actor;\n  array[n] int side;\n  array[n] int cond;\n  array[n] int&lt;lower=0, upper=1&gt; pulled_left;\n}\nparameters {\n  vector[n_actor] a;\n  vector[n_side] b1;\n  vector[n_cond] b2;\n}\nmodel {\n  pulled_left ~ binomial(1, inv_logit(a[actor] + b1[side] + b2[cond]));\n  a ~ normal(0, 1.5);\n  b1 ~ normal(0, 0.5);\n  b2 ~ normal(0, 0.5);\n}\ngenerated quantities {\n  vector[n] eta;  // To simplify the `log_lik` code\n  vector[n] log_lik;\n  \n  eta = a[actor] + b1[side] + b2[cond];\n  for (i in 1:n) log_lik[i] = binomial_lpmf(pulled_left[i] | 1, inv_logit(eta[i]));\n  \n  // This also works for the `log_lik`, and it negates the need for `eta` from above\n  // for (i in 1:n) log_lik[i] = binomial_lpmf(pulled_left[i] | 1, inv_logit(a[actor[i]] + b1[side[i]] + b2[cond[i]]));\n}\n'\n\nm11.5 &lt;- stan(\n  model_code = model_code_11.5, \n  data = stan_data,\n  cores = 4, seed = 11)\n\nCheck the model summary.\n\nprint(m11.5, pars = c(\"a\", \"b1\", \"b2\"), probs = c(0.055, 0.945))\n\nInference for Stan model: anon_model.\n4 chains, each with iter=2000; warmup=1000; thin=1; \npost-warmup draws per chain=1000, total post-warmup draws=4000.\n\n       mean se_mean   sd  5.5% 94.5% n_eff Rhat\na[1]  -0.64    0.01 0.44 -1.35  0.06  1204    1\na[2]   3.72    0.02 0.80  2.54  5.06  1890    1\na[3]  -0.95    0.01 0.44 -1.65 -0.25  1208    1\na[4]  -0.95    0.01 0.45 -1.68 -0.24  1229    1\na[5]  -0.64    0.01 0.44 -1.33  0.06  1158    1\na[6]   0.29    0.01 0.45 -0.44  1.01  1212    1\na[7]   1.77    0.01 0.51  0.95  2.61  1444    1\nb1[1] -0.20    0.01 0.33 -0.72  0.33  1454    1\nb1[2]  0.49    0.01 0.33 -0.01  1.03  1456    1\nb2[1]  0.28    0.01 0.33 -0.25  0.81  1291    1\nb2[2]  0.03    0.01 0.34 -0.50  0.57  1289    1\n\nSamples were drawn using NUTS(diag_e) at Thu Aug 15 11:29:50 2024.\nFor each parameter, n_eff is a crude measure of effective sample size,\nand Rhat is the potential scale reduction factor on split chains (at \nconvergence, Rhat=1).\n\n\nCompare the two models by the LOO with the extract_log_lik() and loo_compare() functions.\n\nloo_compare(\n  extract_log_lik(m11.4) |&gt; loo(),\n  extract_log_lik(m11.5) |&gt; loo()\n) |&gt; \n  print(simplify = FALSE)\n\n       elpd_diff se_diff elpd_loo se_elpd_loo p_loo  se_p_loo looic  se_looic\nmodel2    0.0       0.0  -265.5      9.6         7.9    0.4    531.0   19.2  \nmodel1   -0.4       0.7  -265.9      9.5         8.3    0.4    531.8   18.9  \n\n\n\n11.1.1.1 Overthinking: Adding log-probability calculations to a Stan model.\nWe did this with m11.5, above.\n\n\n\n11.1.2 Relative shark and absolute deer.\nBased on the full model, m11.4, here’s how you might compute the posterior mean and 89% intervals for the proportional odds of switching from treatment == 2 to treatment == 4.\n\nas_draws_df(m11.4) |&gt; \n  mutate(proportional_odds = exp(`b[4]` - `b[2]`)) |&gt; \n  mean_qi(proportional_odds, .width = 0.89)\n\n# A tibble: 1 × 6\n  proportional_odds .lower .upper .width .point .interval\n              &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;    \n1             0.929  0.574   1.39   0.89 mean   qi       \n\n\nA limitation of relative measures measures like proportional odds is they ignore what you might think of as the reference or the baseline.\n\n11.1.2.1 Overthinking: Proportional odds and relative risk.\n\n\n\n11.1.3 Aggregated binomial: Chimpanzees again, condensed.\nWith the tidyverse, we can use group_by() and summarise() to achieve what McElreath did with aggregate().\n\nd_aggregated &lt;- d |&gt;\n  group_by(treatment, actor, side, cond) |&gt;\n  summarise(left_pulls = sum(pulled_left)) |&gt; \n  ungroup()\n\n# What?\nd_aggregated |&gt;\n  head(n = 10)\n\n# A tibble: 10 × 5\n   treatment actor  side  cond left_pulls\n   &lt;fct&gt;     &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt;      &lt;int&gt;\n 1 1             1     1     1          6\n 2 1             2     1     1         18\n 3 1             3     1     1          5\n 4 1             4     1     1          6\n 5 1             5     1     1          6\n 6 1             6     1     1         14\n 7 1             7     1     1         14\n 8 2             1     2     1          9\n 9 2             2     2     1         18\n10 2             3     2     1         11\n\n\nUpdate the stan_data for the new d_aggregated format.\n\nstan_data &lt;- d_aggregated |&gt; \n  compose_data(n_actor = n_distinct(d_aggregated$actor))\n\n# What?\nstr(stan_data)\n\nList of 8\n $ treatment  : num [1:28(1d)] 1 1 1 1 1 1 1 2 2 2 ...\n $ n_treatment: int 4\n $ actor      : int [1:28(1d)] 1 2 3 4 5 6 7 1 2 3 ...\n $ side       : num [1:28(1d)] 1 1 1 1 1 1 1 2 2 2 ...\n $ cond       : num [1:28(1d)] 1 1 1 1 1 1 1 1 1 1 ...\n $ left_pulls : int [1:28(1d)] 6 18 5 6 6 14 14 9 18 11 ...\n $ n          : int 28\n $ n_actor    : int 7\n\n\nDefine model_code_11.6 and fit the model.\n\nmodel_code_11.6 &lt;- '\ndata {\n  int&lt;lower=1&gt; n;\n  int&lt;lower=1&gt; n_actor;\n  int&lt;lower=1&gt; n_treatment;\n  array[n] int treatment;\n  array[n] int actor;\n  array[n] int&lt;lower=0, upper=18&gt; left_pulls;\n}\nparameters {\n  vector[n_actor] a;\n  vector[n_treatment] b;\n}\nmodel {\n  left_pulls ~ binomial(18, inv_logit(a[actor] + b[treatment]));\n  a ~ normal(0, 1.5);\n  b ~ normal(0, 0.5);\n}\ngenerated quantities {\n  vector[n] eta;\n  vector[n] log_lik;\n  eta = a[actor] + b[treatment];\n  for (i in 1:n) log_lik[i] = binomial_lpmf(left_pulls[i] | 18, inv_logit(eta[i]));\n}\n'\n\nm11.6 &lt;- stan(\n  model_code = model_code_11.6, \n  data = stan_data,\n  cores = 4, seed = 11)\n\nRather than the typical print() summary, here we’ll compare the a and b parameters in this aggregated binomial model m11.6 with its disaggregated version m11.4 in a coefficient plot.\n\nbind_rows(\n  as_draws_df(m11.4) |&gt; \n    select(.draw, `a[1]`:`b[4]`) ,\n  as_draws_df(m11.6) |&gt; \n    select(.draw, `a[1]`:`b[4]`) \n) |&gt; \n  mutate(type = rep(c(\"disaggregated\", \"aggregated\"), each = n() / 2)) |&gt; \n  pivot_longer(`a[1]`:`b[4]`) |&gt; \n  mutate(class = str_extract(name, \"\\\\w\")) |&gt; \n  \n  ggplot(aes(x = value, y = name,\n             color = type)) +\n  stat_pointinterval(.width = 0.89, linewidth = 1, shape = 1,\n                     position = position_dodge(width = -0.5)) +\n  scale_y_discrete(NULL, labels = ggplot2:::parse_safe) +\n  xlab(\"posterior\") +\n  facet_wrap(~ class, scales = \"free\")\n\n\n\n\nDifferent version of the likelihood, same model. Feed the extract_log_lik() results into loo(), and save output as loo_m11.6.\n\nloo_m11.6 &lt;- extract_log_lik(m11.6) |&gt;\n  loo()\n\nWarning: Some Pareto k diagnostic values are too high. See help('pareto-k-diagnostic') for details.\n\n# What?\nprint(loo_m11.6)\n\n\nComputed from 4000 by 28 log-likelihood matrix.\n\n         Estimate  SE\nelpd_loo    -57.1 4.2\np_loo         8.4 1.5\nlooic       114.1 8.4\n------\nMCSE of elpd_loo is NA.\nMCSE and ESS estimates assume independent draws (r_eff=1).\n\nPareto k diagnostic values:\n                         Count Pct.    Min. ESS\n(-Inf, 0.7]   (good)     27    96.4%   407     \n   (0.7, 1]   (bad)       1     3.6%   &lt;NA&gt;    \n   (1, Inf)   (very bad)  0     0.0%   &lt;NA&gt;    \nSee help('pareto-k-diagnostic') for details.\n\n\nUnlike with McElreath’s compare() code in the text, the loo::loo_compare() will not let us directly compare the two versions of the model. I’m going to supress the output, but if you execute this code on your computer, you’ll see it returns a warning.\n\nloo_compare(\n  extract_log_lik(m11.4) |&gt; loo(),\n  loo_m11.6\n) |&gt; \n  print(simplify = FALSE)\n\nTo understand what’s going on, consider how you might describe six 1’s out of nine trials in the aggregated form,\n\\[\\Pr(6|9, p) = \\frac{6!}{6!(9 - 6)!} p^6 (1 - p)^{9 - 6}.\\]\nIf we still stick with the same data, but this time re-express those as nine dichotomous data points, we now describe their joint probability as\n\\[\\Pr(1, 1, 1, 1, 1, 1, 0, 0, 0 \\mid p) = p^6 (1 - p)^{9 - 6}.\\]\nLet’s work this out in code.\n\n# Deviance of aggregated 6-in-9 \n-2 * dbinom(6, size = 9, prob = 0.2, log = TRUE)\n\n[1] 11.79048\n\n# Deviance of dis-aggregated \n-2 * sum(dbinom(c(1, 1, 1, 1, 1, 1, 0, 0, 0), size = 1, prob = 0.2, log = TRUE))\n\n[1] 20.65212\n\n\n\nBut this difference is entirely meaningless. It is just a side effect of how we organized the data. The posterior distribution for the probability of success on each trial will end up the same, either way. (p. 339)\n\nThis is what our coefficient plot showed us, above. The posterior distribution was the same within simulation variance for m11.4 and m11.6. Just like McElreath reported in the text, we also got a warning about high Pareto \\(k\\) values from the aggregated binomial model, m11.6. To access the message and its associated table directly, we can feed our loo_m11.6 object into the loo::pareto_k_table function.\n\nloo_m11.6 |&gt; \n  loo::pareto_k_table()\n\nPareto k diagnostic values:\n                         Count Pct.    Min. ESS\n(-Inf, 0.7]   (good)     27    96.4%   407     \n   (0.7, 1]   (bad)       1     3.6%   &lt;NA&gt;    \n   (1, Inf)   (very bad)  0     0.0%   &lt;NA&gt;    \n\n\n\n\n11.1.4 Aggregated binomial: Graduate school admissions.\nLoad the infamous UCBadmit data.\n\ndata(UCBadmit, package = \"rethinking\")\nd &lt;- UCBadmit\nrm(UCBadmit)\n\n# What?\nprint(d)\n\n   dept applicant.gender admit reject applications\n1     A             male   512    313          825\n2     A           female    89     19          108\n3     B             male   353    207          560\n4     B           female    17      8           25\n5     C             male   120    205          325\n6     C           female   202    391          593\n7     D             male   138    279          417\n8     D           female   131    244          375\n9     E             male    53    138          191\n10    E           female    94    299          393\n11    F             male    22    351          373\n12    F           female    24    317          341\n\n\nNow compute our new index variable, gid. Notice that if we save gid as a factor, the compose_data() a couple blocks below will automatically compute n_gid. We’ll also slip in a case variable that saves the row numbers as a factor, which will come in handy later when we plot.\n\nd &lt;- d |&gt;  \n  mutate(gid  = ifelse(applicant.gender == \"male\", 1, 2) |&gt; factor(),\n         case = 1:n() |&gt; factor())\n\n# What?\nd |&gt; \n  distinct(applicant.gender, gid)\n\n  applicant.gender gid\n1             male   1\n2           female   2\n\n\nThe univariable logistic model with male as the sole predictor of admit follows the form\n\\[\n\\begin{align*}\n\\text{admit}_i    & \\sim \\operatorname{Binomial}(n_i, p_i) \\\\\n\\text{logit}(p_i) & = \\alpha_{\\text{gid}[i]} \\\\\n\\alpha_j          & \\sim \\operatorname{Normal}(0, 1.5),\n\\end{align*}\n\\]\nwhere \\(n_i = \\text{applications}_i\\), the rows are indexed by \\(i\\), and the two levels of \\(\\text{gid}\\) are indexed by \\(j\\).\nMake the stan_data with the compose_data() function.\n\nstan_data &lt;- d |&gt; \n  select(dept, gid, admit, applications) |&gt;\n  compose_data()\n\n# What?\nstr(stan_data)\n\nList of 7\n $ dept        : num [1:12(1d)] 1 1 2 2 3 3 4 4 5 5 ...\n $ n_dept      : int 6\n $ gid         : num [1:12(1d)] 1 2 1 2 1 2 1 2 1 2 ...\n $ n_gid       : int 2\n $ admit       : int [1:12(1d)] 512 89 353 17 120 202 138 131 53 94 ...\n $ applications: int [1:12(1d)] 825 108 560 25 325 593 417 375 191 393 ...\n $ n           : int 12\n\n\nMake the model_code and fit m11.7 with stan(). Note the generated quantities block for the posterior-predictive check to come.\n\nmodel_code_11.7 &lt;- '\ndata {\n  int&lt;lower=1&gt; n;\n  int&lt;lower=1&gt; n_gid;\n  array[n] int gid;\n  array[n] int&lt;lower=1&gt; applications;\n  array[n] int&lt;lower=0&gt; admit;\n}\nparameters {\n  vector[n_gid] a;\n}\nmodel {\n  admit ~ binomial(applications, inv_logit(a[gid]));\n  a ~ normal(0, 1.5);\n}\ngenerated quantities {\n  // For the pp check\n  array[n] int&lt;lower=0&gt; pp_admit = binomial_rng(applications, inv_logit(a[gid]));\n}\n'\n\nm11.7 &lt;- stan(\n  model_code = model_code_11.7, \n  data = stan_data,\n  cores = 4, iter = 4000, seed = 11)\n\nCheck the model summary.\n\nprint(m11.7, pars = \"a\", probs = c(0.055, 0.945))\n\nInference for Stan model: anon_model.\n4 chains, each with iter=4000; warmup=2000; thin=1; \npost-warmup draws per chain=2000, total post-warmup draws=8000.\n\n      mean se_mean   sd  5.5% 94.5% n_eff Rhat\na[1] -0.22       0 0.04 -0.28 -0.16  5765    1\na[2] -0.83       0 0.05 -0.91 -0.75  5699    1\n\nSamples were drawn using NUTS(diag_e) at Thu Aug 15 11:33:46 2024.\nFor each parameter, n_eff is a crude measure of effective sample size,\nand Rhat is the potential scale reduction factor on split chains (at \nconvergence, Rhat=1).\n\n\nWe’ll hold off on computing diff_a and diff_p, for a moment, and jump straight to Figure 11.5. Note how we’re using the pp_admit values we computed with the generated quantities block.\n\nm11.7 |&gt; \n  spread_draws(pp_admit[i]) |&gt; \n  left_join(d |&gt; \n              mutate(i = as.integer(case)),\n            by = join_by(i)) |&gt; \n  \n  ggplot(aes(x = gid)) +\n  stat_pointinterval(aes(y = pp_admit / applications),\n                     .width = 0.89, linewidth = 1, shape = 1) +\n  geom_point(data = d,\n             aes(y = admit / applications),\n             color = \"blue\") +\n  geom_path(data = d,\n             aes(y = admit / applications, group = dept),\n             color = \"blue\") +\n  scale_x_discrete(NULL, labels = c(\"male\", \"female\")) +\n  scale_y_continuous(\"admit\", limits = 0:1) +\n  facet_wrap(~ dept, nrow = 1)\n\n\n\n\nI should acknowledge I got the idea to reformat the plot this way from Arel-Bundock’s work.\nNow we fit the model\n\\[\n\\begin{align*}\n\\text{admit}_i    & \\sim \\operatorname{Binomial} (n_i, p_i) \\\\\n\\text{logit}(p_i) & = \\alpha_{\\text{gid}[i]} + \\delta_{\\text{dept}[i]} \\\\\n\\alpha_j          & \\sim \\operatorname{Normal} (0, 1.5) \\\\\n\\delta_k          & \\sim \\operatorname{Normal} (0, 1.5),\n\\end{align*}\n\\]\nwhere departments are indexed by \\(k\\). Make the model_code and fit m11.8 with stan(). Note how we’re increasing the iter argument in stan().\n\nmodel_code_11.8 &lt;- '\ndata {\n  int&lt;lower=1&gt; n;\n  int&lt;lower=1&gt; n_gid;\n  int&lt;lower=1&gt; n_dept;\n  array[n] int gid;\n  array[n] int dept;\n  array[n] int applications;\n  array[n] int&lt;lower=0&gt; admit;\n}\nparameters {\n  vector[n_gid] a;\n  vector[n_dept] d;\n}\nmodel {\n  admit ~ binomial(applications, inv_logit(a[gid] + d[dept]));\n  a ~ normal(0, 1.5);\n  d ~ normal(0, 1.5);\n}\ngenerated quantities {\n  // For the pp check\n  array[n] int&lt;lower=0&gt; pp_admit = binomial_rng(applications, inv_logit(a[gid] + d[dept]));\n}\n'\n\nm11.8 &lt;- stan(\n  model_code = model_code_11.8, \n  data = stan_data,\n  cores = 4, iter = 4000, seed = 11)\n\nCheck the model summary.\n\nprint(m11.8, pars = c(\"a\", \"d\"), probs = c(0.055, 0.945))\n\nInference for Stan model: anon_model.\n4 chains, each with iter=4000; warmup=2000; thin=1; \npost-warmup draws per chain=2000, total post-warmup draws=8000.\n\n      mean se_mean   sd  5.5% 94.5% n_eff Rhat\na[1] -0.54    0.02 0.54 -1.42  0.34   603    1\na[2] -0.45    0.02 0.54 -1.33  0.44   607    1\nd[1]  1.12    0.02 0.54  0.24  2.00   604    1\nd[2]  1.08    0.02 0.55  0.18  1.96   603    1\nd[3] -0.14    0.02 0.54 -1.02  0.74   611    1\nd[4] -0.17    0.02 0.55 -1.05  0.71   610    1\nd[5] -0.61    0.02 0.55 -1.51  0.28   623    1\nd[6] -2.17    0.02 0.55 -3.07 -1.27   642    1\n\nSamples were drawn using NUTS(diag_e) at Thu Aug 15 11:35:07 2024.\nFor each parameter, n_eff is a crude measure of effective sample size,\nand Rhat is the potential scale reduction factor on split chains (at \nconvergence, Rhat=1).\n\n\nHere we’ll show the contrasts for the two models in a coefficient plot.\n\nbind_rows(\n  as_draws_df(m11.7) |&gt; select(.draw, `a[1]`:`a[2]`),\n  as_draws_df(m11.8) |&gt; select(.draw, `a[1]`:`a[2]`)\n) |&gt; \n  mutate(fit = rep(c(\"m11.7\", \"m11.8\"), each = n() / 2),\n         diff_a = `a[1]` - `a[2]`,\n         diff_p = plogis(`a[1]`) - plogis(`a[2]`)) |&gt; \n  pivot_longer(contains(\"diff\")) |&gt; \n  \n  ggplot(aes(x = value, y = name,\n             color = fit)) +\n  geom_vline(xintercept = 0, color = \"white\") +\n  stat_pointinterval(.width = 0.89, linewidth = 1, shape = 1,\n                     position = position_dodge(width = -0.5)) +\n  labs(x = \"contrast\",\n       y = NULL)\n\n\n\n\nHere’s our tidyverse-style tabulation of the proportions of applicants in each department by gid.\n\nd |&gt; \n  group_by(dept) |&gt; \n  mutate(proportion = applications / sum(applications)) |&gt; \n  select(dept, gid, proportion) |&gt; \n  pivot_wider(names_from = dept,\n              values_from = proportion) |&gt; \n  mutate_if(is.double, round, digits = 2)\n\n# A tibble: 2 × 7\n  gid       A     B     C     D     E     F\n  &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 1      0.88  0.96  0.35  0.53  0.33  0.52\n2 2      0.12  0.04  0.65  0.47  0.67  0.48\n\n\nIf we make another version of Figure 11.5 with m11.8, we’ll see conditioning on both substantially improved the posterior predictive distribution.\n\nm11.8 |&gt; \n  spread_draws(pp_admit[i]) |&gt; \n  left_join(d |&gt; \n              mutate(i = as.integer(case)),\n            by = join_by(i)) |&gt; \n  \n  ggplot(aes(x = gid)) +\n  stat_pointinterval(aes(y = pp_admit / applications),\n                     .width = 0.89, linewidth = 1, shape = 1) +\n  geom_point(data = d,\n             aes(y = admit / applications),\n             color = \"blue\") +\n  geom_path(data = d,\n             aes(y = admit / applications, group = dept),\n             color = \"blue\") +\n  scale_x_discrete(NULL, labels = c(\"male\", \"female\")) +\n  scale_y_continuous(\"admit\", limits = 0:1) +\n  facet_wrap(~ dept, nrow = 1)\n\n\n\n\nMcElreath recommended we look at the pairs() plot to get a sense of how highly correlated the parameters in our m11.8 model are. Here’s the plot.\n\npairs(m11.8, pars = c(\"a\", \"d\"), gap = 0.25)\n\n\n\n\n\n11.1.4.1 Rethinking: Simpson’s paradox is not a paradox."
  },
  {
    "objectID": "11.html#poisson-regression",
    "href": "11.html#poisson-regression",
    "title": "11  God Spiked the Integers",
    "section": "11.2 Poisson regression",
    "text": "11.2 Poisson regression\n\n11.2.1 Example: Oceanic tool complexity.\nLoad the Kline data (see Kline & Boyd, 2010).\n\ndata(Kline, package = \"rethinking\")\nd &lt;- Kline\nrm(Kline)\n\n# What?\nprint(d)\n\n      culture population contact total_tools mean_TU\n1    Malekula       1100     low          13     3.2\n2     Tikopia       1500     low          22     4.7\n3  Santa Cruz       3600     low          24     4.0\n4         Yap       4791    high          43     5.0\n5    Lau Fiji       7400    high          33     5.0\n6   Trobriand       8000    high          19     4.0\n7       Chuuk       9200    high          40     3.8\n8       Manus      13000     low          28     6.6\n9       Tonga      17500    high          55     5.4\n10     Hawaii     275000     low          71     6.6\n\n\nHere are our new columns.\n\nd &lt;- d |&gt;\n  mutate(log_pop_std = (log(population) - mean(log(population))) / sd(log(population)),\n         cid         = ifelse(contact == \"high\", \"2\", \"1\"))\n\nOur statistical model will follow the form\n\\[\n\\begin{align*}\n\\text{total-tools}_i & \\sim \\operatorname{Poisson}(\\lambda_i) \\\\\n\\log(\\lambda_i)      & = \\alpha_{\\text{cid}[i]} + \\beta_{\\text{cid}[i]} \\text{log-pop-std}_i \\\\\n\\alpha_j             & \\sim \\; ? \\\\\n\\beta_j              & \\sim \\; ?,\n\\end{align*}\n\\]\nwhere the priors for \\(\\alpha_j\\) and \\(\\beta_j\\) have yet be defined. If we continue our convention of using a Normal prior on the \\(\\alpha\\) parameters, we should recognize those will be log-Normal distributed on the outcome scale. Why? Because we’re modeling \\(\\lambda\\) with the log link. Here’s our version of Figure 11.7, depicting the two log-Normal priors considered in the text.\n\nd_plot &lt;- tibble(\n  x       = c(3, 22),\n  y       = c(0.055, 0.04),\n  meanlog = c(0, 3),\n  sdlog   = c(10, 0.5)) |&gt; \n  expand_grid(number = seq(from = 0, to = 100, length.out = 200)) |&gt; \n  mutate(density = dlnorm(number, meanlog, sdlog),\n         group   = str_c(\"alpha%~%Normal(\", meanlog, \", \", sdlog, \")\"))\n\nd_plot |&gt; \n  ggplot(aes(fill = group, color = group)) +\n  geom_area(aes(x = number, y = density),\n            alpha = 3/4, linewidth = 0, position = \"identity\") +\n  geom_text(data = d_plot |&gt; \n              group_by(group) |&gt; \n              slice(1),\n            aes(x = x, y = y, label = group),\n            hjust = 0, parse = TRUE) +\n  scale_y_continuous(NULL, breaks = NULL) +\n  xlab(\"mean number of tools\") +\n  theme(legend.position = \"none\")\n\n\n\n\nIn this context, \\(\\alpha \\sim \\operatorname{Normal}(0, 10)\\) has a very long tail on the outcome scale. The mean of the log-Normal distribution, recall, is \\(\\exp (\\mu + \\sigma^2/2)\\). Here that is in code.\n\nexp(0 + 10^2 / 2)\n\n[1] 5.184706e+21\n\n\nThat is very large. Here’s the same thing in a simulation.\n\nset.seed(11)\n\nrnorm(1e4, 0, 10) |&gt; \n  exp() |&gt; \n  mean()\n\n[1] 1.61276e+12\n\n\nNow compute the mean for the other prior under consideration, \\(\\alpha \\sim \\operatorname{Normal}(3, 0.5)\\).\n\nexp(3 + 0.5^2 / 2)\n\n[1] 22.7599\n\n\nThis is much smaller and more reasonable.\nNow let’s prepare to make the top row of Figure 11.8. In this portion of the figure, we consider the implications of two competing priors for \\(\\beta\\) while holding the prior for \\(\\alpha\\) at \\(\\operatorname{Normal}(3, 0.5)\\). The two \\(\\beta\\) priors under consideration are \\(\\operatorname{Normal}(0, 10)\\) and \\(\\operatorname{Normal}(0, 0.2)\\).\n\nset.seed(11)\n\n# How many lines would you like?\nn &lt;- 100\n\n# Simulate and wrangle\ntibble(i = 1:n,\n       a = rnorm(n, mean = 3, sd = 0.5)) |&gt; \n  mutate(`beta%~%Normal(0*', '*10)`  = rnorm(n, mean = 0 , sd = 10),\n         `beta%~%Normal(0*', '*0.2)` = rnorm(n, mean = 0 , sd = 0.2)) |&gt; \n  pivot_longer(contains(\"beta\"),\n               values_to = \"b\",\n               names_to = \"prior\") |&gt; \n  expand_grid(x = seq(from = -2, to = 2, length.out = 100)) |&gt; \n  mutate(prior = fct_rev(prior)) |&gt; \n  \n  # Plot\n  ggplot(aes(x = x, y = exp(a + b * x), group = i)) +\n  geom_line(alpha = 2/3, linewidth = 1/4) +\n  labs(x = \"log population (std)\",\n       y = \"total tools\") +\n  coord_cartesian(ylim = c(0, 100)) +\n  facet_wrap(~ prior, labeller = label_parsed)\n\n\n\n\nIt turns out that many of the lines considered plausible under \\(\\operatorname{Normal}(0, 10)\\) are disturbingly extreme. Here is what \\(\\alpha \\sim \\operatorname{Normal}(3, 0.5)\\) and \\(\\beta \\sim \\operatorname{Normal}(0, 0.2)\\) would mean when the \\(x\\)-axis is on the log population scale and the population scale.\n\nset.seed(11)\n\nprior &lt;- tibble(\n  i = 1:n,\n  a = rnorm(n, mean = 3, sd = 0.5),\n  b = rnorm(n, mean = 0, sd = 0.2)) |&gt; \n  expand_grid(x = seq(from = log(100), to = log(200000), length.out = 100))\n\n# Left\np1 &lt;- prior |&gt; \n  ggplot(aes(x = x, y = exp(a + b * x), group = i)) +\n  geom_line(alpha = 2/3, linewidth = 1/4) +\n  labs(x = \"log population\",\n       y = \"total tools\") +\n  coord_cartesian(xlim = c(log(100), log(200000)),\n                  ylim = c(0, 500))\n# Right\np2 &lt;- prior |&gt; \n  ggplot(aes(x = exp(x), y = exp(a + b * x), group = i)) +\n  geom_line(alpha = 2/3, linewidth = 1/4) +\n  scale_y_continuous(NULL, breaks = NULL) +\n  xlab(\"population\") +\n  coord_cartesian(xlim = c(100, 200000),\n                  ylim = c(0, 500))\n\n# Combine, add facet strips, and display\n(p1 | p2) &\n  facet_wrap(~ \"atop(alpha%~%Normal(3*', '*0.5), beta%~%Normal(0*', '*0.2))\", \n             labeller = label_parsed)\n\n\n\n\nOkay, after settling on our two priors, the updated model formula is\n\\[\n\\begin{align*}\ny_i             & \\sim \\operatorname{Poisson}(\\lambda_i) \\\\\n\\log(\\lambda_i) & = \\alpha + \\beta (x_i - \\bar x) \\\\\n\\alpha          & \\sim \\operatorname{Normal}(3, 0.5) \\\\\n\\beta           & \\sim \\operatorname{Normal}(0, 0.2).\n\\end{align*}\n\\]\nWe’re finally ready to start fitting the models. First, define the stan_data.\n\nstan_data &lt;- d |&gt; \n  select(total_tools, log_pop_std, cid) |&gt; \n  compose_data()\n\n# What?\nstr(stan_data)\n\nList of 5\n $ total_tools: int [1:10(1d)] 13 22 24 43 33 19 40 28 55 71\n $ log_pop_std: num [1:10(1d)] -1.2915 -1.0886 -0.5158 -0.3288 -0.0443 ...\n $ cid        : num [1:10(1d)] 1 1 1 2 2 2 2 1 2 1\n $ n_cid      : int 2\n $ n          : int 10\n\n\nDefine model_code_11.9 and model_code_11.10.\n\n# Intercept only\nmodel_code_11.9 &lt;- '\ndata {\n  int&lt;lower=1&gt; n;\n  array[n] int&lt;lower=0&gt; total_tools;\n}\nparameters {\n  real a;  \n}\nmodel {\n  total_tools ~ poisson(exp(a));\n  a ~ normal(3, 0.5);\n}\ngenerated quantities {\n  vector[n] log_lik;\n  for (i in 1:n) log_lik[i] = poisson_lpmf(total_tools[i] | exp(a));\n}\n'\n\n# Interaction model\nmodel_code_11.10 &lt;- '\ndata {\n  int&lt;lower=1&gt; n;\n  int&lt;lower=1&gt; n_cid;\n  array[n] int cid;\n  vector[n] log_pop_std;\n  array[n] int&lt;lower=0&gt; total_tools;\n}\nparameters {\n  vector[n_cid] a;\n  vector[n_cid] b;\n}\nmodel {\n  vector[n] lambda;\n  lambda = exp(a[cid] + b[cid] .* log_pop_std);\n  \n  total_tools ~ poisson(lambda);\n  a ~ normal(3, 0.5);\n  b ~ normal(0, 0.2);\n}\ngenerated quantities {\n  vector[n] log_lik;\n  for (i in 1:n) log_lik[i] = poisson_lpmf(total_tools[i] | exp(a[cid[i]] + b[cid[i]] .* log_pop_std[i]));\n}\n'\n\nSample from the two posteriors with stan().\n\nm11.9 &lt;- stan(\n  data = stan_data,\n  model_code = model_code_11.9,\n  cores = 4, seed = 11)\n\nm11.10 &lt;- stan(\n  data = stan_data,\n  model_code = model_code_11.10,\n  cores = 4, seed = 11)\n\nCompare the two models by the LOO.\n\nl11.9 &lt;- extract_log_lik(m11.9) |&gt; loo()\nl11.10 &lt;- extract_log_lik(m11.10) |&gt; loo()\n\nWarning: Some Pareto k diagnostic values are too high. See help('pareto-k-diagnostic') for details.\n\nloo_compare(l11.9, l11.10) |&gt; \n  print(simplify = FALSE)\n\n       elpd_diff se_diff elpd_loo se_elpd_loo p_loo se_p_loo looic se_looic\nmodel2   0.0       0.0   -42.6      6.6         6.9   2.6     85.2  13.2   \nmodel1 -28.1      16.4   -70.7     16.7         8.3   3.5    141.4  33.4   \n\n\nLike McElreath reported in the text, we have a Pareto-\\(k\\) warning. We can inspect the \\(k\\) values with loo::pareto_k_table().\n\npareto_k_table(l11.10)\n\nPareto k diagnostic values:\n                         Count Pct.    Min. ESS\n(-Inf, 0.7]   (good)     8     80.0%   344     \n   (0.7, 1]   (bad)      1     10.0%   &lt;NA&gt;    \n   (1, Inf)   (very bad) 1     10.0%   &lt;NA&gt;    \n\n\nLet’s take a closer look.\n\nd |&gt; \n  select(culture) |&gt; \n  mutate(k = l11.10$diagnostics$pareto_k) |&gt; \n  arrange(desc(k)) |&gt; \n  mutate_if(is.double, round, digits = 2)\n\n      culture    k\n1      Hawaii 1.02\n2       Tonga 0.83\n3   Trobriand 0.56\n4         Yap 0.55\n5    Malekula 0.42\n6       Manus 0.32\n7     Tikopia 0.26\n8    Lau Fiji 0.25\n9  Santa Cruz 0.20\n10      Chuuk 0.13\n\n\nIt turns out Hawaii is very influential. Figure 11.9 will clarify why. For a little practice while computing the trajectories, we’ll use an as_draws_df()-based workflow for the panel on the left, and use a spread_draws()-based workflow for the panel on the right.\n\n# For subsetting the labels in the left panel\nculture_vec &lt;- c(\"Hawaii\", \"Tonga\", \"Trobriand\", \"Yap\")\n\n# Left\np1 &lt;- as_draws_df(m11.10) |&gt; \n  select(.draw, `a[1]`:`b[2]`) |&gt; \n  pivot_longer(-.draw) |&gt; \n  mutate(parameter = str_extract(name, \"[a-z]\"),\n         cid = str_extract(name, \"\\\\d\")) |&gt; \n  select(-name) |&gt; \n  pivot_wider(names_from = parameter, values_from = value) |&gt; \n  expand_grid(log_pop_std = seq(from = -4.5, to = 2.5, length.out = 100)) |&gt; \n  mutate(total_tools = exp(a + b * log_pop_std)) |&gt; \n  \n  ggplot(aes(x = log_pop_std, y = total_tools,\n             color = cid, fill = cid, group = cid)) +\n  stat_lineribbon(.width = 0.89, alpha = 1/4) +\n  geom_point(data = d |&gt; \n               mutate(k = l11.10$diagnostics$pareto_k),\n             aes(size = k)) +\n  geom_text(data = d |&gt; \n              mutate(k = l11.10$diagnostics$pareto_k) |&gt; \n              mutate(label = str_c(culture, \" (\", round(k, digits = 2), \")\"),\n                     vjust = ifelse(total_tools &gt; 30, -0.3, 1.3)) |&gt; \n              filter(culture %in% culture_vec),\n            aes(label = label, vjust = vjust),\n            hjust = 1.1, size = 3) +\n  labs(x = \"log population (std)\",\n       y = \"total tools\") +\n  coord_cartesian(xlim = range(d$log_pop_std),\n                  ylim = c(0, 80))\n\n# Right\np2 &lt;- spread_draws(m11.10, a[cid], b[cid]) |&gt; \n  mutate(cid = as.character(cid)) |&gt; \n  expand_grid(log_pop_std = seq(from = -4.5, to = 2.5, length.out = 100)) |&gt; \n  mutate(total_tools = exp(a + b * log_pop_std)) |&gt;\n  mutate(population = exp((log_pop_std * sd(log(d$population))) + mean(log(d$population)))) |&gt; \n  \n  ggplot(aes(x = population, y = total_tools,\n             color = cid, fill = cid, group = cid)) +\n  stat_lineribbon(.width = 0.89, alpha = 1/4) +\n  geom_point(data = d |&gt; \n               mutate(k = l11.10$diagnostics$pareto_k),\n             aes(size = k)) +\n  scale_x_continuous(\"population\", breaks = c(0, 50000, 150000, 250000),\n                     labels = scales::comma(c(0, 50000, 150000, 250000))) +\n  scale_y_continuous(NULL, breaks = NULL) +\n  coord_cartesian(xlim = range(d$population),\n                  ylim = c(0, 80))\n\n# Combine, adjust, and display\n(p1 | p2) &\n  scale_color_viridis_d(option = \"A\", end = 0.6) &\n  scale_fill_viridis_d(option = \"A\", end = 0.6) &\n  scale_size_continuous(range = c(0.1, 5), limits = c(0.1, 1.1)) &\n  theme(legend.position = \"none\")\n\n\n\n\nHawaii is influential in that it has a very large population relative to the other islands.\n\n11.2.1.1 Overthinking: Modeling tool innovation.\nMcElreath’s theoretical, or scientific, model for total_tools is\n\\[\\widehat{\\text{total-tools}} = \\frac{\\alpha_{\\text{cid}[i]} \\: \\text{population}^{\\beta_{\\text{cid}[i]}}}{\\gamma}.\\]\nWe can use the Poisson likelihood to express this in a Bayesian model as\n\\[\n\\begin{align*}\n\\text{total-tools} & \\sim \\operatorname{Poisson}(\\lambda_i) \\\\\n\\lambda_i & = \\left[ \\exp (\\alpha_{\\text{cid}[i]}) \\text{population}_i^{\\beta_{\\text{cid}[i]}} \\right] / \\gamma \\\\\n\\alpha_j  & \\sim \\operatorname{Normal}(1, 1) \\\\\n\\beta_j   & \\sim \\operatorname{Exponential}(1) \\\\\n\\gamma    & \\sim \\operatorname{Exponential}(1),\n\\end{align*}\n\\]\nwhere we exponentiate \\(\\alpha_{\\text{cid}[i]}\\) to restrict the posterior to zero and above. To fit that model with rstan, first we make some data d_pred for the predictions we’ll display in the plot.\n\nd_pred &lt;- tibble(\n  population = seq(from = 0, to = 3e5, length.out = 101) |&gt; \n    as.integer()) |&gt; \n  expand_grid(cid = 1:2) |&gt; \n  mutate(i = 1:n())\n\n# What?\nglimpse(d_pred)\n\nRows: 202\nColumns: 3\n$ population &lt;int&gt; 0, 0, 3000, 3000, 6000, 6000, 9000, 9000, 12000, 12000, 150…\n$ cid        &lt;int&gt; 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2,…\n$ i          &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, …\n\n\nNow make the stan_data.\n\nstan_data &lt;- d |&gt; \n  mutate(population = as.double(population)) |&gt;\n  select(total_tools, population, cid) |&gt;\n  compose_data(population_pred = d_pred$population,\n               cid_pred = d_pred$cid,\n               n_pred = nrow(d_pred))\n\n# What?\nstr(stan_data)\n\nList of 8\n $ total_tools    : int [1:10(1d)] 13 22 24 43 33 19 40 28 55 71\n $ population     : num [1:10(1d)] 1100 1500 3600 4791 7400 ...\n $ cid            : num [1:10(1d)] 1 1 1 2 2 2 2 1 2 1\n $ n_cid          : int 2\n $ n              : int 10\n $ population_pred: int [1:202] 0 0 3000 3000 6000 6000 9000 9000 12000 12000 ...\n $ cid_pred       : int [1:202] 1 2 1 2 1 2 1 2 1 2 ...\n $ n_pred         : int 202\n\n\nDefine model_code_11.11.\n\nmodel_code_11.11 &lt;- '\ndata {\n  int&lt;lower=1&gt; n;\n  int&lt;lower=1&gt; n_cid;\n  array[n] int cid;\n  vector[n] population;\n  array[n] int&lt;lower=0&gt; total_tools;\n  // For predictions\n  int&lt;lower=1&gt; n_pred;\n  array[n_pred] int cid_pred;\n  vector[n_pred] population_pred;\n}\nparameters {\n  vector[n_cid] a;\n  vector&lt;lower=0&gt;[n_cid] b;\n  real&lt;lower=0&gt; g;\n}\ntransformed parameters {\n  vector[n] lambda;\n  lambda = exp(a[cid]) .* population^b[cid] / g;\n}\nmodel {\n  total_tools ~ poisson(lambda);\n  a ~ normal(1, 1);\n  b ~ exponential(1);\n  g ~ exponential(1);\n}\ngenerated quantities {\n  vector[n] log_lik;\n  vector[n_pred] lambda_pred;\n  \n  for (i in 1:n) log_lik[i] = poisson_lpmf(total_tools[i] | lambda[i]);\n  lambda_pred = exp(a[cid_pred]) .* population_pred^b[cid_pred] / g;\n}\n'\n\nSample from the posterior.\n\nm11.11 &lt;- stan(\n  data = stan_data,\n  model_code = model_code_11.11,\n  cores = 4, seed = 11)\n\nCheck the model summary.\n\nprint(m11.11, pars = c(\"a\", \"b\", \"g\"), probs = c(0.055, 0.945))\n\nInference for Stan model: anon_model.\n4 chains, each with iter=2000; warmup=1000; thin=1; \npost-warmup draws per chain=1000, total post-warmup draws=4000.\n\n     mean se_mean   sd  5.5% 94.5% n_eff Rhat\na[1] 0.92    0.02 0.68 -0.22  1.97  1383    1\na[2] 0.92    0.02 0.83 -0.42  2.26  1967    1\nb[1] 0.26    0.00 0.03  0.20  0.32  1964    1\nb[2] 0.29    0.00 0.11  0.12  0.46  1480    1\ng    1.15    0.02 0.76  0.30  2.48  1605    1\n\nSamples were drawn using NUTS(diag_e) at Thu Aug 15 11:44:42 2024.\nFor each parameter, n_eff is a crude measure of effective sample size,\nand Rhat is the potential scale reduction factor on split chains (at \nconvergence, Rhat=1).\n\n\nCompute and check the PSIS-LOO estimates along with their diagnostic Pareto-\\(k\\) values.\n\nl11.11 &lt;- extract_log_lik(m11.11) |&gt; loo()\n\nWarning: Some Pareto k diagnostic values are too high. See help('pareto-k-diagnostic') for details.\n\nprint(l11.11)\n\n\nComputed from 4000 by 10 log-likelihood matrix.\n\n         Estimate   SE\nelpd_loo    -40.6  6.0\np_loo         5.5  1.9\nlooic        81.3 12.0\n------\nMCSE of elpd_loo is NA.\nMCSE and ESS estimates assume independent draws (r_eff=1).\n\nPareto k diagnostic values:\n                         Count Pct.    Min. ESS\n(-Inf, 0.7]   (good)     9     90.0%   274     \n   (0.7, 1]   (bad)      1     10.0%   &lt;NA&gt;    \n   (1, Inf)   (very bad) 0      0.0%   &lt;NA&gt;    \nSee help('pareto-k-diagnostic') for details.\n\n\nWe still have one high Pareto-\\(k\\) value. Recall that due to the very small sample size, this isn’t entirely surprising. If you’re curious, here’s a scatter plot of the Pareto-\\(k\\) values for this model and the last.\n\ntibble(m11.10 = l11.10$diagnostics$pareto_k,\n       m11.11 = l11.11$diagnostics$pareto_k) |&gt; \n  \n  ggplot(aes(x = m11.10, y = m11.11)) +\n  geom_abline(color = \"white\") +\n  geom_point() +\n  scale_x_continuous(breaks = 0:5 / 5 + 0.1, limits = c(0.1, 1.1)) +\n  scale_y_continuous(breaks = 0:5 / 5 + 0.1, limits = c(0.1, 1.1)) +\n  labs(subtitle = expression(Pareto~italic(k)))\n\n\n\n\nOkay, it’s time to make Figure 11.10. In the first line in the Wrangle section below, note how we’re using spread_draws() to extract the lambda_pred values we defined in the generated quantities, above.\n\n# For the annotation\nd_text &lt;- distinct(d, cid, contact) |&gt; \n  mutate(population  = c(210000, 72500),\n         total_tools = c(59, 68),\n         label       = str_c(contact, \" contact\"))\n\n# Wrangle\nspread_draws(m11.11, lambda_pred[i]) |&gt; \n  left_join(d_pred, by = join_by(i)) |&gt; \n  mutate(cid = as.character(cid)) |&gt; \n  rename(total_tools = lambda_pred) |&gt; \n  \n  # Plot!\n  ggplot(aes(x = population, y = total_tools,\n             color = cid, fill = cid, group = cid)) +\n  stat_lineribbon(.width = 0.89, alpha = 1/4) +\n  geom_point(data = d |&gt; \n               mutate(k = l11.11$diagnostics$pareto_k),\n             aes(size = k)) +\n  geom_text(data = d_text,\n            aes(label = label)) +\n  scale_x_continuous(\"population\", breaks = c(0, 50000, 150000, 250000),\n                     labels = scales::comma(c(0, 50000, 150000, 250000))) +\n  scale_color_viridis_d(option = \"A\", end = 0.6) +\n  scale_fill_viridis_d(option = \"A\", end = 0.6) +\n  scale_size_continuous(range = c(0.1, 5), limits = c(0.1, 1)) +\n  ylab(\"total tools\") +\n  coord_cartesian(xlim = range(d$population),\n                  ylim = c(0, 80)) +\n  theme(legend.position = \"none\")\n\n\n\n\nIn case you were curious, here are the results if we compare m11.10 and m11.11 by the PSIS-LOO.\n\nloo_compare(l11.10, l11.11) |&gt; \n  print(simplify = FALSE)\n\n       elpd_diff se_diff elpd_loo se_elpd_loo p_loo se_p_loo looic se_looic\nmodel2   0.0       0.0   -40.6      6.0         5.5   1.9     81.3  12.0   \nmodel1  -2.0       2.9   -42.6      6.6         6.9   2.6     85.2  13.2   \n\n\n\n\n\n11.2.2 Negative binomial (gamma-Poisson) models.\n\n\n11.2.3 Example: Exposure and the offset.\nHere we simulate our industrious monk data.\n\nset.seed(11)\n\nnum_days &lt;- 30\ny        &lt;- rpois(num_days, lambda = 1.5)\n\nnum_weeks &lt;- 4\ny_new     &lt;- rpois(num_weeks, lambda = 0.5 * 7)\n\nNow tidy the data and add log_days.\n\nd &lt;- tibble(\n  y         = c(y, y_new), \n  days      = rep(c(1, 7), times = c(num_days, num_weeks)),  # this is the exposure\n  monastery = rep(0:1, times = c(num_days, num_weeks))) |&gt;\n  mutate(log_days = log(days))\n\n# What?\nglimpse(d)\n\nRows: 34\nColumns: 4\n$ y         &lt;int&gt; 1, 0, 1, 0, 0, 4, 0, 1, 3, 0, 0, 1, 3, 3, 2, 2, 1, 1, 0, 1, …\n$ days      &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, …\n$ monastery &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ log_days  &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n\n\nWithin the context of the Poisson likelihood, we can decompose \\(\\lambda\\) into two parts, \\(\\mu\\) (mean) and \\(\\tau\\) (exposure), like this:\n\\[\ny_i \\sim \\operatorname{Poisson}(\\lambda_i) \\\\\n\\log \\lambda_i = \\log \\frac{\\mu_i}{\\tau_i} = \\log \\mu_i - \\log \\tau_i.\n\\]\nTherefore, you can rewrite the equation if the exposure (\\(\\tau\\)) varies in your data and you still want to model the mean (\\(\\mu\\)). Using the model we’re about to fit as an example, here’s what that might look like:\n\\[\n\\begin{align*}\ny_i & \\sim \\operatorname{Poisson}(\\mu_i) \\\\\n\\log \\mu_i & = \\color{blue}{\\log \\tau_i} + \\alpha + \\beta \\text{monastery}_i \\\\\n\\alpha     & \\sim \\operatorname{Normal}(0, 1) \\\\\n\\beta      & \\sim \\operatorname{Normal}(0, 1),\n\\end{align*}\n\\]\nwhere the offset \\(\\log \\tau_i\\) does not get a prior. In this context, its value is added directly to the right side of the formula. With the rstan package, we do this directly in the model block. First, though, let’s make the stan_data.\n\nstan_data &lt;- d |&gt; \n  compose_data()\n\n# What?\nstr(stan_data)\n\nList of 5\n $ y        : int [1:34(1d)] 1 0 1 0 0 4 0 1 3 0 ...\n $ days     : num [1:34(1d)] 1 1 1 1 1 1 1 1 1 1 ...\n $ monastery: int [1:34(1d)] 0 0 0 0 0 0 0 0 0 0 ...\n $ log_days : num [1:34(1d)] 0 0 0 0 0 0 0 0 0 0 ...\n $ n        : int 34\n\n\nDefine model_code_11.12. Note how log_days does not get a coefficient in the lambda formula. It stands on its own.\n\nmodel_code_11.12 &lt;- '\ndata {\n  int&lt;lower=1&gt; n;\n  vector[n] log_days;\n  vector[n] monastery;\n  array[n] int&lt;lower=0&gt; y;\n}\nparameters {\n  real a;\n  real b;\n}\nmodel {\n  y ~ poisson(exp(log_days + a + b * monastery));\n  a ~ normal(0, 1);\n  b ~ normal(0, 1);\n}\n'\n\nSample from the posterior.\n\nm11.12 &lt;- stan(\n  data = stan_data,\n  model_code = model_code_11.12,\n  cores = 4, seed = 11)\n\nAs we look at the model summary, keep in mind that the parameters are on the per-one-unit-of-time scale. Since we simulated the data based on summary information from two units of time–one day and seven days–, this means the parameters are in the scale of \\(\\log (\\lambda)\\) per one day.\n\nprint(m11.12, probs = c(0.055, 0.945))\n\nInference for Stan model: anon_model.\n4 chains, each with iter=2000; warmup=1000; thin=1; \npost-warmup draws per chain=1000, total post-warmup draws=4000.\n\n       mean se_mean   sd   5.5%  94.5% n_eff Rhat\na     -0.01    0.00 0.18  -0.31   0.26  1776    1\nb     -0.88    0.01 0.33  -1.40  -0.37  1861    1\nlp__ -31.30    0.03 1.07 -33.31 -30.32  1639    1\n\nSamples were drawn using NUTS(diag_e) at Thu Aug 15 11:46:33 2024.\nFor each parameter, n_eff is a crude measure of effective sample size,\nand Rhat is the potential scale reduction factor on split chains (at \nconvergence, Rhat=1).\n\n\nTo get the posterior distributions for average daily outputs for the old and new monasteries, respectively, we’ll use use the formulas\n\\[\n\\begin{align*}\n\\lambda_\\text{old} & = \\exp (\\alpha) \\;\\;\\; \\text{and} \\\\\n\\lambda_\\text{new} & = \\exp (\\alpha + \\beta_\\text{monastery}).\n\\end{align*}\n\\]\nFollowing those transformations, we’ll summarize the \\(\\lambda\\) distributions with medians and 89% HDIs with help from the tidybayes::mean_hdi() function.\n\nas_draws_df(m11.12) |&gt;\n  mutate(lambda_old = exp(a),\n         lambda_new = exp(a + b)) |&gt;\n  pivot_longer(contains(\"lambda\")) |&gt; \n  mutate(name = factor(name, levels = c(\"lambda_old\", \"lambda_new\"))) |&gt;\n  group_by(name) |&gt;\n  mean_hdi(value, .width = .89) |&gt; \n  mutate_if(is.double, round, digits = 2)\n\n# A tibble: 2 × 7\n  name       value .lower .upper .width .point .interval\n  &lt;fct&gt;      &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;    \n1 lambda_old  1      0.73   1.28   0.89 mean   hdi      \n2 lambda_new  0.43   0.24   0.61   0.89 mean   hdi      \n\n\nBecause we don’t know what seed McElreath used to simulate his data, our simulated data differed a little from his and, as a consequence, our results differ a little, too."
  },
  {
    "objectID": "11.html#multinomial-and-categorical-models",
    "href": "11.html#multinomial-and-categorical-models",
    "title": "11  God Spiked the Integers",
    "section": "11.3 Multinomial and categorical models",
    "text": "11.3 Multinomial and categorical models\n\n11.3.1 Predictors matched to outcomes.\nI will flesh this section out later.\n\n\n11.3.2 Predictors matched to observations.\nI will flesh this section out later.\n\n11.3.2.1 Multinomial in disguise as Poisson.\nHere we fit a multinomial likelihood by refactoring it to a series of Poisson models. Let’s retrieve the Berkeley data.\n\ndata(UCBadmit, package = \"rethinking\")\nd &lt;- UCBadmit\nrm(UCBadmit)\n\nSet up the stan_data.\n\nstan_data &lt;- d |&gt; \n  # `reject` is a reserved word in Stan, and must not be used as variable name\n  mutate(rej = reject) |&gt; \n  select(admit, rej, applications) |&gt; \n  compose_data()\n\n# What?\nstr(stan_data)\n\nList of 4\n $ admit       : int [1:12(1d)] 512 89 353 17 120 202 138 131 53 94 ...\n $ rej         : int [1:12(1d)] 313 19 207 8 205 391 279 244 138 299 ...\n $ applications: int [1:12(1d)] 825 108 560 25 325 593 417 375 191 393 ...\n $ n           : int 12\n\n\nDefine the model_code objects for the two complimentary models.\n\n# Binomial model of overall admission probability\nmodel_code_11.binom &lt;- '\ndata {\n  int&lt;lower=1&gt; n;\n  array[n] int&lt;lower=1&gt; applications;\n  array[n] int&lt;lower=0&gt; admit;\n}\nparameters {\n  real a;\n}\nmodel {\n  admit ~ binomial(applications, inv_logit(a));\n  a ~ normal(0, 1.5);\n}\n'\n\n# Poisson model of overall admission rate and rejection rate\nmodel_code_11.pois &lt;- '\ndata {\n  int&lt;lower=1&gt; n;\n  array[n] int&lt;lower=1&gt; applications;\n  array[n] int&lt;lower=0&gt; admit;\n  array[n] int&lt;lower=0&gt; rej;\n}\nparameters {\n  real a1;\n  real a2;\n}\nmodel {\n  admit ~ poisson(exp(a1));\n  rej ~ poisson(exp(a2));\n  [a1, a2] ~ normal(0, 1.5);\n}\n'\n\nCompile and extract the posterior draws for both with stan().\n\nm11.binom &lt;- stan(\n  model_code = model_code_11.binom, \n  data = stan_data,\n  chains = 3, cores = 3, seed = 11)\n\nm11.pois &lt;- stan(\n  model_code = model_code_11.pois,\n  data = stan_data,\n  chains = 3, cores = 3, seed = 11)\n\nCompare the two model summaries.\n\nprint(m11.binom, pars = \"a\", probs = c(0.055, 0.945))\n\nInference for Stan model: anon_model.\n3 chains, each with iter=2000; warmup=1000; thin=1; \npost-warmup draws per chain=1000, total post-warmup draws=3000.\n\n   mean se_mean   sd  5.5% 94.5% n_eff Rhat\na -0.46       0 0.03 -0.51 -0.41  1078    1\n\nSamples were drawn using NUTS(diag_e) at Thu Aug 15 11:47:57 2024.\nFor each parameter, n_eff is a crude measure of effective sample size,\nand Rhat is the potential scale reduction factor on split chains (at \nconvergence, Rhat=1).\n\nprint(m11.pois, pars = c(\"a1\", \"a2\"), probs = c(0.055, 0.945))\n\nInference for Stan model: anon_model.\n3 chains, each with iter=2000; warmup=1000; thin=1; \npost-warmup draws per chain=1000, total post-warmup draws=3000.\n\n   mean se_mean   sd 5.5% 94.5% n_eff Rhat\na1 4.98       0 0.02 4.94  5.02  2591    1\na2 5.44       0 0.02 5.41  5.47  3015    1\n\nSamples were drawn using NUTS(diag_e) at Thu Aug 15 11:48:24 2024.\nFor each parameter, n_eff is a crude measure of effective sample size,\nand Rhat is the potential scale reduction factor on split chains (at \nconvergence, Rhat=1).\n\n\nThough the model summaries look very different for the two models, they give the same answer, within MCMC simulation error, for the focal estimand \\(p_\\text{admit}\\). We might explore that in a plot.\n\nbind_rows(\n  # Binomial\n  as_draws_df(m11.binom) |&gt; \n    transmute(p_admit = plogis(a)),\n  # Poisson\n  as_draws_df(m11.pois) |&gt; \n    transmute(p_admit = exp(a1) / (exp(a1) + exp(a2)))\n) |&gt; \n  mutate(fit = rep(c(\"m11.binom\", \"m11.pois\"), each = n() / 2)) |&gt; \n  \n  ggplot(aes(x = p_admit, y = fit)) +\n  stat_halfeye(.width = 0.89) +\n  scale_y_discrete(NULL, expand = expansion(mult = 0.1)) +\n  xlab(expression(italic(p)[admit]))\n\n\n\n\n\n\n11.3.2.2 Overthinking: Multinomial-Poisson transformation."
  },
  {
    "objectID": "11.html#summary",
    "href": "11.html#summary",
    "title": "11  God Spiked the Integers",
    "section": "11.4 Summary",
    "text": "11.4 Summary"
  },
  {
    "objectID": "11.html#session-info",
    "href": "11.html#session-info",
    "title": "11  God Spiked the Integers",
    "section": "Session info",
    "text": "Session info\n\nsessionInfo()\n\nR version 4.4.0 (2024-04-24)\nPlatform: aarch64-apple-darwin20\nRunning under: macOS Ventura 13.4\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: America/Chicago\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n [1] posterior_1.6.0    patchwork_1.2.0    loo_2.8.0          rstan_2.32.6      \n [5] StanHeaders_2.32.7 tidybayes_3.0.6    lubridate_1.9.3    forcats_1.0.0     \n [9] stringr_1.5.1      dplyr_1.1.4        purrr_1.0.2        readr_2.1.5       \n[13] tidyr_1.3.1        tibble_3.2.1       ggplot2_3.5.1      tidyverse_2.0.0   \n\nloaded via a namespace (and not attached):\n [1] gtable_0.3.5         tensorA_0.36.2.1     xfun_0.43           \n [4] QuickJSR_1.1.3       htmlwidgets_1.6.4    inline_0.3.19       \n [7] lattice_0.22-6       tzdb_0.4.0           vctrs_0.6.5         \n[10] tools_4.4.0          generics_0.1.3       stats4_4.4.0        \n[13] curl_5.2.1           parallel_4.4.0       fansi_1.0.6         \n[16] pkgconfig_2.0.3      KernSmooth_2.23-22   Matrix_1.7-0        \n[19] checkmate_2.3.1      distributional_0.4.0 RcppParallel_5.1.7  \n[22] lifecycle_1.0.4      farver_2.1.1         compiler_4.4.0      \n[25] munsell_0.5.1        codetools_0.2-20     htmltools_0.5.8.1   \n[28] yaml_2.3.8           pillar_1.9.0         arrayhelpers_1.1-0  \n[31] abind_1.4-5          tidyselect_1.2.1     digest_0.6.35       \n[34] svUnit_1.0.6         stringi_1.8.4        labeling_0.4.3      \n[37] fastmap_1.1.1        grid_4.4.0           colorspace_2.1-0    \n[40] cli_3.6.3            magrittr_2.0.3       pkgbuild_1.4.4      \n[43] utf8_1.2.4           withr_3.0.0          scales_1.3.0        \n[46] backports_1.5.0      timechange_0.3.0     rmarkdown_2.26      \n[49] matrixStats_1.3.0    gridExtra_2.3        hms_1.1.3           \n[52] coda_0.19-4.1        evaluate_0.23        knitr_1.46          \n[55] V8_4.4.2             ggdist_3.3.2         viridisLite_0.4.2   \n[58] rlang_1.1.4          Rcpp_1.0.12          glue_1.7.0          \n[61] rstudioapi_0.16.0    jsonlite_1.8.8       R6_2.5.1"
  },
  {
    "objectID": "11.html#comments",
    "href": "11.html#comments",
    "title": "11  God Spiked the Integers",
    "section": "Comments",
    "text": "Comments\n\n\n\n\nKline, M. A., & Boyd, R. (2010). Population size predicts technological complexity in Oceania. Proceedings of the Royal Society B: Biological Sciences, 277(1693), 2559–2564. https://doi.org/10.1098/rspb.2010.0452\n\n\nSilk, J. B., Brosnan, S. F., Vonk, J., Henrich, J., Povinelli, D. J., Richardson, A. S., Lambeth, S. P., Mascaro, J., & Schapiro, S. J. (2005). Chimpanzees are indifferent to the welfare of unrelated group members. Nature, 437(7063), 1357–1359. https://doi.org/10.1038/nature04243"
  },
  {
    "objectID": "12.html#over-dispersed-counts",
    "href": "12.html#over-dispersed-counts",
    "title": "12  Monsters and Mixtures",
    "section": "12.1 Over-dispersed counts",
    "text": "12.1 Over-dispersed counts\n\n12.1.1 Beta-binomial.\nHere’s how we might plot the beta distribution, as discussed in McElreath’s R code 12.1. Note our use of the rethinking::dbeta2() function, which is parameterized in terms of prob (i.e., the mean, \\(\\alpha / (\\alpha + \\beta)\\)) and theta (i.e., the concentration, \\(\\alpha + \\beta\\)).\n\npbar  &lt;- 0.5\ntheta &lt;- 5\n\ntibble(x = seq(from = 0, to = 1, by = 0.01)) |&gt; \n  mutate(y = rethinking::dbeta2(x = x, prob = pbar, theta = theta)) |&gt; \n  \n  ggplot(aes(x = x, y = y)) +\n  geom_area() +\n  scale_x_continuous(\"probability space\", breaks = 0:2 / 2) +\n  scale_y_continuous(NULL, breaks = NULL) +\n  ggtitle(expression(The~beta~distribution),\n          subtitle = expression(\"Defined in terms of \"*mu*\" (i.e., pbar) and \"*kappa*\" (i.e., theta)\"))\n\n\n\n\nIn his (2015) text, Doing Bayesian data analysis, Kruschke provided code for a convenience function that takes pbar and theta as inputs and returns the corresponding \\(\\alpha\\) and \\(\\beta\\) values. Here’s the function:\n\nbeta_a_b_from_mean_kappa &lt;- function(mean, kappa) {\n  \n  if (mean &lt;= 0 | mean &gt;= 1) stop(\"Must have 0 &lt; `mean` &lt; 1.\")\n  if (kappa &lt;= 0) stop(\"`kappa` must be &gt; 0.\")\n  \n  a &lt;- mean * kappa\n  b &lt;- (1.0 - mean) * kappa\n  \n  list(a = a, b = b)\n  \n}\n\nNow we can use the beta_a_b_from_mean_kappa() function to find the \\(\\alpha\\) and \\(\\beta\\) values corresponding to McElreath’s pbar and theta.\n\nbeta_a_b_from_mean_kappa(mean = pbar, kappa = theta)\n\n$a\n[1] 2.5\n\n$b\n[1] 2.5\n\n\nAnd finally, we can double check that all of this works. Here’s the same distribution but defined in terms of \\(\\alpha\\) and \\(\\beta\\).\n\ntibble(x = seq(from = 0, to = 1, by = 0.01)) |&gt; \n  mutate(y = dbeta(x = x, shape1 = 2.5, shape2 = 2.5)) |&gt; \n  \n  ggplot(aes(x = x, y = y)) +\n  geom_area() +\n  scale_x_continuous(\"probability space\", breaks = 0:2 / 2) +\n  scale_y_continuous(NULL, breaks = NULL) +\n  ggtitle(expression(The~beta~distribution),\n          subtitle = expression(\"This time defined in terms of \"*alpha*\" and \"*beta))\n\n\n\n\nMcElreath encouraged us to “explore different values for pbar and theta” (p. 371). Here’s a grid of plots with \\(\\bar p \\in \\{0.25, 0.5, 0.75 \\}\\) and \\(\\theta \\in \\{5, 15, 30 \\}\\).\n\n# Data\ncrossing(pbar  = c(0.25, 0.5, 0.75),\n         theta = c(5, 15, 30)) |&gt; \n  expand_grid(x = seq(from = 0, to = 1, length.out = 301)) |&gt; \n  mutate(density = rethinking::dbeta2(x = x, prob = pbar, theta = theta),\n         mu      = str_c(\"mu==\", pbar),\n         kappa   = factor(str_c(\"kappa==\", theta),\n                          levels = str_c(\"kappa==\", c(30, 15, 5)))) |&gt; \n  \n  # plot\n  ggplot(aes(x = x, y = density)) +\n  geom_area() +\n  scale_x_continuous(\"probability space\", \n                     breaks = 0:2 / 2, labels = c(0, 0.5, 1)) +\n  scale_y_continuous(NULL, breaks = NULL) +\n  facet_grid(kappa ~ mu, labeller = label_parsed)\n\n\n\n\nThe statistical model we’ll be fitting follows the form\n\\[\n\\begin{align*}\n\\text{admit}_i & \\sim \\operatorname{BetaBinomial}(n_i, \\bar p_i, \\theta) \\\\\n\\operatorname{logit}(\\bar p_i) & = \\alpha_{\\text{gid}[i]} \\\\\n\\alpha_j & \\sim \\operatorname{Normal}(0, 1.5) \\\\\n\\theta & = \\phi + 2 \\\\\n\\phi     & \\sim \\operatorname{Exponential}(1),\n\\end{align*}\n\\]\nwhere \\(n\\) is defined in the applications column in the data, and \\(\\alpha_\\text{gid}\\) means we’ll be fitting separate intercepts by the two levels of our gender index gid. On page 317 of the text, McElreath explained why we’d work with \\(\\phi\\), and from whence came its relation with \\(\\theta\\).\nHere we load the UCBadmit data and then make our stan_data.\n\ndata(UCBadmit, package = \"rethinking\") \nd &lt;- UCBadmit |&gt; \n  rownames_to_column(\"i\") |&gt; \n  mutate(gid = ifelse(applicant.gender == \"male\", \"1\", \"2\"))\nrm(UCBadmit)\n\nstan_data &lt;- d |&gt;\n  mutate(gid = ifelse(applicant.gender == \"male\", \"1\", \"2\")) |&gt;\n  select(admit, applications, gid) |&gt; \n  compose_data()\n\n# What?\nstr(stan_data)\n\nList of 5\n $ admit       : int [1:12(1d)] 512 89 353 17 120 202 138 131 53 94 ...\n $ applications: int [1:12(1d)] 825 108 560 25 325 593 417 375 191 393 ...\n $ gid         : num [1:12(1d)] 1 2 1 2 1 2 1 2 1 2 ...\n $ n_gid       : int 2\n $ n           : int 12\n\n\nOur model_code_12.1 shows some complications McElreath glossed over in the text. Before we get into the bigger complications, first note how we defined phi in the parameters block, and then defined theta in terms of phi in the transformed parameters below. We also defined a vector of pbar values, which are just \\(\\operatorname{logit}(\\alpha_{\\text{gid}[i]})^{-1}\\). These will come in handy for the posterior-predictive check in Figure 12.1. But they’ll also come in handy for another reason we’ll describe next.\nThe larger complications in our model_code_12.1 come into play when we get to the likelihood within the model block. In the statistical formula above, which is based on McElreath’s statistical formula on page 371 in the text, we defined the beta-binomial likelihood in terms of \\(\\bar p\\) and \\(\\theta\\). This is also how McElreath parameterized the dbetabinom() function in the rethinking package. Stan, however, parameterizes the beta_binomial() likelihood in terms of the canonical \\(\\alpha\\) and \\(\\beta\\) parameters. See the Beta-binomial distribution section in the Stan Functions Reference for the technical details. This means we need to transform our \\(\\bar p\\) and \\(\\theta\\) parameters into \\(\\alpha\\) and \\(\\beta\\). We defined that vector of pbar values as a preliminary step. We can then define alpha and beta in terms of pbar and theta, which are\n\\[\n\\begin{align}\n\\alpha & = \\bar p \\theta, \\\\\n\\beta  & = (1 - \\bar p) \\theta.\n\\end{align}\n\\]\nThen after all that, we can define the beta-binomial likelihood for admit with the beta_binomial() function in terms of alpha and beta.\n\nmodel_code_12.1 &lt;- '\ndata {\n  int&lt;lower=1&gt; n;                       \n  int&lt;lower=1&gt; n_gid;                       \n  array[n] int applications;\n  array[n] int gid;\n  array[n] int admit;\n}\nparameters {\n  vector[n_gid] a;\n  real&lt;lower=0&gt; phi;\n}\ntransformed parameters {\n  real theta;\n  theta = phi + 2;\n  \n  vector[n] pbar;\n  pbar = inv_logit(a[gid]);\n}\nmodel {\n  vector[n] alpha;\n  vector[n] beta;\n  alpha = pbar * theta;\n  beta = (1 - pbar) * theta;\n  \n  admit ~ beta_binomial(applications, alpha, beta);\n  a ~ normal(0, 1.5);\n  phi ~ exponential(1);\n}\n'\n\nm12.1 &lt;- stan(\n  model_code = model_code_12.1, \n  data = stan_data,\n  cores = 4, seed = 12)\n\nCheck the model summary.\n\nprint(m12.1, pars = c(\"a\", \"phi\", \"theta\"), probs = c(0.055, 0.945))\n\nInference for Stan model: anon_model.\n4 chains, each with iter=2000; warmup=1000; thin=1; \npost-warmup draws per chain=1000, total post-warmup draws=4000.\n\n       mean se_mean   sd  5.5% 94.5% n_eff Rhat\na[1]  -0.43    0.01 0.41 -1.08  0.21  3237    1\na[2]  -0.33    0.01 0.41 -0.98  0.33  3116    1\nphi    1.04    0.01 0.80  0.10  2.51  3737    1\ntheta  3.04    0.01 0.80  2.10  4.51  3737    1\n\nSamples were drawn using NUTS(diag_e) at Sun Aug 18 15:49:54 2024.\nFor each parameter, n_eff is a crude measure of effective sample size,\nand Rhat is the potential scale reduction factor on split chains (at \nconvergence, Rhat=1).\n\n\nHere’s the summary for the \\(\\alpha_1 - \\alpha_2\\) contrast, what McElreath called da.\n\n# Extract the posterior draws\npost &lt;- as_draws_df(m12.1)\n\npost |&gt; \n  mean_qi(`a[1]` - `a[2]`, .width = 0.89) |&gt; \n  mutate_if(is.double, round, digits = 3)\n\n# A tibble: 1 × 6\n  `\\`a[1]\\` - \\`a[2]\\`` .lower .upper .width .point .interval\n                  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;    \n1                -0.103  -1.00  0.824   0.89 mean   qi       \n\n\nMuch like in the text, the difference between genders on admission rates is near zero, with wide uncertainty intervals spanning in either direction.\nHere’s the left panel of Figure 12.1.\n\nset.seed(12)\n\n# For the 100 lines\np1 &lt;- post |&gt; \n  mutate(p_bar = plogis(`a[2]`)) |&gt; \n  slice_sample(n = 100) |&gt; \n  select(.draw, p_bar, theta) |&gt; \n  expand_grid(x = seq(from = 0, to = 1, length.out = 201)) |&gt; \n  mutate(density = rethinking::dbeta2(x = x, prob = p_bar, theta = theta)) |&gt; \n  \n  ggplot(aes(x = x, y = density)) +\n  geom_line(aes(group = .draw),\n            alpha = 0.2, linewidth = 0.25) +\n  # For the line of the mean parameters\n  stat_function(fun = rethinking::dbeta2,\n                args = list(prob = mean(plogis(post$`a[2]`)),\n                            theta = mean(post$theta)),\n                linewidth = 1.5, n = 201) +\n  labs(subtitle = \"Distribution of female admission rates\",\n       x = \"probability admit\") +\n  coord_cartesian(ylim = c(0, 3))\n\np1\n\n\n\n\nHere’s one way to make the right panel of Figure 12.1, and then combine it with the left panel, above, to display the full figure. Note our use of the pbar[i] vector in spread_draws().\n\np2 &lt;- spread_draws(m12.1, pbar[i], theta) |&gt; \n  left_join(d |&gt; \n              mutate(i = as.integer(i)),\n            by = join_by(i)) |&gt; \n  mutate(admit = rethinking::rbetabinom(n = n(), size = applications, prob = pbar, theta = theta)) |&gt; \n  \n  ggplot(aes(x = gid)) +\n  stat_pointinterval(aes(y = admit / applications),\n                     point_interval = mean_qi, .width = 0.89,\n                     linewidth = 1, shape = 1) +\n  geom_point(data = d,\n             aes(y = admit / applications),\n             color = \"blue\", size = 2.5) +\n  scale_x_discrete(\"case\", labels = c(\"m\", \"f\")) +\n  scale_y_continuous(\"admit\", limits = 0:1) +\n  labs(subtitle = \"Posterior validation check\") +\n  facet_wrap(~ dept, nrow = 1)\n\n# Combine\np1 | p2\n\n\n\n\nAs in the text, the raw data are consistent with the prediction intervals. But those intervals are so incredibly wide, they’re hardly an endorsement of the model. Once we learn about hierarchical models, we’ll be able to do much better.\n\n\n12.1.2 Negative-binomial or gamma-Poisson.\nWe might express the gamma-Poisson (negative binomial) as\n\\[y_i \\sim \\operatorname{Gamma-Poisson}(\\lambda, \\phi),\\]\nwhere \\(\\lambda\\) is the mean or rate, and \\(\\alpha\\) is the dispersion or scale.\nLet’s load the Kline data to help get a sense of how this works.\n\ndata(Kline, package = \"rethinking\")\nd &lt;- Kline |&gt; \n  mutate(i = 1:n(),\n         cid = ifelse(contact == \"high\", \"2\", \"1\")) \nrm(Kline)\n\n# What?\nprint(d)\n\n      culture population contact total_tools mean_TU  i cid\n1    Malekula       1100     low          13     3.2  1   1\n2     Tikopia       1500     low          22     4.7  2   1\n3  Santa Cruz       3600     low          24     4.0  3   1\n4         Yap       4791    high          43     5.0  4   2\n5    Lau Fiji       7400    high          33     5.0  5   2\n6   Trobriand       8000    high          19     4.0  6   2\n7       Chuuk       9200    high          40     3.8  7   2\n8       Manus      13000     low          28     6.6  8   1\n9       Tonga      17500    high          55     5.4  9   2\n10     Hawaii     275000     low          71     6.6 10   1\n\n\nIf you take a look at McElreath’s m12.2, you’ll see it’s a gamma-Poisson version of the non-linear model m11.11 he fit back in Section 11.2.1.1. We can describe this new version of the model as\n\\[\n\\begin{align*}\n\\text{total-tools}_i & \\sim \\operatorname{Gamma-Poisson} (\\lambda_i, \\phi) \\\\\n\\lambda_i & = \\exp (\\alpha_{\\text{cid}[i]}) \\text{population}_i^{\\beta_\\text{cid}[i]} / \\gamma \\\\\n\\alpha_j & \\sim \\operatorname{Normal}(1, 1) \\\\\n\\beta_j  & \\sim \\operatorname{Exponential}(1) \\\\\n\\gamma & \\sim \\operatorname{Exponential}(1) \\\\\n\\phi   & \\sim \\operatorname{Exponential}(1).\n\\end{align*}\n\\]\nMake the d_pred data for the predictions we’ll display in the plot.\n\nd_pred &lt;- tibble(\n  population = seq(from = 0, to = 3e5, length.out = 101) |&gt; \n    as.integer()) |&gt; \n  expand_grid(cid = 1:2) |&gt; \n  mutate(i = 1:n())\n\n# What?\nglimpse(d_pred)\n\nRows: 202\nColumns: 3\n$ population &lt;int&gt; 0, 0, 3000, 3000, 6000, 6000, 9000, 9000, 12000, 12000, 150…\n$ cid        &lt;int&gt; 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2,…\n$ i          &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, …\n\n\nMake the stan_data.\n\nstan_data &lt;- d |&gt; \n  mutate(population = as.double(population)) |&gt;\n  select(total_tools, population, cid) |&gt;\n  compose_data(population_pred = d_pred$population,\n               cid_pred = d_pred$cid,\n               n_pred = nrow(d_pred))\n\n# What?\nstr(stan_data)\n\nList of 8\n $ total_tools    : int [1:10(1d)] 13 22 24 43 33 19 40 28 55 71\n $ population     : num [1:10(1d)] 1100 1500 3600 4791 7400 ...\n $ cid            : num [1:10(1d)] 1 1 1 2 2 2 2 1 2 1\n $ n_cid          : int 2\n $ n              : int 10\n $ population_pred: int [1:202] 0 0 3000 3000 6000 6000 9000 9000 12000 12000 ...\n $ cid_pred       : int [1:202] 1 2 1 2 1 2 1 2 1 2 ...\n $ n_pred         : int 202\n\n\nDefine model_code_12.2. Note that in Stan, the gamma-Poisson likelihood is called neg_binomial_2().\n\nmodel_code_12.2 &lt;- '\ndata {\n  int&lt;lower=1&gt; n;\n  int&lt;lower=1&gt; n_cid;\n  array[n] int cid;\n  vector[n] population;\n  array[n] int&lt;lower=0&gt; total_tools;\n  // For predictions\n  int&lt;lower=1&gt; n_pred;\n  array[n_pred] int cid_pred;\n  vector[n_pred] population_pred;\n}\nparameters {\n  vector[n_cid] a;\n  vector&lt;lower=0&gt;[n_cid] b;\n  real&lt;lower=0&gt; g;\n  real&lt;lower=0&gt; phi;\n}\ntransformed parameters {\n  vector[n] lambda;\n  lambda = exp(a[cid]) .* population^b[cid] / g;\n}\nmodel {\n  total_tools ~ neg_binomial_2(lambda, phi);\n  a ~ normal(1, 1);\n  b ~ exponential(1);\n  g ~ exponential(1);\n  phi ~ exponential(1);\n}\ngenerated quantities {\n  vector[n] log_lik;\n  vector[n_pred] lambda_pred;\n  \n  for (i in 1:n) log_lik[i] = neg_binomial_2_lpmf(total_tools[i] | lambda[i], phi);\n  lambda_pred = exp(a[cid_pred]) .* population_pred^b[cid_pred] / g;\n}\n'\n\nSample from the posteriors.\n\nm12.2 &lt;- stan(\n  data = stan_data,\n  model_code = model_code_12.2,\n  cores = 4, seed = 12)\n\nHere is the model summary.\n\nprint(m12.2, pars = c(\"a\", \"b\", \"g\", \"phi\"), probs = c(0.055, 0.945))\n\nInference for Stan model: anon_model.\n4 chains, each with iter=2000; warmup=1000; thin=1; \npost-warmup draws per chain=1000, total post-warmup draws=4000.\n\n     mean se_mean   sd  5.5% 94.5% n_eff Rhat\na[1] 0.92    0.02 0.83 -0.41  2.21  2117    1\na[2] 1.04    0.02 0.94 -0.44  2.57  2283    1\nb[1] 0.25    0.00 0.10  0.10  0.40  1910    1\nb[2] 0.26    0.00 0.13  0.06  0.47  1760    1\ng    1.08    0.02 0.86  0.19  2.69  1895    1\nphi  3.69    0.03 1.58  1.55  6.56  2382    1\n\nSamples were drawn using NUTS(diag_e) at Sun Aug 18 15:50:22 2024.\nFor each parameter, n_eff is a crude measure of effective sample size,\nand Rhat is the potential scale reduction factor on split chains (at \nconvergence, Rhat=1).\n\n\nCompute and check the PSIS-LOO estimates along with their diagnostic \\(k\\) values.\n\nl12.2 &lt;- extract_log_lik(m12.2) |&gt; loo()\n\nprint(l12.2)\n\n\nComputed from 4000 by 10 log-likelihood matrix.\n\n         Estimate  SE\nelpd_loo    -41.4 1.7\np_loo         1.2 0.2\nlooic        82.7 3.3\n------\nMCSE of elpd_loo is 0.0.\nMCSE and ESS estimates assume independent draws (r_eff=1).\n\nAll Pareto k estimates are good (k &lt; 0.7).\nSee help('pareto-k-diagnostic') for details.\n\n\n“All Pareto k estimates are good!”\nHere’s the LOO comparison between the original Poisson model, and our new gamma-Poisson.\n\nloo_compare(l11.11, l12.2) |&gt; \n  print(simplify = FALSE)\n\n       elpd_diff se_diff elpd_loo se_elpd_loo p_loo se_p_loo looic se_looic\nmodel1   0.0       0.0   -40.6      6.0         5.5   1.9     81.3  12.0   \nmodel2  -0.7       5.7   -41.4      1.7         1.2   0.2     82.7   3.3   \n\n\nNot much difference in this case. Here’s how we might make Figure 12.2.\n\n# For the `k`-sized points\nd_k &lt;- d |&gt; \n  mutate(p = l11.11$diagnostics$pareto_k,\n         gp = l12.2$diagnostics$pareto_k) |&gt; \n  pivot_longer(p:gp, values_to = \"k\") |&gt; \n  mutate(likelihood = factor(name, levels = c(\"p\", \"gp\"), \n                             labels = c(\"Poisson\", \"Gamma-Poisson\")))\n\n# Wrangle the posterior draws\nbind_rows(\n  spread_draws(m11.11, lambda_pred[i]),\n  spread_draws(m12.2, lambda_pred[i])\n  ) |&gt; \n  left_join(d_pred, by = join_by(i)) |&gt; \n  mutate(likelihood = rep(c(\"p\", \"gp\"), each = n() / 2) |&gt; \n           factor(levels = c(\"p\", \"gp\"), labels = c(\"Poisson\", \"Gamma-Poisson\")),\n         cid = as.character(cid)) |&gt; \n  rename(total_tools = lambda_pred)  |&gt; \n  \n  # Plot!\n  ggplot(aes(x = population, y = total_tools,\n             color = cid, fill = cid, group = cid)) +\n  stat_lineribbon(.width = 0.89, point_interval = mean_qi,\n                  alpha = 1/4) +\n  geom_point(data = d_k,\n             aes(size = k)) +\n  scale_x_continuous(\"population\", breaks = c(0, 50000, 150000, 250000),\n                     labels = scales::comma(c(0, 50000, 150000, 250000))) +\n  scale_color_viridis_d(option = \"A\", end = 0.6) +\n  scale_fill_viridis_d(option = \"A\", end = 0.6) +\n  scale_size_continuous(range = c(0.1, 5)) +\n  ylab(\"total tools\") +\n  coord_cartesian(xlim = range(d$population),\n                  ylim = c(0, 80)) +\n  facet_wrap(~ likelihood) +\n  theme(legend.position = \"none\")\n\n\n\n\n\n\n12.1.3 Over-dispersion, entropy, and information criteria.\n\n12.1.3.1 Overthinking: Continuous mixtures."
  },
  {
    "objectID": "12.html#zero-inflated-outcomes",
    "href": "12.html#zero-inflated-outcomes",
    "title": "12  Monsters and Mixtures",
    "section": "12.2 Zero-inflated outcomes",
    "text": "12.2 Zero-inflated outcomes\n\n12.2.0.1 Rethinking: Breaking the law.\n\n\n12.2.1 Example: Zero-inflated Poisson.\nDo you remember the monk data from back in Section 11.2.3? Here we simulate some more. This time we’ll work in a little alcohol.\n\n# Define parameters\nprob_drink &lt;- 0.2  # 20% of days\nrate_work  &lt;- 1    # Average 1 manuscript per day\n\n# Sample one year of production\nn &lt;- 365\n\n# Simulate days monks drink\nset.seed(365)\nd &lt;- tibble(drink = rbinom(n = n, size = 1, prob = prob_drink)) |&gt; \n  # Simulate manuscripts completed\n  mutate(y = (1 - drink) * rpois(n = n, lambda = rate_work))\n\n# What?\nglimpse(d)\n\nRows: 365\nColumns: 2\n$ drink &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0…\n$ y     &lt;dbl&gt; 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 2, 0, 0, 0, 0, 0, 0, 2, 0…\n\n\nHere’s a version of Figure 12.3, right.\n\nd |&gt; \n  ggplot(aes(x = y, fill = factor(drink, levels = 1:0))) +\n  geom_bar() +\n  scale_fill_viridis_d(end = 0.6, breaks = NULL) +\n  xlab(\"Manuscripts completed\")\n\n\n\n\nWith these data, the likelihood of observing zero on y, (i.e., the likelihood zero manuscripts were completed on a given occasion) is\n\\[\n\\begin{align*}\n\\Pr (0 \\mid p, \\lambda) & = \\Pr(\\text{drink} \\mid p) + \\Pr(\\text{work} \\mid p) \\times \\Pr(0 \\mid \\lambda) \\\\\n                        & = p + (1 - p) \\exp (- \\lambda).\n\\end{align*}\n\\]\nAnd\n\nsince the Poisson likelihood of \\(y\\) is \\(\\Pr (y \\mid \\lambda) = \\lambda^y \\exp (- \\lambda) / y!\\), the likelihood of \\(y = 0\\) is just \\(\\exp (- \\lambda)\\). The above is just the mathematics for:\n\nThe probability of observing a zero is the probability that the monks didn’t drink OR (\\(+\\)) the probability that the monks worked AND (\\(\\times\\)) failed to finish anything.\n\nAnd the likelihood of a non-zero value \\(y\\) is:\n\\[\\Pr (y \\mid y &gt; 0, p, \\lambda) = \\Pr (\\text{drink} \\mid p) (0) + \\Pr (\\text{work} \\mid p) \\Pr (y \\mid \\lambda) = (1 - p) \\frac {\\lambda^y \\exp (- \\lambda)}{y!}\\]\nSince drinking monks never produce \\(y &gt; 0\\), the expression above is just the chance the monks both work \\(1 - p\\), and finish \\(y\\) manuscripts. (pp. 377–378, emphasis in the original)\n\nSo letting \\(p\\) be the probability \\(y\\) is zero and \\(\\lambda\\) be the shape of the distribution, the zero-inflated Poisson (\\(\\operatorname{ZIPoisson}\\)) regression model might take the basic form\n\\[\n\\begin{align*}\ny_i & \\sim \\operatorname{ZIPoisson}(p_i, \\lambda_i) \\\\\n\\operatorname{logit}(p_i) & = \\alpha_p + \\beta_p x_i \\\\\n\\log (\\lambda_i) & = \\alpha_\\lambda + \\beta_\\lambda x_i,\n\\end{align*}\n\\]\nwhere both parameters in the likelihood, \\(p_i\\) and \\(\\lambda_i\\) might get their own statistical model, making this a special case of what Bürkner (2022) calls distributional models.\nMake the stan_data.\n\nstan_data &lt;- d |&gt; \n  compose_data()\n\n# What?\nstr(stan_data)\n\nList of 3\n $ drink: int [1:365(1d)] 0 0 0 0 0 0 0 1 0 0 ...\n $ y    : num [1:365(1d)] 1 0 1 0 0 0 1 0 0 1 ...\n $ n    : int 365\n\n\nNow we make model_code_12.3. Based on the Vectorizing mixtures section of the Stan User’s Guide, it looks like there is no way to express a zero-inflated model (or any other mixture model) with the vectorized notation. You must use a for loop of some kind.\n\nmodel_code_12.3 &lt;- '\ndata {\n  int&lt;lower=1&gt; n;\n  array[n] int y;\n}\nparameters {\n  real ap;\n  real al;\n}\nmodel {\n  // Convert the parameters to their natural scales, \n  // for notational convenience\n  real p;\n  real lambda;\n  p = inv_logit(ap);\n  lambda = exp(al);\n  \n  // Here is the likelihood\n  for (i in 1:n) {\n    if (y[i] == 0)\n      target += log_mix(p, 0, poisson_lpmf(0 | lambda));\n    if (y[i] &gt; 0)\n      target += log1m(p) + poisson_lpmf(y[i] | lambda);\n    }\n  \n  ap ~ normal(-1.5, 1);\n  al ~ normal(1, 0.5);\n} \n'\n\nFor proper attribution, this model_code is a thinly-veiled version of Arel-Bundock’s work. Now sample from the posterior with stan().\n\nm12.3 &lt;- stan(\n  data = stan_data,\n  model_code = model_code_12.3,\n  cores = 4, seed = 12)\n\nCheck the model summary.\n\nprint(m12.3, probs = c(0.055, 0.945))\n\nInference for Stan model: anon_model.\n4 chains, each with iter=2000; warmup=1000; thin=1; \npost-warmup draws per chain=1000, total post-warmup draws=4000.\n\n        mean se_mean   sd    5.5%   94.5% n_eff Rhat\nap     -1.28    0.01 0.36   -1.92   -0.79  1282    1\nal      0.01    0.00 0.09   -0.14    0.15  1251    1\nlp__ -438.66    0.03 1.04 -440.69 -437.67  1341    1\n\nSamples were drawn using NUTS(diag_e) at Sun Aug 18 15:51:57 2024.\nFor each parameter, n_eff is a crude measure of effective sample size,\nand Rhat is the potential scale reduction factor on split chains (at \nconvergence, Rhat=1).\n\n\nHere are the posterior means and CIs for \\(\\lambda\\) and \\(p\\), on their natural scales.\n\nas_draws_df(m12.3) |&gt; \n  transmute(p = plogis(ap),\n            lambda = exp(al)) |&gt; \n  pivot_longer(everything(), names_to = \"parameter\") |&gt; \n  group_by(parameter) |&gt; \n  mean_qi(.width = 0.89)\n\n# A tibble: 2 × 7\n  parameter value .lower .upper .width .point .interval\n  &lt;chr&gt;     &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;    \n1 lambda    1.02   0.872  1.16    0.89 mean   qi       \n2 p         0.224  0.128  0.312   0.89 mean   qi       \n\n\n\n12.2.1.1 Overthinking: Zero-inflated Poisson calculations in Stan.\nWe just did that!"
  },
  {
    "objectID": "12.html#ordered-categorical-outcomes",
    "href": "12.html#ordered-categorical-outcomes",
    "title": "12  Monsters and Mixtures",
    "section": "12.3 Ordered categorical outcomes",
    "text": "12.3 Ordered categorical outcomes\n\n12.3.1 Example: Moral intuition.\nLet’s get the Trolley data (see Cushman et al., 2006).\n\ndata(Trolley, package = \"rethinking\")\nd &lt;- Trolley\nrm(Trolley)\n\nUse glimpse() to get a sense of the dimensions of the data.\n\nglimpse(d)\n\nRows: 9,930\nColumns: 12\n$ case      &lt;fct&gt; cfaqu, cfbur, cfrub, cibox, cibur, cispe, fkaqu, fkboa, fkbo…\n$ response  &lt;int&gt; 4, 3, 4, 3, 3, 3, 5, 4, 4, 4, 4, 4, 4, 5, 4, 4, 4, 4, 4, 3, …\n$ order     &lt;int&gt; 2, 31, 16, 32, 4, 9, 29, 12, 23, 22, 27, 19, 14, 3, 18, 15, …\n$ id        &lt;fct&gt; 96;434, 96;434, 96;434, 96;434, 96;434, 96;434, 96;434, 96;4…\n$ age       &lt;int&gt; 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, …\n$ male      &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ edu       &lt;fct&gt; Middle School, Middle School, Middle School, Middle School, …\n$ action    &lt;int&gt; 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, …\n$ intention &lt;int&gt; 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, …\n$ contact   &lt;int&gt; 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ story     &lt;fct&gt; aqu, bur, rub, box, bur, spe, aqu, boa, box, bur, car, spe, …\n$ action2   &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, …\n\n\nThough we have 9,930 rows, we only have 331 unique individuals.\n\nd |&gt; \n  summarise(n = n_distinct(id))\n\n    n\n1 331\n\n\n\n\n12.3.2 Describing an ordered distribution with intercepts.\nMake our version of the simple Figure 12.4 histogram of our primary variable, response.\n\np1 &lt;- d |&gt; \n  ggplot(aes(x = response)) +\n  geom_bar(width = 1/4) +\n  scale_x_continuous(breaks = 1:7)\n        \np1\n\n\n\n\nOur cumulative proportion plot, Figure 12.4.b, will require some pre-plot wrangling.\n\np2 &lt;- d |&gt;\n  count(response) |&gt;\n  mutate(pr_k     = n / nrow(d),\n         cum_pr_k = cumsum(pr_k)) |&gt; \n  \n  ggplot(aes(x = response, y = cum_pr_k)) +\n  geom_line() +\n  geom_point(fill = \"grey92\", shape = 21, size = 2) +\n  scale_x_continuous(breaks = 1:7) +\n  scale_y_continuous(\"cumulative proportion\", breaks = 0:2 / 2) +\n  coord_cartesian(ylim = 0:1)\n\np2\n\n\n\n\n\nThen to re-describe the histogram as log-cumulative odds, we’ll need a series of intercept parameters. Each intercept will be on the log-cumulative-odds scale and stand in for the cumulative probability of each outcome. So this is just the application of the link function. The log-cumulative-odds that a response value \\(y_i\\) is equal-to-or-less-than some possible outcome value \\(k\\) is:\n\\[\\log \\frac{\\Pr(y_i \\leq k)}{1 - \\Pr(y_i \\leq k)} = \\alpha_k\\]\nwhere \\(\\alpha_k\\) is an “intercept” unique to each possible outcome value \\(k\\). (p. 383)\n\nFor Figure 12.4., we can compute the \\(\\alpha_k\\) estimates with the base-R qlogis() function, rather than using McElreath’s custom logit() function.\n\np3 &lt;- d |&gt;\n  count(response) |&gt;\n  mutate(cum_pr_k = cumsum(n / nrow(d))) |&gt; \n  mutate(alpha = qlogis(cum_pr_k)) |&gt; \n  filter(response &lt; 7) |&gt; \n  \n  ggplot(aes(x = response, y = alpha)) +\n  geom_line() +\n  geom_point(fill = \"grey92\", shape = 21, size = 2) +\n  scale_x_continuous(breaks = 1:7, limits = c(1, 7)) +\n  ylab(\"log-cumulative-odds\")\np3\n\n\n\n\nWhy not combine the three subplots with patchwork?\n\n(p1 | p2 | p3) + \n  plot_annotation(title = \"Re-describing a discrete distribution using log-cumulative-odds.\")\n\n\n\n\nThe code for Figure 12.5 is itself something of a monster.\n\nd |&gt;\n  count(response) |&gt;\n  mutate(pr_k     = n / nrow(d),\n         cum_pr_k = cumsum(n / nrow(d))) |&gt; \n  mutate(discrete_probability = ifelse(response == 1, cum_pr_k, cum_pr_k - pr_k)) |&gt;\n  \n  ggplot(aes(x = response, y = cum_pr_k)) +\n  geom_line() +\n  geom_point(fill = \"grey92\", shape = 21, size = 2) +\n  geom_linerange(aes(ymin = 0, ymax = cum_pr_k),\n                 color = \"gray40\") +\n  geom_linerange(aes(ymin = ifelse(response == 1, 0, discrete_probability), \n                     ymax = cum_pr_k),\n                 color = \"blue\", position = position_nudge(x = 0.1)) +\n  annotate(geom = \"text\",\n           x = 4.3, y = 0.565,\n           label = \"discrete probability\",\n           angle = 270, color = \"blue\", hjust = 0, size = 3) +\n  annotate(geom = \"text\",\n           x = 3.8, y = 0,\n           label = \"cumulative probability\",\n           angle = 90, color = \"gray40\", hjust = 0, size = 3) +\n  scale_x_continuous(breaks = 1:7) +\n  scale_y_continuous(\"cumulative proportion\", breaks = 0:2 / 2)\n\n\n\n\nA compact way to express the formula for this first type of statistical model is\n\\[\n\\begin{align*}\n\\text{response}_i & \\sim \\operatorname{Categorical} (\\mathbf p) \\\\\n\\operatorname{logit}(p_k) & = \\alpha_k - \\phi \\\\\n\\phi              & = 0 \\\\\n\\alpha_k          & \\sim \\operatorname{Normal}(0, 1.5),\n\\end{align*}\n\\]\nwhere the \\(\\alpha_k\\) term denotes the \\(K - 1\\) intercepts (cut points or thresholds) we use to describe each possible outcome value \\(k\\) and. The mysterious looking \\(\\phi\\) term is a stand-in for the potential terms of the linear model. In the case where we have no predictors, it’s just 0. Just hold on to your hats; this will make more sense in the next section.\n\nAn ordered-logit distribution is really just a categorical distribution that takes a vector \\(\\mathbf p = \\{p_1, p_2, p_3, p_4, p_5, p_6\\}\\) of probabilities of each response value below the maximum response (7 in this example). Each response value \\(k\\) in this vector is defined by its link to an intercept parameter, \\(\\alpha_k\\). Finally, some weakly regularizing priors are placed on these intercepts. (p. 385)\n\nMake the stan_data.\n\nstan_data &lt;- d |&gt; \n  select(response, action, intention, contact) |&gt; \n  compose_data(n_response = n_distinct(response))\n\n# What?\nstr(stan_data)\n\nList of 6\n $ response  : int [1:9930(1d)] 4 3 4 3 3 3 5 4 4 4 ...\n $ action    : int [1:9930(1d)] 0 0 0 0 0 0 1 1 1 1 ...\n $ intention : int [1:9930(1d)] 0 0 0 1 1 1 0 0 0 0 ...\n $ contact   : int [1:9930(1d)] 1 1 1 1 1 1 0 0 0 0 ...\n $ n         : int 9930\n $ n_response: int 7\n\n\nDefine model_code_12.4. I learned the syntax for this kind of model from this post on the Stan forums.\n\nmodel_code_12.4 &lt;- '\ndata {\n  int&lt;lower=1&gt; n;\n  int&lt;lower=1&gt; n_response;  // This is k\n  array[n] int&lt;lower=1, upper=n_response&gt; response;\n}\nparameters {\n  ordered[n_response - 1] cutpoint;\n}\nmodel {\n  vector[n] phi = rep_vector(0, n);\n  response ~ ordered_logistic(phi, cutpoint);\n  cutpoint ~ normal(0, 1.5);\n}\n'\n\nSample with stan().\n\nm12.4 &lt;- stan(\n  data = stan_data,\n  model_code = model_code_12.4,\n  cores = 4, seed = 12)\n\nCheck the model summary.\n\nprint(m12.4, pars = \"cutpoint\", probs = c(0.055, 0.945))\n\nInference for Stan model: anon_model.\n4 chains, each with iter=2000; warmup=1000; thin=1; \npost-warmup draws per chain=1000, total post-warmup draws=4000.\n\n             mean se_mean   sd  5.5% 94.5% n_eff Rhat\ncutpoint[1] -1.92       0 0.03 -1.96 -1.87  2734    1\ncutpoint[2] -1.27       0 0.02 -1.30 -1.23  3717    1\ncutpoint[3] -0.72       0 0.02 -0.75 -0.68  4341    1\ncutpoint[4]  0.25       0 0.02  0.22  0.28  4543    1\ncutpoint[5]  0.89       0 0.02  0.85  0.92  4248    1\ncutpoint[6]  1.77       0 0.03  1.72  1.81  4749    1\n\nSamples were drawn using NUTS(diag_e) at Sun Aug 18 15:52:39 2024.\nFor each parameter, n_eff is a crude measure of effective sample size,\nand Rhat is the potential scale reduction factor on split chains (at \nconvergence, Rhat=1).\n\n\nWe can convert the cutpoint posteriors to cumulative probabilities with plogis().\n\nm12.4 |&gt; \n  spread_draws(cutpoint[k]) |&gt; \n  mutate(cum_p = plogis(cutpoint)) |&gt; \n  mean_qi(cum_p, .width = 0.89)\n\n# A tibble: 6 × 7\n      k cum_p .lower .upper .width .point .interval\n  &lt;int&gt; &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;    \n1     1 0.128  0.123  0.134   0.89 mean   qi       \n2     2 0.220  0.213  0.226   0.89 mean   qi       \n3     3 0.328  0.320  0.335   0.89 mean   qi       \n4     4 0.562  0.554  0.569   0.89 mean   qi       \n5     5 0.709  0.702  0.716   0.89 mean   qi       \n6     6 0.854  0.849  0.860   0.89 mean   qi       \n\n\n\n\n12.3.3 Adding predictor variables.\nNow we define the generic linear model as \\(\\phi_i = \\beta x_i\\). Accordingly, the formula for our cumulative logit model becomes\n\\[\n\\begin{align*}\n\\log \\frac{\\Pr(y_i \\leq k)}{1 - \\Pr(y_i \\leq k)} & = \\alpha_k - \\phi_i \\\\\n\\phi_i & = \\beta x_i.\n\\end{align*}\n\\]\n\nThis form automatically ensures the correct ordering of the outcome values, while still morphing the likelihood of each individual value as the predictor \\(x_i\\) changes value. Why is the linear model \\(\\phi\\) subtracted from each intercept? Because if we decrease the log-cumulative-odds of every outcome value \\(k\\) below the maximum, this necessarily shifts probability mass upwards towards higher outcome values. So then positive values of \\(\\beta\\) mean increasing \\(x\\) also increases the mean \\(y\\). You could add \\(\\phi\\) instead like \\(\\alpha_k + \\phi_i\\). But then \\(\\beta &gt; 0\\) would indicate increasing \\(x\\) decreases the mean. (p. 386)\n\nHere’s a version of McElreath’s rethinking::dordlogit() function. You can find the original code for dordlogit() from McElreath’s GitHub repo for rethinking. We’ll call our version d_ord_logit().\n\nd_ord_logit &lt;- function(x, phi, a, log = FALSE) {\n  \n  a  &lt;- c(as.numeric(a), Inf)\n  p  &lt;- plogis(a[x] - phi)\n  na &lt;- c(-Inf, a)\n  np &lt;- plogis(na[x] - phi)\n  p  &lt;- p - np\n  if (log == TRUE) p &lt;- log(p)\n  p\n  \n}\n\nOur d_ord_logit() function works like this.\n\np_k &lt;- m12.4 |&gt; \n  spread_draws(cutpoint[k]) |&gt; \n  summarise(cutpoint = mean(cutpoint)) |&gt; \n  pull() |&gt; \n  d_ord_logit(x = 1:7, phi = 0)\n\n# What?\nprint(p_k)\n\n[1] 0.12823369 0.09159923 0.10785636 0.23394015 0.14727085 0.14550889 0.14559082\n\n\nNext, as McElreath further noted on page 338, “these probabilities imply an average outcome of:”\n\ntibble(k = 1:7,\n       p_k = p_k) |&gt; \n  summarise(average_outcome = sum(p_k * k))\n\n# A tibble: 1 × 1\n  average_outcome\n            &lt;dbl&gt;\n1            4.20\n\n\nNow we’ll try it by subtracting 0.5 from each.\n\np_k &lt;- m12.4 |&gt; \n  spread_draws(cutpoint[k]) |&gt; \n  # Here's the change\n  summarise(cutpoint = mean(cutpoint - 0.5)) |&gt; \n  pull() |&gt; \n  d_ord_logit(x = 1:7, phi = 0)\n\n# What?\nprint(p_k)\n\n[1] 0.08191055 0.06405010 0.08221264 0.20910330 0.15901792 0.18438150 0.21932400\n\n# The average\ntibble(k = 1:7,\n       p_k = p_k) |&gt; \n  summarise(average_outcome = sum(p_k * k))\n\n# A tibble: 1 × 1\n  average_outcome\n            &lt;dbl&gt;\n1            4.73\n\n\nSo the rule is we subtract the linear model from each intercept. “This way, a positive \\(\\beta\\) value indicates that an increase in the predictor variable \\(x\\) results in an increase in the average response” (p. 387). As to our upcoming model, we might express the statistical formula as\n\\[\n\\begin{align*}\n\\text{response}_i & \\sim \\operatorname{Categorical} (\\mathbf p) \\\\\n\\text{logit}(p_k) & = \\alpha_k - \\phi_i \\\\\n\\phi_i            & = \\beta_1 \\text{action}_i + \\beta_2 \\text{contact}_i +  (\\beta_3 + \\beta_4 \\text{action}_i + \\beta_5 \\text{contact}_i) \\text{intention}_i \\\\\n\\alpha_k          & \\sim \\operatorname{Normal}(0, 1.5) \\\\\n\\beta_1, \\dots, \\beta_5 & \\sim \\operatorname{Normal}(0, 0.5),\n\\end{align*}\n\\]\nwhere, because we have included predictors, \\(\\phi\\) is no longer set to 0. Using our skills from back in Chapter 8, we might also rewrite the linear model for \\(\\phi\\) as\n\\[\\phi_i = \\beta_1 \\text{action}_i + \\beta_2 \\text{contact}_i + \\beta_3 \\text{intention}_i + \\beta_4 (\\text{action}_i \\times \\text{intention}_i) + \\beta_5 (\\text{contact}_i \\times \\text{intention}_i).\\]\nBefore we fit the model, we’ll want to make a data frame with predictor values for the pp-check in Figure 12.6.\n\nd_pred &lt;- d |&gt; \n  distinct(action, contact, intention) |&gt; \n  mutate(i = 1:n())\n\n# What?\nglimpse(d_pred)\n\nRows: 6\nColumns: 4\n$ action    &lt;int&gt; 0, 0, 1, 0, 1, 0\n$ contact   &lt;int&gt; 1, 1, 0, 0, 0, 0\n$ intention &lt;int&gt; 0, 1, 0, 0, 1, 1\n$ i         &lt;int&gt; 1, 2, 3, 4, 5, 6\n\n\nUpdate the stan_data to include the elements from d_pred.\n\nstan_data &lt;- d |&gt; \n  select(response, action, intention, contact) |&gt; \n  compose_data(n_response = n_distinct(response),\n               # For the predictions\n               n_pred = nrow(d_pred),\n               action_pred = d_pred$action,\n               contact_pred = d_pred$contact,\n               intention_pred = d_pred$intention)\n\n# What?\nstr(stan_data)\n\nList of 10\n $ response      : int [1:9930(1d)] 4 3 4 3 3 3 5 4 4 4 ...\n $ action        : int [1:9930(1d)] 0 0 0 0 0 0 1 1 1 1 ...\n $ intention     : int [1:9930(1d)] 0 0 0 1 1 1 0 0 0 0 ...\n $ contact       : int [1:9930(1d)] 1 1 1 1 1 1 0 0 0 0 ...\n $ n             : int 9930\n $ n_response    : int 7\n $ n_pred        : int 6\n $ action_pred   : int [1:6] 0 0 1 0 1 0\n $ contact_pred  : int [1:6] 1 1 0 0 0 0\n $ intention_pred: int [1:6] 0 1 0 0 1 1\n\n\nNow we define model_code_12.5. Note how we’re adding a generated quantities block for the pp-check.\n\nmodel_code_12.5 &lt;- '\ndata {\n  int&lt;lower=1&gt; n;\n  int&lt;lower=1&gt; n_response;  // This is k\n  vector[n] action;\n  vector[n] contact;\n  vector[n] intention;\n  array[n] int&lt;lower=1, upper=n_response&gt; response;\n  // For predictions\n  int&lt;lower=1&gt; n_pred;\n  vector[n_pred] action_pred;\n  vector[n_pred] contact_pred;\n  vector[n_pred] intention_pred;\n  \n}\nparameters {\n  ordered[n_response - 1] cutpoint;\n  real bA;\n  real bI;\n  real bC;\n  real bIA;\n  real bIC;\n}\nmodel {\n  vector[n] BI;\n  vector[n] phi;\n  BI = bI + bIA * action + bIC * contact;\n  phi = bA * action + bC * contact + BI .* intention;\n  \n  response ~ ordered_logistic(phi, cutpoint);\n  \n  cutpoint ~ normal(0, 1.5);\n  [bA, bI, bC, bIA, bIC] ~ normal(0, 0.5);\n}\ngenerated quantities {\n  vector[n_pred] BI;\n  vector[n_pred] phi;\n  BI = bI + bIA * action_pred + bIC * contact_pred;\n  phi = bA * action_pred + bC * contact_pred + BI .* intention_pred;\n  \n  array[n_pred] int&lt;lower=1, upper=n_response&gt; response_pred;\n  for (i in 1:n_pred) \n    response_pred[i] = ordered_logistic_rng(phi[i], cutpoint);\n}\n'\n\nSample from the conditional ordinal model with stan().\n\nm12.5 &lt;- stan(\n  data = stan_data,\n  model_code = model_code_12.5,\n  cores = 4, seed = 12)\n\nBehold the model summary.\n\nprint(m12.5, \n      pars = c(\"cutpoint\", \"bA\", \"bI\", \"bC\", \"bIA\", \"bIC\"),\n      probs = c(0.055, 0.945))\n\nInference for Stan model: anon_model.\n4 chains, each with iter=2000; warmup=1000; thin=1; \npost-warmup draws per chain=1000, total post-warmup draws=4000.\n\n             mean se_mean   sd  5.5% 94.5% n_eff Rhat\ncutpoint[1] -2.63       0 0.05 -2.71 -2.55  1843    1\ncutpoint[2] -1.94       0 0.05 -2.01 -1.86  1875    1\ncutpoint[3] -1.34       0 0.05 -1.42 -1.27  1806    1\ncutpoint[4] -0.31       0 0.04 -0.38 -0.24  1846    1\ncutpoint[5]  0.36       0 0.04  0.29  0.43  1990    1\ncutpoint[6]  1.27       0 0.05  1.19  1.34  2176    1\nbA          -0.47       0 0.05 -0.56 -0.39  1945    1\nbI          -0.29       0 0.06 -0.38 -0.20  1784    1\nbC          -0.34       0 0.07 -0.45 -0.24  2198    1\nbIA         -0.43       0 0.08 -0.56 -0.30  2250    1\nbIC         -1.23       0 0.10 -1.39 -1.08  2066    1\n\nSamples were drawn using NUTS(diag_e) at Sun Aug 18 15:53:47 2024.\nFor each parameter, n_eff is a crude measure of effective sample size,\nand Rhat is the potential scale reduction factor on split chains (at \nconvergence, Rhat=1).\n\n\nHere are the \\(\\beta\\) coefficients in a coefficient plot.\n\nas_draws_df(m12.5) |&gt;\n  pivot_longer(cols = bA:bIC) |&gt; \n  \n  ggplot(aes(x = value, y = name)) +\n  stat_pointinterval(.width = 0.89, linewidth = 1/2, shape = 1) +\n  labs(x = \"posterior\",\n       y = NULL)\n\n\n\n\nHere’s how we can make the top row of Figure 12.6.\n\n# For the sample statistics\nd_cum_p &lt;- d |&gt;  \n  group_by(intention, contact, action) |&gt; \n  count(response) |&gt; \n  mutate(probability = cumsum(n / sum(n))) |&gt; \n  filter(response &lt; 7)\n\n# For `expand_grid()`\nnd &lt;- d |&gt; \n  count(action, contact, intention)\n\nset.seed(12)  # To make `slice_sample()` reproducible\n\n# Wrangle the posterior draws\nas_draws_df(m12.5) |&gt; \n  slice_sample(n = 50) |&gt; \n  expand_grid(nd) |&gt; \n  pivot_longer(starts_with(\"cutpoint\"), values_to = \"alpha\") |&gt; \n  mutate(k = str_extract(name, \"\\\\d\")) |&gt; \n  mutate(BI = bI + bIA * action + bIC * contact) |&gt; \n  mutate(phi = bA * action + bC * contact + BI * intention) |&gt; \n  mutate(log_cum_odds = alpha - phi) |&gt; \n  select(.draw, action:intention, k, log_cum_odds) |&gt; \n  mutate(probability = plogis(log_cum_odds)) |&gt; \n  \n  # Plot\n  ggplot(aes(x = intention, y = probability)) +\n  geom_line(aes(group = interaction(.draw, k)),\n            alpha = 1/4, linewidth = 1/4) +\n  geom_point(data = d_cum_p,\n             color = \"blue\") +\n  scale_x_continuous(\"intention\", breaks = 0:1) +\n  scale_y_continuous(breaks = c(0, .5, 1), limits = 0:1) +\n  facet_wrap(~ action + contact, labeller = label_both)\n\n\n\n\nHere’s how we might make the bottom row of Figure 12.6 using the response_pred posteriors from the generated quantities block.\n\nset.seed(12)  # To make `ndraws` reproducible\n\nm12.5 |&gt; \n  spread_draws(response_pred[i],\n               ndraws = 1000) |&gt; \n  left_join(d_pred, by = join_by(i)) |&gt; \n  mutate(response = response_pred,\n         intention = factor(intention)) |&gt; \n  \n  ggplot(aes(x = response, fill = intention)) +\n  geom_bar(position = position_dodge(width = 0.6), width = 0.6) +\n  scale_x_continuous(breaks = 1:7) +\n  scale_fill_manual(values = c(\"gray60\", \"blue\")) +\n  ylim(0, NA) +\n  facet_wrap(~ action + contact, labeller = label_both)\n\n\n\n\n\n12.3.3.1 Rethinking: Staring into the abyss."
  },
  {
    "objectID": "12.html#sec-Ordered-categorical-predictors",
    "href": "12.html#sec-Ordered-categorical-predictors",
    "title": "12  Monsters and Mixtures",
    "section": "12.4 Ordered categorical predictors",
    "text": "12.4 Ordered categorical predictors\n\nWe can handle ordered outcome variables using a categorical model with a cumulative link. That was the previous section. What about ordered predictor variables? We could just include them as continuous predictors like in any linear model. But this isn’t ideal. Just like with ordered outcomes, we don’t really want to assume that the distance between each ordinal value is the same. Luckily, we don’t have to. (p. 391)\n\nHere are the eight levels of edu.\n\ndistinct(d, edu)\n\n                   edu\n1        Middle School\n2    Bachelor's Degree\n3         Some College\n4      Master's Degree\n5 High School Graduate\n6      Graduate Degree\n7     Some High School\n8    Elementary School\n\n\nMcElreath defined his edu_new variable with an impressively compact couple lines of code. Here we’ll take a slightly different approach saving it as a factor with defined levels.\n\nedu_levels_vec &lt;- c(\"Elementary School\", \"Middle School\", \"Some High School\", \"High School Graduate\",\n                    \"Some College\", \"Bachelor's Degree\", \"Master's Degree\", \"Graduate Degree\")\n\nd &lt;- d |&gt; \n  mutate(edu_new = factor(edu, levels = edu_levels_vec))\n\n# What did we do?\nd |&gt; \n  distinct(edu, edu_new) |&gt; \n  arrange(edu_new)\n\n                   edu              edu_new\n1    Elementary School    Elementary School\n2        Middle School        Middle School\n3     Some High School     Some High School\n4 High School Graduate High School Graduate\n5         Some College         Some College\n6    Bachelor's Degree    Bachelor's Degree\n7      Master's Degree      Master's Degree\n8      Graduate Degree      Graduate Degree\n\n\nThe prior often used to handle monotonic effects is the Dirichlet distribution. The Dirichlet distribution is the multivariate extension of the beta distribution, which we met back in Section 12.1.1. Here we follow McElreath’s R code 12.32 to simulate a few draws from the Dirichlet distribution.\n\nset.seed(1805)\ndelta &lt;- gtools::rdirichlet(10, alpha = rep(2, times = 7)) \n\n# What?\nstr(delta)\n\n num [1:10, 1:7] 0.1053 0.2504 0.1917 0.1241 0.0877 ...\n\n\nPlot delta with ggplot().\n\ndelta |&gt; \n  data.frame() |&gt;\n  set_names(1:7) |&gt; \n  mutate(row = 1:n()) |&gt; \n  pivot_longer(-row, names_to = \"index\") |&gt; \n  \n  ggplot(aes(x = index, y = value, group = row,\n             alpha = row == 3, color = row == 3)) +\n  geom_line() +\n  geom_point() +\n  scale_alpha_manual(values = c(1/4, 1), breaks = NULL) +\n  scale_color_viridis_d(option = \"A\", end = 0.6, breaks = NULL) +\n  ylab(\"probability\")\n\n\n\n\nUpdate the stan_data to include edu_new and an alpha vector for the prior. Note how the compose_data() function converts the edu_new factor levels to the correct integer values.\n\nstan_data &lt;- d |&gt; \n  select(response, action, intention, contact, edu_new) |&gt; \n  compose_data(n_response = n_distinct(response),\n               alpha = rep(2, times = 7))  # delta prior\n\n# What?\nstr(stan_data)\n\nList of 9\n $ response  : int [1:9930(1d)] 4 3 4 3 3 3 5 4 4 4 ...\n $ action    : int [1:9930(1d)] 0 0 0 0 0 0 1 1 1 1 ...\n $ intention : int [1:9930(1d)] 0 0 0 1 1 1 0 0 0 0 ...\n $ contact   : int [1:9930(1d)] 1 1 1 1 1 1 0 0 0 0 ...\n $ edu_new   : num [1:9930(1d)] 2 2 2 2 2 2 2 2 2 2 ...\n $ n_edu_new : int 8\n $ n         : int 9930\n $ n_response: int 7\n $ alpha     : num [1:7] 2 2 2 2 2 2 2\n\n\nNow we define model_code_12.6. Although we can vectorize the ordered_logistic() likelihood for response, I’m not aware we can vectorize the phi model containing the new bE * sum(delta_j[1:edu_new[i]]) portion. One way or another, it looks like that requires a for loop. For more on why, see this thread on the Stan forums.\n\nmodel_code_12.6 &lt;- '\ndata {\n  int&lt;lower=1&gt; n;\n  int&lt;lower=1&gt; n_response;\n  int&lt;lower=1&gt; n_edu_new;\n  vector[n] action;\n  vector[n] contact;\n  vector[n] intention;\n  array[n] int edu_new;\n  array[n] int&lt;lower=1, upper=n_response&gt; response;\n  vector[n_edu_new - 1] alpha;\n}\nparameters {\n  ordered[n_response - 1] kappa;\n  real bE;\n  real bA;\n  real bI;\n  real bC;\n  simplex[n_edu_new - 1] delta;\n}\nmodel {\n  vector[n] phi;\n  vector[n_edu_new] delta_j;\n  \n  delta_j = append_row(0, delta);\n  for (i in 1:n) phi[i] = bE * sum(delta_j[1:edu_new[i]]) + bA * action[i] + bC * contact[i] + bI * intention[i];\n  response ~ ordered_logistic(phi, kappa);\n  \n  kappa ~ normal(0, 1.5);\n  delta ~ dirichlet(alpha);\n  [bE, bA, bI, bC] ~ normal(0, 1);\n}\n'\n\nSample from the conditional ordinal model with stan().\n\nm12.6 &lt;- stan(\n  data = stan_data,\n  model_code = model_code_12.6,\n  chains = 4, cores = 4, seed = 12)\n\nIn the text (p. 394), McElreath remarked it took about 20 minutes to fit this model in his computer. Using my 2023 M2-chip MacBook Pro, it took just under 4 minutes. Mind you, our rstan defaults to twice the number of warmup and post-warmup draws. If an when you can, try to vectorize your likelihood functions, friends.\nBehold the model summary.\n\nprint(m12.6, probs = c(0.055, 0.945))\n\nInference for Stan model: anon_model.\n4 chains, each with iter=2000; warmup=1000; thin=1; \npost-warmup draws per chain=1000, total post-warmup draws=4000.\n\n              mean se_mean   sd      5.5%     94.5% n_eff Rhat\nkappa[1]     -3.07    0.00 0.14     -3.31     -2.86  1797    1\nkappa[2]     -2.39    0.00 0.14     -2.63     -2.18  1780    1\nkappa[3]     -1.81    0.00 0.14     -2.05     -1.60  1797    1\nkappa[4]     -0.79    0.00 0.14     -1.03     -0.58  1789    1\nkappa[5]     -0.12    0.00 0.14     -0.35      0.09  1806    1\nkappa[6]      0.79    0.00 0.14      0.55      1.00  1809    1\nbE           -0.31    0.00 0.16     -0.57     -0.06  1745    1\nbA           -0.70    0.00 0.04     -0.77     -0.64  4256    1\nbI           -0.72    0.00 0.04     -0.78     -0.66  4810    1\nbC           -0.96    0.00 0.05     -1.03     -0.87  4024    1\ndelta[1]      0.23    0.00 0.14      0.05      0.48  2636    1\ndelta[2]      0.14    0.00 0.09      0.03      0.30  5169    1\ndelta[3]      0.19    0.00 0.11      0.05      0.39  4675    1\ndelta[4]      0.17    0.00 0.10      0.04      0.34  4026    1\ndelta[5]      0.04    0.00 0.05      0.01      0.12  1252    1\ndelta[6]      0.10    0.00 0.07      0.02      0.22  3313    1\ndelta[7]      0.13    0.00 0.08      0.03      0.26  4053    1\nlp__     -18574.88    0.08 2.98 -18580.12 -18570.82  1496    1\n\nSamples were drawn using NUTS(diag_e) at Sun Aug 18 15:57:04 2024.\nFor each parameter, n_eff is a crude measure of effective sample size,\nand Rhat is the potential scale reduction factor on split chains (at \nconvergence, Rhat=1).\n\n\nWe can visualize the \\(\\delta\\) parameters in a version of Figure 12.8 with help from GGally::ggpairs().\n\nm12.6 |&gt; \n  spread_draws(delta[j]) |&gt; \n  ungroup() |&gt; \n  left_join(d |&gt;\n              mutate(j = as.integer(edu_new) - 1L) |&gt; \n              distinct(edu, edu_new, j),\n            by = join_by(j)) |&gt; \n  select(.draw, edu, delta) |&gt; \n  pivot_wider(names_from = edu, values_from = delta) |&gt; \n  select(-.draw) |&gt; \n  \n  ggpairs(upper = list(continuous = wrap(\"cor\", stars = FALSE)),\n          lower = list(continuous = wrap(\"points\", alpha = 0.1, size = 0.1))) +\n  theme(strip.text = element_text(size = 7))\n\n\n\n\nNow we prepare for the more conventional model m12.7. First add a normalized version of edu_new called edu_norm.\n\nd &lt;- d |&gt; \n  mutate(edu_norm = (as.integer(edu_new) - 1) / 7)\n\n# What does this look like?\nd |&gt; \n  distinct(edu, edu_new, edu_norm) |&gt; \n  arrange(edu_new)\n\n                   edu              edu_new  edu_norm\n1    Elementary School    Elementary School 0.0000000\n2        Middle School        Middle School 0.1428571\n3     Some High School     Some High School 0.2857143\n4 High School Graduate High School Graduate 0.4285714\n5         Some College         Some College 0.5714286\n6    Bachelor's Degree    Bachelor's Degree 0.7142857\n7      Master's Degree      Master's Degree 0.8571429\n8      Graduate Degree      Graduate Degree 1.0000000\n\n\nNext we update the stan_data to include edu_norm.\n\nstan_data &lt;- d |&gt; \n  select(response, action, intention, contact, edu_norm) |&gt; \n  compose_data(n_response = n_distinct(response))\n\n# What?\nstr(stan_data)\n\nList of 7\n $ response  : int [1:9930(1d)] 4 3 4 3 3 3 5 4 4 4 ...\n $ action    : int [1:9930(1d)] 0 0 0 0 0 0 1 1 1 1 ...\n $ intention : int [1:9930(1d)] 0 0 0 1 1 1 0 0 0 0 ...\n $ contact   : int [1:9930(1d)] 1 1 1 1 1 1 0 0 0 0 ...\n $ edu_norm  : num [1:9930(1d)] 0.143 0.143 0.143 0.143 0.143 ...\n $ n         : int 9930\n $ n_response: int 7\n\n\nDefine model_code_12.7.\n\nmodel_code_12.7 &lt;- '\ndata {\n  int&lt;lower=1&gt; n;\n  int&lt;lower=1&gt; n_response;\n  vector[n] action;\n  vector[n] contact;\n  vector[n] intention;\n  vector[n] edu_norm;\n  array[n] int&lt;lower=1, upper=n_response&gt; response;\n}\nparameters {\n  ordered[n_response - 1] kappa;\n  real bE;\n  real bA;\n  real bI;\n  real bC;\n}\nmodel {\n  vector[n] phi;\n  phi = bE * edu_norm + bA * action + bC * contact + bI * intention;\n  response ~ ordered_logistic(phi, kappa);\n  \n  kappa ~ normal(0, 1.5);\n  [bE, bA, bI, bC] ~ normal(0, 1);\n}\n'\n\nSample from the conditional ordinal model with stan().\n\nm12.7 &lt;- stan(\n  data = stan_data,\n  model_code = model_code_12.7,\n  chains = 4, cores = 4, seed = 12)\n\nHere’s a focused summary of the \\(\\beta\\) coefficients.\n\nprint(m12.7, pars = c(\"bE\", \"bA\", \"bI\", \"bC\"), probs = c(0.055, 0.945))\n\nInference for Stan model: anon_model.\n4 chains, each with iter=2000; warmup=1000; thin=1; \npost-warmup draws per chain=1000, total post-warmup draws=4000.\n\n    mean se_mean   sd  5.5% 94.5% n_eff Rhat\nbE -0.10       0 0.09 -0.24  0.05  2885    1\nbA -0.70       0 0.04 -0.77 -0.64  3837    1\nbI -0.72       0 0.04 -0.77 -0.66  3976    1\nbC -0.96       0 0.05 -1.04 -0.88  3721    1\n\nSamples were drawn using NUTS(diag_e) at Sun Aug 18 15:58:20 2024.\nFor each parameter, n_eff is a crude measure of effective sample size,\nand Rhat is the potential scale reduction factor on split chains (at \nconvergence, Rhat=1)."
  },
  {
    "objectID": "12.html#summary",
    "href": "12.html#summary",
    "title": "12  Monsters and Mixtures",
    "section": "12.5 Summary",
    "text": "12.5 Summary"
  },
  {
    "objectID": "12.html#session-info",
    "href": "12.html#session-info",
    "title": "12  Monsters and Mixtures",
    "section": "Session info",
    "text": "Session info\n\nsessionInfo()\n\nR version 4.4.0 (2024-04-24)\nPlatform: aarch64-apple-darwin20\nRunning under: macOS Ventura 13.4\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: America/Chicago\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n [1] GGally_2.2.1       posterior_1.6.0    patchwork_1.2.0    loo_2.8.0         \n [5] rstan_2.32.6       StanHeaders_2.32.7 tidybayes_3.0.6    lubridate_1.9.3   \n [9] forcats_1.0.0      stringr_1.5.1      dplyr_1.1.4        purrr_1.0.2       \n[13] readr_2.1.5        tidyr_1.3.1        tibble_3.2.1       ggplot2_3.5.1     \n[17] tidyverse_2.0.0   \n\nloaded via a namespace (and not attached):\n [1] shape_1.4.6.1        gtable_0.3.5         tensorA_0.36.2.1    \n [4] xfun_0.43            QuickJSR_1.1.3       htmlwidgets_1.6.4   \n [7] processx_3.8.4       inline_0.3.19        lattice_0.22-6      \n[10] tzdb_0.4.0           ps_1.7.6             vctrs_0.6.5         \n[13] tools_4.4.0          generics_0.1.3       stats4_4.4.0        \n[16] curl_5.2.1           parallel_4.4.0       fansi_1.0.6         \n[19] cmdstanr_0.8.1       pkgconfig_2.0.3      Matrix_1.7-0        \n[22] checkmate_2.3.1      RColorBrewer_1.1-3   distributional_0.4.0\n[25] RcppParallel_5.1.7   lifecycle_1.0.4      farver_2.1.1        \n[28] compiler_4.4.0       munsell_0.5.1        codetools_0.2-20    \n[31] htmltools_0.5.8.1    yaml_2.3.8           pillar_1.9.0        \n[34] MASS_7.3-60.2        arrayhelpers_1.1-0   rethinking_2.40     \n[37] abind_1.4-5          gtools_3.9.5         ggstats_0.6.0       \n[40] tidyselect_1.2.1     digest_0.6.35        svUnit_1.0.6        \n[43] mvtnorm_1.2-5        stringi_1.8.4        labeling_0.4.3      \n[46] fastmap_1.1.1        grid_4.4.0           colorspace_2.1-0    \n[49] cli_3.6.3            magrittr_2.0.3       pkgbuild_1.4.4      \n[52] utf8_1.2.4           withr_3.0.0          scales_1.3.0        \n[55] backports_1.5.0      timechange_0.3.0     rmarkdown_2.26      \n[58] matrixStats_1.3.0    gridExtra_2.3        hms_1.1.3           \n[61] coda_0.19-4.1        evaluate_0.23        knitr_1.46          \n[64] V8_4.4.2             ggdist_3.3.2         viridisLite_0.4.2   \n[67] rlang_1.1.4          Rcpp_1.0.12          glue_1.7.0          \n[70] rstudioapi_0.16.0    jsonlite_1.8.8       plyr_1.8.9          \n[73] R6_2.5.1"
  },
  {
    "objectID": "12.html#comments",
    "href": "12.html#comments",
    "title": "12  Monsters and Mixtures",
    "section": "Comments",
    "text": "Comments\n\n\n\n\nBürkner, P.-C. (2022). Estimating distributional models with brms. https://CRAN.R-project.org/package=brms/vignettes/brms_distreg.html\n\n\nCushman, F., Young, L., & Hauser, M. (2006). The role of conscious reasoning and intuition in moral judgment: Testing three principles of harm. Psychological Science, 17(12), 1082–1089. https://doi.org/10.1111/j.1467-9280.2006.01834.x\n\n\nKruschke, J. K. (2015). Doing Bayesian data analysis: A tutorial with R, JAGS, and Stan. Academic Press. https://sites.google.com/site/doingbayesiandataanalysis/"
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Allaire, J. J., Teague, C., Scheidegger, C., Xie, Y., & Dervieux, C.\n(2024). Quarto (version 1.2.0). https://doi.org/10.5281/zenodo.5960048\n\n\nBürkner, P.-C. (2022). Estimating distributional models with\nbrms. https://CRAN.R-project.org/package=brms/vignettes/brms_distreg.html\n\n\nCushman, F., Young, L., & Hauser, M. (2006). The role of conscious\nreasoning and intuition in moral judgment: Testing three\nprinciples of harm. Psychological Science, 17(12),\n1082–1089. https://doi.org/10.1111/j.1467-9280.2006.01834.x\n\n\nGrafen, A., & Hails, R. (2002). Modern statistics for the life\nsciences. Oxford University Press. https://global.oup.com/academic/product/modern-statistics-for-the-life-sciences-9780199252312?\n\n\nGuo, J., Gabry, J., Goodrich, B., Johnson, A., Weber, S., & Badr, H.\nS. (2024). “rstan” reference manual,\nVersion 2.32.6. https://CRAN.R-project.org/package=rstan/rstan.pdf\n\n\nHinde, K., & Milligan, L. A. (2011). Primate milk:\nProximate mechanisms and ultimate perspectives.\nEvolutionary Anthropology: Issues, News, and Reviews,\n20(1), 9–23. https://doi.org/10.1002/evan.20289\n\n\nHowell, N. (2001). Demography of the dobe! Kung\n(2nd Edition). Routledge. https://www.routledge.com/Demography-of-the-Dobe-Kung/Howell/p/book/9780202306490\n\n\nHowell, N. (2010). Life histories of the Dobe!\nKung: Food, fatness, and well-being over the\nlife span (Vol. 4). Univ of California Press. https://www.ucpress.edu/book/9780520262348/life-histories-of-the-dobe-kung\n\n\nKline, M. A., & Boyd, R. (2010). Population size predicts\ntechnological complexity in Oceania. Proceedings of the\nRoyal Society B: Biological Sciences, 277(1693),\n2559–2564. https://doi.org/10.1098/rspb.2010.0452\n\n\nKruschke, J. K. (2015). Doing Bayesian data analysis:\nA tutorial with R, JAGS, and\nStan. Academic Press. https://sites.google.com/site/doingbayesiandataanalysis/\n\n\nKurz, A. S. (2023). Statistical Rethinking with brms,\nggplot2, and the tidyverse: Second\nEdition (version 0.4.0). https://bookdown.org/content/4857/\n\n\nMcElreath, R. (2020). Statistical rethinking: A\nBayesian course with examples in R and\nStan (Second Edition). CRC Press. https://xcelab.net/rm/statistical-rethinking/\n\n\nNunn, N., & Puga, D. (2012). Ruggedness: The blessing\nof bad geography in Africa. Review of Economics and\nStatistics, 94(1), 20–36. https://doi.org/10.1162/REST_a_00161\n\n\nR Core Team. (2022). R: A language and environment for\nstatistical computing. R Foundation for Statistical Computing. https://www.R-project.org/\n\n\nSilk, J. B., Brosnan, S. F., Vonk, J., Henrich, J., Povinelli, D. J.,\nRichardson, A. S., Lambeth, S. P., Mascaro, J., & Schapiro, S. J.\n(2005). Chimpanzees are indifferent to the welfare of unrelated group\nmembers. Nature, 437(7063), 1357–1359. https://doi.org/10.1038/nature04243\n\n\nStan Development Team. (2024a). RStan: The\nR interface to Stan. https://mc-stan.org/\n\n\nStan Development Team. (2024b). Stan reference manual,\nVersion 2.35. https://mc-stan.org/docs/reference-manual/\n\n\nStan Development Team. (2024c). Stan user’s guide,\nVersion 2.35. https://mc-stan.org/docs/stan-users-guide/\n\n\nWalker, K. (2022). Tigris: Load census\nTIGER/Line shapefiles [Manual]. https://github.com/walkerke/tigris\n\n\nWickham, H. (2020). The tidyverse style guide. https://style.tidyverse.org/\n\n\nWickham, H. (2022). tidyverse:\nEasily install and load the ’tidyverse’. https://CRAN.R-project.org/package=tidyverse\n\n\nWickham, H., Averick, M., Bryan, J., Chang, W., McGowan, L. D.,\nFrançois, R., Grolemund, G., Hayes, A., Henry, L., Hester, J., Kuhn, M.,\nPedersen, T. L., Miller, E., Bache, S. M., Müller, K., Ooms, J.,\nRobinson, D., Seidel, D. P., Spinu, V., … Yutani, H. (2019). Welcome to\nthe tidyverse. Journal of Open Source Software, 4(43),\n1686. https://doi.org/10.21105/joss.01686\n\n\nWilks, S. S. (1938). The large-sample distribution of the likelihood\nratio for testing composite hypotheses. The Annals of Mathematical\nStatistics, 9(1), 60–62. https://doi.org/10.1214/aoms/1177732360\n\n\nXie, Y., Allaire, J. J., & Grolemund, G. (2020). R markdown:\nThe definitive guide. Chapman and\nHall/CRC. https://bookdown.org/yihui/rmarkdown/\n\n\nYao, Y., Vehtari, A., Simpson, D., & Gelman, A. (2018). Using\nstacking to average Bayesian predictive distributions (with\ndiscussion). Bayesian Analysis, 13(3), 917–1007. https://doi.org/10.1214/17-BA1091"
  }
]